{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04af3ce0",
   "metadata": {},
   "source": [
    "# Prompt Learning with NeMo\n",
    "\n",
    "In this example, we utilize NeMo's [prompt learning](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/nlp/nemo_megatron/prompt_learning.html)\n",
    "feature to showcase how to adapt a large language model (LLM) to \n",
    "a downstream task, such as financial sentiment predictions. \n",
    "\n",
    "The prompt learning technique shown in the example is [p-tuning](https://arxiv.org/abs/2103.10385), which adds a small prompt encoder network to the LLM\n",
    "to produce virtual token embeddings that guide the model toward the desired output of the downstream task.\n",
    "\n",
    "For more details on how to change hyperparameters for prompt learning in NeMo, see this [tutorial](https://github.com/NVIDIA/NeMo/blob/main/tutorials/nlp/Multitask_Prompt_and_PTuning.ipynb) which is also the basis for this NVFlare tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da75a8c",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "We assume you followed the instructions [here](../../README.md#requirements) \n",
    "to install the NeMo framework and the NeMo-NVFlare package. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb35454b",
   "metadata": {},
   "source": [
    "## Download the pre-trained LLM\n",
    "In this example, we use a `MegatronGPTModel`, a transformer-based language model based on the GPT architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7c60385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-06-01 17:59:34 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-06-01 17:59:34 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-06-01 17:59:38 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PretrainedModelInfo(\n",
       " \tpretrained_model_name=megatron_gpt_345m,\n",
       " \tdescription=345M parameter GPT generative Megatron model.,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/megatron_gpt_345m/versions/1/files/megatron_gpt_345m.nemo\n",
       " )]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check what GPT .nemo models we have available on NGC\n",
    "from nemo.collections.nlp.models.language_modeling.megatron_gpt_model import MegatronGPTModel\n",
    "MegatronGPTModel.list_available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7094bd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "megatron_gpt_345m.nemo already downloaded.\n"
     ]
    }
   ],
   "source": [
    "# Download the model from NGC\n",
    "import os\n",
    "model_file = \"megatron_gpt_345m.nemo\"\n",
    "if not os.path.isfile(model_file):\n",
    "    !wget \"https://api.ngc.nvidia.com/v2/models/nvidia/nemo/megatron_gpt_345m/versions/1/files/$model_file\"\n",
    "else:\n",
    "    print(f\"{model_file} already downloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af87594d",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "As our downstream task, we will use the [Financial PhraseBank dataset](https://huggingface.co/datasets/financial_phrasebank) for sentiment analysis.\n",
    "\n",
    "The Financial PhraseBank dataset contains the sentiments for financial news headlines from a retail investor's perspective. Further details about the dataset can be found in Malo et al.'s [\"Good Debt or Bad Debt: Detecting Semantic Orientations in Economic Texts\"](https://arxiv.org/abs/1307.5336).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d961b888",
   "metadata": {},
   "source": [
    "#### 1. Download the preprocessing scripts\n",
    "We use the preprocessing scripts provided by NeMo which can be downloaded from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1e787b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_learning_financial_phrase_bank_preprocessing.py already downloaded.\n"
     ]
    }
   ],
   "source": [
    "script_name = \"prompt_learning_financial_phrase_bank_preprocessing.py\"\n",
    "if not os.path.isfile(script_name):\n",
    "    !wget -N \"https://raw.githubusercontent.com/NVIDIA/NeMo/main/scripts/dataset_processing/nlp/financial_phrase_bank/$script_name\"\n",
    "else:\n",
    "    print(f\"{script_name} already downloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b144b6a",
   "metadata": {},
   "source": [
    "#### 2. Download the Financial PhraseBank Dataset\n",
    "\n",
    "Download the `FinancialPhraseBank-v1.0.zip` dataset from [here](https://www.researchgate.net/profile/Pekka_Malo/publication/251231364_FinancialPhraseBank-v1.0/data/0c96051eee4fb1d56e000000/FinancialPhraseBank-v1.0.zip).\n",
    "\n",
    "Then extract it under `./data`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4ef67d",
   "metadata": {},
   "source": [
    "#### 3. Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9bf347f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving train split to data/FinancialPhraseBank-v1.0/financial_phrase_bank_train.jsonl\n",
      "100%|███████████████████████████████████| 1811/1811 [00:00<00:00, 115010.74it/s]\n",
      "Saving val split to data/FinancialPhraseBank-v1.0/financial_phrase_bank_val.jsonl\n",
      "100%|█████████████████████████████████████| 226/226 [00:00<00:00, 113604.11it/s]\n",
      "Saving test split to data/FinancialPhraseBank-v1.0/financial_phrase_bank_test.jsonl\n",
      "100%|█████████████████████████████████████| 227/227 [00:00<00:00, 122567.84it/s]\n"
     ]
    }
   ],
   "source": [
    "!python3 prompt_learning_financial_phrase_bank_preprocessing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639e932d",
   "metadata": {},
   "source": [
    "#### 4. Split the dataset to simulate clients\n",
    "Next, we use three clients to simulate federated learning for p-tuning with NeMo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b207d7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training data with 1811 entries\n",
      "Save split 1 of 3 with 604 entries to data/FinancialPhraseBank-v1.0_split/site-1.jsonl\n",
      "Save split 2 of 3 with 604 entries to data/FinancialPhraseBank-v1.0_split/site-2.jsonl\n",
      "Save split 3 of 3 with 603 entries to data/FinancialPhraseBank-v1.0_split/site-3.jsonl\n"
     ]
    }
   ],
   "source": [
    "!python3 data/split_financial_phrase_data.py --data_path data/FinancialPhraseBank-v1.0/financial_phrase_bank_train.jsonl --num_clients 3 --out_dir data/FinancialPhraseBank-v1.0_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c35b1d",
   "metadata": {},
   "source": [
    "## Federated learning simulations\n",
    "Next, we are using NVFlare's [simulator](https://nvflare.readthedocs.io/en/latest/user_guide/fl_simulator.html) to simulate each client training on their own dataset locally and all three clients training together using the [FedAvg](https://arxiv.org/abs/1602.05629) algorithm implemented in NVFlare.\n",
    "\n",
    "With this setting, we require a GPU with at least 16GB memory to run all clients in parallel on the same GPU. \n",
    "If you have multiple GPUs in your system, you can use the `gpu` argument to assign one GPU for each client, e.g., `gpu=\"0,1\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7289c4",
   "metadata": {},
   "source": [
    "#### 1. Local P-Tuning\n",
    "First, we create the configuration files and modify them to include the current directory path to access the dataset and pre-trained LLM.\n",
    "At this point, we also modify the local number of clients, local epochs and FL rounds to simulate local training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c061fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created configs for 3 clients and set ROOT_DIR to /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning\n"
     ]
    }
   ],
   "source": [
    "!python3 create_configs.py --job_folder \"jobs/gpt_p-tuning_local_345M\" --num_clients 3 --aggregation_epochs 50 --num_rounds 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb462e0f",
   "metadata": {},
   "source": [
    "Next, simulate each client p-tuning on their local dataset using the FL simulator. To do this, we only run 1 round of FL, with each client running 50 p-tuning epochs on their local dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1475d13d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 17:59:42,489 - SimulatorRunner - INFO - Create the Simulator Server.\n",
      "2023-06-01 17:59:42,495 - Cell - INFO - server: creating listener on tcp://0:37707\n",
      "2023-06-01 17:59:42,497 - Cell - INFO - server: created backbone external listener for tcp://0:37707\n",
      "2023-06-01 17:59:42,498 - ConnectorManager - INFO - 2372: Try start_listener Listener resources: {'secure': False, 'host': 'localhost'}\n",
      "2023-06-01 17:59:42,499 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00002 PASSIVE tcp://0:5994] is starting\n",
      "2023-06-01 17:59:43,002 - Cell - INFO - server: created backbone internal listener for tcp://localhost:5994\n",
      "2023-06-01 17:59:43,004 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 PASSIVE tcp://0:37707] is starting\n",
      "2023-06-01 17:59:43,202 - nvflare.fuel.hci.server.hci - INFO - Starting Admin Server localhost on Port 55737\n",
      "2023-06-01 17:59:43,203 - SimulatorRunner - INFO - Deploy the Apps.\n",
      "2023-06-01 17:59:43,215 - SimulatorRunner - INFO - Create the simulate clients.\n",
      "2023-06-01 17:59:43,222 - ClientManager - INFO - Client: New client site-1@100.96.239.80 joined. Sent token: b0039ce2-47ee-49f0-b88e-ffb46b41a42b.  Total clients: 1\n",
      "2023-06-01 17:59:43,224 - FederatedClient - INFO - Successfully registered client:site-1 for project simulator_server. Token:b0039ce2-47ee-49f0-b88e-ffb46b41a42b SSID:\n",
      "2023-06-01 17:59:43,230 - ClientManager - INFO - Client: New client site-2@100.96.239.80 joined. Sent token: 5f5f491f-c986-49b3-9595-1ea8b0467c13.  Total clients: 2\n",
      "2023-06-01 17:59:43,232 - FederatedClient - INFO - Successfully registered client:site-2 for project simulator_server. Token:5f5f491f-c986-49b3-9595-1ea8b0467c13 SSID:\n",
      "2023-06-01 17:59:43,237 - ClientManager - INFO - Client: New client site-3@100.96.239.80 joined. Sent token: d32b4f90-3c63-4f36-b200-b016a8d0e358.  Total clients: 3\n",
      "2023-06-01 17:59:43,239 - FederatedClient - INFO - Successfully registered client:site-3 for project simulator_server. Token:d32b4f90-3c63-4f36-b200-b016a8d0e358 SSID:\n",
      "2023-06-01 17:59:43,242 - SimulatorRunner - INFO - Set the client status ready.\n",
      "2023-06-01 17:59:43,243 - SimulatorRunner - INFO - Deploy and start the Server App.\n",
      "2023-06-01 17:59:43,245 - ServerCommandAgent - INFO - ServerCommandAgent cell register_request_cb: server.simulate_job\n",
      "NEMO version 1.17.0\n",
      "2023-06-01 17:59:44,335 - IntimeModelSelector - INFO - model selection weights control: None\n",
      "2023-06-01 17:59:44,341 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job]: Server runner starting ...\n",
      "2023-06-01 17:59:44,473 - ServerPromptEncoder - INFO - [identity=simulator_server, run=simulate_job]: Initialized prompt encoder type PromptEncoderType.MLP\n",
      "2023-06-01 17:59:44,477 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job]: starting workflow share_config (<class 'nemo_nvflare.share_config.ShareConfig'>) ...\n",
      "2023-06-01 17:59:44,478 - ShareConfig - INFO - [identity=simulator_server, run=simulate_job]: Initializing BroadcastAndProcess.\n",
      "2023-06-01 17:59:44,481 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job]: Workflow share_config (<class 'nemo_nvflare.share_config.ShareConfig'>) started\n",
      "2023-06-01 17:59:44,532 - ConfigSharer - INFO - [identity=simulator_server, run=simulate_job, wf=share_config]: Load model configuration from /tmp/nvflare/nemo/gpt_p-tuning_local_345M/simulate_job/app_server/config/megatron_gpt_prompt_learning_config.yaml\n",
      "2023-06-01 17:59:44,534 - ConfigSharer - INFO - [identity=simulator_server, run=simulate_job, wf=share_config]: Load task templates from /tmp/nvflare/nemo/gpt_p-tuning_local_345M/simulate_job/app_server/config/task_templates.json\n",
      "2023-06-01 17:59:44,545 - ShareConfig - INFO - [identity=simulator_server, run=simulate_job, wf=share_config]: scheduled task share_config\n",
      "2023-06-01 17:59:45,253 - SimulatorClientRunner - INFO - Start the clients run simulation.\n",
      "2023-06-01 17:59:46,258 - SimulatorClientRunner - INFO - Simulate Run client: site-1\n",
      "2023-06-01 17:59:46,260 - SimulatorClientRunner - INFO - Simulate Run client: site-2\n",
      "2023-06-01 17:59:46,280 - SimulatorClientRunner - INFO - Simulate Run client: site-3\n",
      "2023-06-01 17:59:47,326 - ClientTaskWorker - INFO - ClientTaskWorker started to run\n",
      "2023-06-01 17:59:47,328 - Cell - INFO - site-1.simulate_job: created backbone external connector to tcp://localhost:37707\n",
      "2023-06-01 17:59:47,328 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 ACTIVE tcp://localhost:37707] is starting\n",
      "2023-06-01 17:59:47,333 - ClientTaskWorker - INFO - ClientTaskWorker started to run\n",
      "2023-06-01 17:59:47,334 - Cell - INFO - site-2.simulate_job: created backbone external connector to tcp://localhost:37707\n",
      "2023-06-01 17:59:47,334 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 ACTIVE tcp://localhost:37707] is starting\n",
      "2023-06-01 17:59:47,348 - ClientTaskWorker - INFO - ClientTaskWorker started to run\n",
      "2023-06-01 17:59:47,350 - Cell - INFO - site-3.simulate_job: created backbone external connector to tcp://localhost:37707\n",
      "2023-06-01 17:59:47,350 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 ACTIVE tcp://localhost:37707] is starting\n",
      "2023-06-01 17:59:54,088 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmpq8bec6cb\n",
      "2023-06-01 17:59:54,088 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmpq8bec6cb/_remote_module_non_scriptable.py\n",
      "2023-06-01 17:59:54,279 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmplfosgd8y\n",
      "2023-06-01 17:59:54,279 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmplfosgd8y/_remote_module_non_scriptable.py\n",
      "2023-06-01 17:59:54,476 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmphogouqsn\n",
      "2023-06-01 17:59:54,476 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmphogouqsn/_remote_module_non_scriptable.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-06-01 18:00:01 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-06-01 18:00:01 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-06-01 18:00:02 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-06-01 18:00:02 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-06-01 18:00:02 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-06-01 18:00:02 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-06-01 18:00:02 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 18:00:03,082 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-3, peer_run=simulate_job, task_name=share_config, task_id=c8a5911c-7e5e-441f-b165-a7c96fbeff7a]: assigned task to client site-3: name=share_config, id=c8a5911c-7e5e-441f-b165-a7c96fbeff7a\n",
      "2023-06-01 18:00:03,084 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-3, peer_run=simulate_job, task_name=share_config, task_id=c8a5911c-7e5e-441f-b165-a7c96fbeff7a]: sent task assignment to client. client_name:site-3 task_id:c8a5911c-7e5e-441f-b165-a7c96fbeff7a\n",
      "2023-06-01 18:00:03,086 - GetTaskCommand - INFO - return task to client.  client_name: site-3  task_name: share_config   task_id: c8a5911c-7e5e-441f-b165-a7c96fbeff7a  sharable_header_task_id: c8a5911c-7e5e-441f-b165-a7c96fbeff7a\n",
      "2023-06-01 18:00:03,121 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-3, peer_run=simulate_job]: got result from client site-3 for task: name=share_config, id=c8a5911c-7e5e-441f-b165-a7c96fbeff7a\n",
      "2023-06-01 18:00:03,123 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-3, peer_run=simulate_job, peer_rc=OK, task_name=share_config, task_id=c8a5911c-7e5e-441f-b165-a7c96fbeff7a]: finished processing client result by share_config\n",
      "2023-06-01 18:00:03,125 - SubmitUpdateCommand - INFO - submit_update process. client_name:site-3   task_id:c8a5911c-7e5e-441f-b165-a7c96fbeff7a\n",
      "NEMO version 1.17.0\n",
      "2023-06-01 18:00:03,077 - PromptLearner - INFO - [identity=site-3, run=simulate_job]: Initializing the Learner...\n",
      "2023-06-01 18:00:03,078 - PromptLearner - INFO - [identity=site-3, run=simulate_job]: Running with distributed environment: LOCAL_RANK: 0, RANK: 0, WORLD_SIZE 1, MASTER_ADDR: localhost, and MASTER_PORT: 36839\n",
      "2023-06-01 18:00:03,078 - ClientRunner - INFO - [identity=site-3, run=simulate_job]: client runner started\n",
      "2023-06-01 18:00:03,078 - ClientTaskWorker - INFO - Initialize ClientRunner for client: site-3\n",
      "2023-06-01 18:00:03,088 - Communicator - INFO - Received from simulator_server server  (3492 Bytes). getTask: share_config time: 0.007776737213134766 seconds\n",
      "2023-06-01 18:00:03,092 - FederatedClient - INFO - pull_task completed. Task name:share_config Status:True \n",
      "2023-06-01 18:00:03,092 - ClientRunner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=share_config, id=c8a5911c-7e5e-441f-b165-a7c96fbeff7a\n",
      "2023-06-01 18:00:03,093 - ClientRunner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c8a5911c-7e5e-441f-b165-a7c96fbeff7a]: invoking task executor <class 'nemo_nvflare.learner_executor.NemoLearnerExecutor'>\n",
      "2023-06-01 18:00:03,093 - PromptLearner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c8a5911c-7e5e-441f-b165-a7c96fbeff7a]: Initializing the Learner...\n",
      "2023-06-01 18:00:03,094 - PromptLearner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c8a5911c-7e5e-441f-b165-a7c96fbeff7a]: Running with distributed environment: LOCAL_RANK: 0, RANK: 0, WORLD_SIZE 1, MASTER_ADDR: localhost, and MASTER_PORT: 51565\n",
      "2023-06-01 18:00:03,094 - NemoLearnerExecutor - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c8a5911c-7e5e-441f-b165-a7c96fbeff7a]: Client trainer got task: share_config\n",
      "2023-06-01 18:00:03,118 - NemoLearnerExecutor - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c8a5911c-7e5e-441f-b165-a7c96fbeff7a]: Received config with 2 entries from server.\n",
      "2023-06-01 18:00:03,118 - ClientRunner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c8a5911c-7e5e-441f-b165-a7c96fbeff7a]: finished processing task\n",
      "2023-06-01 18:00:03,120 - FederatedClient - INFO - Starting to push execute result.\n",
      "2023-06-01 18:00:03,127 - Communicator - INFO -  SubmitUpdate size: 477 Bytes. time: 0.0068187713623046875 seconds\n",
      "2023-06-01 18:00:03,128 - ClientRunner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c8a5911c-7e5e-441f-b165-a7c96fbeff7a]: result sent to server for task: name=share_config, id=c8a5911c-7e5e-441f-b165-a7c96fbeff7a\n",
      "2023-06-01 18:00:03,128 - ClientTaskWorker - INFO - Finished one task run for client: site-3 interval: 2 task_processed: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0601 18:00:03.077422 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job]: Initializing the Learner...\n",
      "I0601 18:00:03.078066 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job]: Running with distributed environment: LOCAL_RANK: 0, RANK: 0, WORLD_SIZE 1, MASTER_ADDR: localhost, and MASTER_PORT: 36839\n",
      "I0601 18:00:03.078348 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job]: client runner started\n",
      "I0601 18:00:03.078536 140659256891200 simulator_worker.py:85] Initialize ClientRunner for client: site-3\n",
      "I0601 18:00:03.088636 140658085013248 communicator.py:200] Received from simulator_server server  (3492 Bytes). getTask: share_config time: 0.007776737213134766 seconds\n",
      "I0601 18:00:03.092673 140659256891200 fed_client.py:91] pull_task completed. Task name:share_config Status:True \n",
      "I0601 18:00:03.092940 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=share_config, id=c8a5911c-7e5e-441f-b165-a7c96fbeff7a\n",
      "I0601 18:00:03.093546 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c8a5911c-7e5e-441f-b165-a7c96fbeff7a]: invoking task executor <class 'nemo_nvflare.learner_executor.NemoLearnerExecutor'>\n",
      "I0601 18:00:03.093770 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c8a5911c-7e5e-441f-b165-a7c96fbeff7a]: Initializing the Learner...\n",
      "I0601 18:00:03.094047 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c8a5911c-7e5e-441f-b165-a7c96fbeff7a]: Running with distributed environment: LOCAL_RANK: 0, RANK: 0, WORLD_SIZE 1, MASTER_ADDR: localhost, and MASTER_PORT: 51565\n",
      "I0601 18:00:03.094260 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c8a5911c-7e5e-441f-b165-a7c96fbeff7a]: Client trainer got task: share_config\n",
      "I0601 18:00:03.118391 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c8a5911c-7e5e-441f-b165-a7c96fbeff7a]: Received config with 2 entries from server.\n",
      "I0601 18:00:03.118995 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c8a5911c-7e5e-441f-b165-a7c96fbeff7a]: finished processing task\n",
      "I0601 18:00:03.120325 140657883678464 fed_client_base.py:296] Starting to push execute result.\n",
      "I0601 18:00:03.127375 140657883678464 communicator.py:268]  SubmitUpdate size: 477 Bytes. time: 0.0068187713623046875 seconds\n",
      "I0601 18:00:03.128214 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c8a5911c-7e5e-441f-b165-a7c96fbeff7a]: result sent to server for task: name=share_config, id=c8a5911c-7e5e-441f-b165-a7c96fbeff7a\n",
      "I0601 18:00:03.128542 140659256891200 simulator_worker.py:94] Finished one task run for client: site-3 interval: 2 task_processed: True\n",
      "[NeMo W 2023-06-01 18:00:03 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-06-01 18:00:03 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 18:00:03,494 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-2, peer_run=simulate_job, task_name=share_config, task_id=c1e25224-6319-49f1-b387-e2bb0c8a2a33]: assigned task to client site-2: name=share_config, id=c1e25224-6319-49f1-b387-e2bb0c8a2a33\n",
      "2023-06-01 18:00:03,496 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-2, peer_run=simulate_job, task_name=share_config, task_id=c1e25224-6319-49f1-b387-e2bb0c8a2a33]: sent task assignment to client. client_name:site-2 task_id:c1e25224-6319-49f1-b387-e2bb0c8a2a33\n",
      "2023-06-01 18:00:03,497 - GetTaskCommand - INFO - return task to client.  client_name: site-2  task_name: share_config   task_id: c1e25224-6319-49f1-b387-e2bb0c8a2a33  sharable_header_task_id: c1e25224-6319-49f1-b387-e2bb0c8a2a33\n",
      "2023-06-01 18:00:03,536 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-2, peer_run=simulate_job]: got result from client site-2 for task: name=share_config, id=c1e25224-6319-49f1-b387-e2bb0c8a2a33\n",
      "2023-06-01 18:00:03,538 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-2, peer_run=simulate_job, peer_rc=OK, task_name=share_config, task_id=c1e25224-6319-49f1-b387-e2bb0c8a2a33]: finished processing client result by share_config\n",
      "2023-06-01 18:00:03,539 - SubmitUpdateCommand - INFO - submit_update process. client_name:site-2   task_id:c1e25224-6319-49f1-b387-e2bb0c8a2a33\n",
      "2023-06-01 18:00:03,574 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-1, peer_run=simulate_job, task_name=share_config, task_id=2cb7fa1a-6710-45ba-98a5-95ea7a4267f9]: assigned task to client site-1: name=share_config, id=2cb7fa1a-6710-45ba-98a5-95ea7a4267f9\n",
      "2023-06-01 18:00:03,575 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-1, peer_run=simulate_job, task_name=share_config, task_id=2cb7fa1a-6710-45ba-98a5-95ea7a4267f9]: sent task assignment to client. client_name:site-1 task_id:2cb7fa1a-6710-45ba-98a5-95ea7a4267f9\n",
      "2023-06-01 18:00:03,577 - GetTaskCommand - INFO - return task to client.  client_name: site-1  task_name: share_config   task_id: 2cb7fa1a-6710-45ba-98a5-95ea7a4267f9  sharable_header_task_id: 2cb7fa1a-6710-45ba-98a5-95ea7a4267f9\n",
      "2023-06-01 18:00:03,613 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-1, peer_run=simulate_job]: got result from client site-1 for task: name=share_config, id=2cb7fa1a-6710-45ba-98a5-95ea7a4267f9\n",
      "2023-06-01 18:00:03,615 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-1, peer_run=simulate_job, peer_rc=OK, task_name=share_config, task_id=2cb7fa1a-6710-45ba-98a5-95ea7a4267f9]: finished processing client result by share_config\n",
      "2023-06-01 18:00:03,617 - SubmitUpdateCommand - INFO - submit_update process. client_name:site-1   task_id:2cb7fa1a-6710-45ba-98a5-95ea7a4267f9\n",
      "NEMO version 1.17.0\n",
      "2023-06-01 18:00:03,490 - PromptLearner - INFO - [identity=site-2, run=simulate_job]: Initializing the Learner...\n",
      "2023-06-01 18:00:03,490 - PromptLearner - INFO - [identity=site-2, run=simulate_job]: Running with distributed environment: LOCAL_RANK: 0, RANK: 0, WORLD_SIZE 1, MASTER_ADDR: localhost, and MASTER_PORT: 41387\n",
      "2023-06-01 18:00:03,490 - ClientRunner - INFO - [identity=site-2, run=simulate_job]: client runner started\n",
      "2023-06-01 18:00:03,491 - ClientTaskWorker - INFO - Initialize ClientRunner for client: site-2\n",
      "2023-06-01 18:00:03,499 - Communicator - INFO - Received from simulator_server server  (3492 Bytes). getTask: share_config time: 0.00640869140625 seconds\n",
      "2023-06-01 18:00:03,503 - FederatedClient - INFO - pull_task completed. Task name:share_config Status:True \n",
      "2023-06-01 18:00:03,503 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=share_config, id=c1e25224-6319-49f1-b387-e2bb0c8a2a33\n",
      "2023-06-01 18:00:03,504 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c1e25224-6319-49f1-b387-e2bb0c8a2a33]: invoking task executor <class 'nemo_nvflare.learner_executor.NemoLearnerExecutor'>\n",
      "2023-06-01 18:00:03,504 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c1e25224-6319-49f1-b387-e2bb0c8a2a33]: Initializing the Learner...\n",
      "2023-06-01 18:00:03,505 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c1e25224-6319-49f1-b387-e2bb0c8a2a33]: Running with distributed environment: LOCAL_RANK: 0, RANK: 0, WORLD_SIZE 1, MASTER_ADDR: localhost, and MASTER_PORT: 35677\n",
      "2023-06-01 18:00:03,505 - NemoLearnerExecutor - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c1e25224-6319-49f1-b387-e2bb0c8a2a33]: Client trainer got task: share_config\n",
      "2023-06-01 18:00:03,530 - NemoLearnerExecutor - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c1e25224-6319-49f1-b387-e2bb0c8a2a33]: Received config with 2 entries from server.\n",
      "2023-06-01 18:00:03,530 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c1e25224-6319-49f1-b387-e2bb0c8a2a33]: finished processing task\n",
      "2023-06-01 18:00:03,535 - FederatedClient - INFO - Starting to push execute result.\n",
      "2023-06-01 18:00:03,541 - Communicator - INFO -  SubmitUpdate size: 477 Bytes. time: 0.006183624267578125 seconds\n",
      "2023-06-01 18:00:03,542 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c1e25224-6319-49f1-b387-e2bb0c8a2a33]: result sent to server for task: name=share_config, id=c1e25224-6319-49f1-b387-e2bb0c8a2a33\n",
      "2023-06-01 18:00:03,542 - ClientTaskWorker - INFO - Finished one task run for client: site-2 interval: 2 task_processed: True\n",
      "NEMO version 1.17.0\n",
      "2023-06-01 18:00:03,569 - PromptLearner - INFO - [identity=site-1, run=simulate_job]: Initializing the Learner...\n",
      "2023-06-01 18:00:03,570 - PromptLearner - INFO - [identity=site-1, run=simulate_job]: Running with distributed environment: LOCAL_RANK: 0, RANK: 0, WORLD_SIZE 1, MASTER_ADDR: localhost, and MASTER_PORT: 53353\n",
      "2023-06-01 18:00:03,570 - ClientRunner - INFO - [identity=site-1, run=simulate_job]: client runner started\n",
      "2023-06-01 18:00:03,570 - ClientTaskWorker - INFO - Initialize ClientRunner for client: site-1\n",
      "2023-06-01 18:00:03,579 - Communicator - INFO - Received from simulator_server server  (3492 Bytes). getTask: share_config time: 0.0060040950775146484 seconds\n",
      "2023-06-01 18:00:03,584 - FederatedClient - INFO - pull_task completed. Task name:share_config Status:True \n",
      "2023-06-01 18:00:03,584 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=share_config, id=2cb7fa1a-6710-45ba-98a5-95ea7a4267f9\n",
      "2023-06-01 18:00:03,585 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=2cb7fa1a-6710-45ba-98a5-95ea7a4267f9]: invoking task executor <class 'nemo_nvflare.learner_executor.NemoLearnerExecutor'>\n",
      "2023-06-01 18:00:03,585 - PromptLearner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=2cb7fa1a-6710-45ba-98a5-95ea7a4267f9]: Initializing the Learner...\n",
      "2023-06-01 18:00:03,585 - PromptLearner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=2cb7fa1a-6710-45ba-98a5-95ea7a4267f9]: Running with distributed environment: LOCAL_RANK: 0, RANK: 0, WORLD_SIZE 1, MASTER_ADDR: localhost, and MASTER_PORT: 41629\n",
      "2023-06-01 18:00:03,586 - NemoLearnerExecutor - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=2cb7fa1a-6710-45ba-98a5-95ea7a4267f9]: Client trainer got task: share_config\n",
      "2023-06-01 18:00:03,610 - NemoLearnerExecutor - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=2cb7fa1a-6710-45ba-98a5-95ea7a4267f9]: Received config with 2 entries from server.\n",
      "2023-06-01 18:00:03,611 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=2cb7fa1a-6710-45ba-98a5-95ea7a4267f9]: finished processing task\n",
      "2023-06-01 18:00:03,612 - FederatedClient - INFO - Starting to push execute result.\n",
      "2023-06-01 18:00:03,618 - Communicator - INFO -  SubmitUpdate size: 477 Bytes. time: 0.006112098693847656 seconds\n",
      "2023-06-01 18:00:03,619 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=2cb7fa1a-6710-45ba-98a5-95ea7a4267f9]: result sent to server for task: name=share_config, id=2cb7fa1a-6710-45ba-98a5-95ea7a4267f9\n",
      "2023-06-01 18:00:03,620 - ClientTaskWorker - INFO - Finished one task run for client: site-1 interval: 2 task_processed: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0601 18:00:03.490007 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job]: Initializing the Learner...\n",
      "I0601 18:00:03.490608 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job]: Running with distributed environment: LOCAL_RANK: 0, RANK: 0, WORLD_SIZE 1, MASTER_ADDR: localhost, and MASTER_PORT: 41387\n",
      "I0601 18:00:03.490874 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job]: client runner started\n",
      "I0601 18:00:03.491047 140713251325760 simulator_worker.py:85] Initialize ClientRunner for client: site-2\n",
      "I0601 18:00:03.499837 140712079447808 communicator.py:200] Received from simulator_server server  (3492 Bytes). getTask: share_config time: 0.00640869140625 seconds\n",
      "I0601 18:00:03.503662 140713251325760 fed_client.py:91] pull_task completed. Task name:share_config Status:True \n",
      "I0601 18:00:03.503941 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=share_config, id=c1e25224-6319-49f1-b387-e2bb0c8a2a33\n",
      "I0601 18:00:03.504549 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c1e25224-6319-49f1-b387-e2bb0c8a2a33]: invoking task executor <class 'nemo_nvflare.learner_executor.NemoLearnerExecutor'>\n",
      "I0601 18:00:03.504770 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c1e25224-6319-49f1-b387-e2bb0c8a2a33]: Initializing the Learner...\n",
      "I0601 18:00:03.505048 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c1e25224-6319-49f1-b387-e2bb0c8a2a33]: Running with distributed environment: LOCAL_RANK: 0, RANK: 0, WORLD_SIZE 1, MASTER_ADDR: localhost, and MASTER_PORT: 35677\n",
      "I0601 18:00:03.505245 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c1e25224-6319-49f1-b387-e2bb0c8a2a33]: Client trainer got task: share_config\n",
      "I0601 18:00:03.530249 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c1e25224-6319-49f1-b387-e2bb0c8a2a33]: Received config with 2 entries from server.\n",
      "I0601 18:00:03.530842 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c1e25224-6319-49f1-b387-e2bb0c8a2a33]: finished processing task\n",
      "I0601 18:00:03.535059 140711878113024 fed_client_base.py:296] Starting to push execute result.\n",
      "I0601 18:00:03.541470 140711878113024 communicator.py:268]  SubmitUpdate size: 477 Bytes. time: 0.006183624267578125 seconds\n",
      "I0601 18:00:03.542386 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=c1e25224-6319-49f1-b387-e2bb0c8a2a33]: result sent to server for task: name=share_config, id=c1e25224-6319-49f1-b387-e2bb0c8a2a33\n",
      "I0601 18:00:03.542724 140713251325760 simulator_worker.py:94] Finished one task run for client: site-2 interval: 2 task_processed: True\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0601 18:00:03.569459 140671809345344 fl_component.py:134] [identity=site-1, run=simulate_job]: Initializing the Learner...\n",
      "I0601 18:00:03.570110 140671809345344 fl_component.py:134] [identity=site-1, run=simulate_job]: Running with distributed environment: LOCAL_RANK: 0, RANK: 0, WORLD_SIZE 1, MASTER_ADDR: localhost, and MASTER_PORT: 53353\n",
      "I0601 18:00:03.570403 140671809345344 fl_component.py:134] [identity=site-1, run=simulate_job]: client runner started\n",
      "I0601 18:00:03.570578 140671809345344 simulator_worker.py:85] Initialize ClientRunner for client: site-1\n",
      "I0601 18:00:03.579733 140670637467392 communicator.py:200] Received from simulator_server server  (3492 Bytes). getTask: share_config time: 0.0060040950775146484 seconds\n",
      "I0601 18:00:03.584351 140671809345344 fed_client.py:91] pull_task completed. Task name:share_config Status:True \n",
      "I0601 18:00:03.584669 140671809345344 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=share_config, id=2cb7fa1a-6710-45ba-98a5-95ea7a4267f9\n",
      "I0601 18:00:03.585297 140671809345344 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=2cb7fa1a-6710-45ba-98a5-95ea7a4267f9]: invoking task executor <class 'nemo_nvflare.learner_executor.NemoLearnerExecutor'>\n",
      "I0601 18:00:03.585527 140671809345344 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=2cb7fa1a-6710-45ba-98a5-95ea7a4267f9]: Initializing the Learner...\n",
      "I0601 18:00:03.585809 140671809345344 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=2cb7fa1a-6710-45ba-98a5-95ea7a4267f9]: Running with distributed environment: LOCAL_RANK: 0, RANK: 0, WORLD_SIZE 1, MASTER_ADDR: localhost, and MASTER_PORT: 41629\n",
      "I0601 18:00:03.586007 140671809345344 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=2cb7fa1a-6710-45ba-98a5-95ea7a4267f9]: Client trainer got task: share_config\n",
      "I0601 18:00:03.610632 140671809345344 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=2cb7fa1a-6710-45ba-98a5-95ea7a4267f9]: Received config with 2 entries from server.\n",
      "I0601 18:00:03.611227 140671809345344 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=2cb7fa1a-6710-45ba-98a5-95ea7a4267f9]: finished processing task\n",
      "I0601 18:00:03.612613 140670436132608 fed_client_base.py:296] Starting to push execute result.\n",
      "I0601 18:00:03.618998 140670436132608 communicator.py:268]  SubmitUpdate size: 477 Bytes. time: 0.006112098693847656 seconds\n",
      "I0601 18:00:03.619933 140671809345344 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=2cb7fa1a-6710-45ba-98a5-95ea7a4267f9]: result sent to server for task: name=share_config, id=2cb7fa1a-6710-45ba-98a5-95ea7a4267f9\n",
      "I0601 18:00:03.620302 140671809345344 simulator_worker.py:94] Finished one task run for client: site-1 interval: 2 task_processed: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 18:00:03,713 - ShareConfig - INFO - [identity=simulator_server, run=simulate_job, wf=share_config]: task share_config exit with status TaskCompletionStatus.OK\n",
      "2023-06-01 18:00:03,798 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config]: Workflow: share_config finalizing ...\n",
      "2023-06-01 18:00:03,915 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config]: starting workflow scatter_and_gather (<class 'nvflare.app_common.workflows.scatter_and_gather.ScatterAndGather'>) ...\n",
      "2023-06-01 18:00:03,917 - ScatterAndGather - INFO - [identity=simulator_server, run=simulate_job, wf=share_config]: Initializing ScatterAndGather workflow.\n",
      "2023-06-01 18:00:03,922 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config]: Workflow scatter_and_gather (<class 'nvflare.app_common.workflows.scatter_and_gather.ScatterAndGather'>) started\n",
      "2023-06-01 18:00:03,923 - ScatterAndGather - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: Beginning ScatterAndGather training phase.\n",
      "2023-06-01 18:00:03,925 - ScatterAndGather - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: Round 0 started.\n",
      "2023-06-01 18:00:03,926 - ScatterAndGather - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: scheduled task train\n",
      "2023-06-01 18:00:05,133 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-3, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: assigned task to client site-3: name=train, id=42980685-a93e-4664-b2e2-9e89ea7f2802\n",
      "2023-06-01 18:00:05,135 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-3, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: sent task assignment to client. client_name:site-3 task_id:42980685-a93e-4664-b2e2-9e89ea7f2802\n",
      "2023-06-01 18:00:05,186 - GetTaskCommand - INFO - return task to client.  client_name: site-3  task_name: train   task_id: 42980685-a93e-4664-b2e2-9e89ea7f2802  sharable_header_task_id: 42980685-a93e-4664-b2e2-9e89ea7f2802\n",
      "2023-06-01 18:00:05,269 - Communicator - INFO - Received from simulator_server server  (16873468 Bytes). getTask: train time: 0.11282181739807129 seconds\n",
      "2023-06-01 18:00:05,270 - FederatedClient - INFO - pull_task completed. Task name:train Status:True \n",
      "2023-06-01 18:00:05,270 - ClientRunner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=train, id=42980685-a93e-4664-b2e2-9e89ea7f2802\n",
      "2023-06-01 18:00:05,271 - ClientRunner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: invoking task executor <class 'nemo_nvflare.learner_executor.NemoLearnerExecutor'>\n",
      "2023-06-01 18:00:05,271 - NemoLearnerExecutor - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Client trainer got task: train\n",
      "2023-06-01 18:00:05,271 - PromptLearner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Configuring the Learner...\n",
      "2023-06-01 18:00:05,275 - PromptLearner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Training with global_batch_size 64 and micro_batch_size 4\n",
      "2023-06-01 18:00:05,279 - pytorch_lightning.utilities.rank_zero - INFO - Using 16bit None Automatic Mixed Precision (AMP)\n",
      "2023-06-01 18:00:05,315 - pytorch_lightning.utilities.rank_zero - INFO - GPU available: True (cuda), used: True\n",
      "2023-06-01 18:00:05,315 - pytorch_lightning.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores\n",
      "2023-06-01 18:00:05,315 - pytorch_lightning.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs\n",
      "2023-06-01 18:00:05,315 - pytorch_lightning.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs\n",
      "2023-06-01 18:00:05,316 - pytorch_lightning.utilities.rank_zero - INFO - `Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "2023-06-01 18:00:05,330 - PromptLearner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Model config - seed: 1234\n",
      "nemo_path: /tmp/nvflare/nemo/gpt_p-tuning_local_345M/simulate_job/app_site-3/megatron_gpt_345m_sentiment.nemo\n",
      "virtual_prompt_style: P_TUNING\n",
      "tensor_model_parallel_size: 1\n",
      "pipeline_model_parallel_size: 1\n",
      "global_batch_size: 64\n",
      "micro_batch_size: 4\n",
      "validation_global_batch_size: ${model.global_batch_size}\n",
      "validation_micro_batch_size: ${model.micro_batch_size}\n",
      "validation_drop_last: false\n",
      "report_validation_metric: false\n",
      "validation_metric: accuracy\n",
      "restore_path: null\n",
      "language_model_path: /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/megatron_gpt_345m.nemo\n",
      "save_nemo_on_validation_end: true\n",
      "existing_tasks: []\n",
      "new_tasks:\n",
      "- chat\n",
      "sequence_parallel: false\n",
      "activations_checkpoint_granularity: null\n",
      "activations_checkpoint_method: null\n",
      "activations_checkpoint_num_layers: null\n",
      "task_templates:\n",
      "- taskname: sentiment\n",
      "  prompt_template: <|VIRTUAL_PROMPT_0|> {sentence} sentiment:{label}\n",
      "  total_virtual_tokens: 10\n",
      "  virtual_token_splits:\n",
      "  - 10\n",
      "  truncate_field: null\n",
      "  answer_only_loss: true\n",
      "  answer_field: label\n",
      "- taskname: chat\n",
      "  prompt_template: <|VIRTUAL_PROMPT_0|> {input} answer:{output}\n",
      "  total_virtual_tokens: 10\n",
      "  virtual_token_splits:\n",
      "  - 10\n",
      "  truncate_field: null\n",
      "  answer_only_loss: true\n",
      "  answer_field: output\n",
      "prompt_tuning:\n",
      "  new_prompt_init_methods:\n",
      "  - text\n",
      "  new_prompt_init_text:\n",
      "  - some init text goes here\n",
      "p_tuning:\n",
      "  encoder_type: mlp\n",
      "  dropout: 0.0\n",
      "  num_layers: 2\n",
      "  encoder_hidden: 2048\n",
      "  init_std: 0.023\n",
      "data:\n",
      "  train_ds:\n",
      "  - /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/data/FinancialPhraseBank-v1.0_split/site-2.jsonl\n",
      "  validation_ds:\n",
      "  - /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/data/FinancialPhraseBank-v1.0/financial_phrase_bank_val.jsonl\n",
      "  add_eos: true\n",
      "  shuffle: true\n",
      "  num_workers: 8\n",
      "  pin_memory: true\n",
      "  train_cache_data_path: null\n",
      "  validation_cache_data_path: null\n",
      "  test_cache_data_path: null\n",
      "  load_cache: false\n",
      "  max_seq_length: 1024\n",
      "  min_seq_length: 1\n",
      "optim:\n",
      "  name: fused_adam\n",
      "  lr: 0.0001\n",
      "  weight_decay: 0.01\n",
      "  betas:\n",
      "  - 0.9\n",
      "  - 0.98\n",
      "  sched:\n",
      "    name: CosineAnnealing\n",
      "    warmup_steps: 50\n",
      "    min_lr: 0.0\n",
      "    constant_steps: 0\n",
      "    monitor: val_loss\n",
      "    reduce_on_plateau: false\n",
      "    max_steps: 11000\n",
      "inference:\n",
      "  greedy: false\n",
      "  top_k: 0\n",
      "  top_p: 0.9\n",
      "  temperature: 1.0\n",
      "  tokens_to_generate: 30\n",
      "  repetition_penalty: 1.2\n",
      "  min_tokens_to_generate: 0\n",
      "precision: 16\n",
      "\n",
      "2023-06-01 18:00:05,332 - PromptLearner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Trainer config - devices: 1\n",
      "accelerator: gpu\n",
      "num_nodes: 1\n",
      "precision: 16\n",
      "logger: true\n",
      "enable_checkpointing: false\n",
      "replace_sampler_ddp: false\n",
      "max_epochs: -1\n",
      "max_steps: -1\n",
      "log_every_n_steps: 10\n",
      "val_check_interval: 1.0\n",
      "gradient_clip_val: 1.0\n",
      "resume_from_checkpoint: null\n",
      "benchmark: false\n",
      "default_root_dir: /tmp/nvflare/nemo/gpt_p-tuning_local_345M/simulate_job/app_site-3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:00:05.269148 140657783011072 communicator.py:200] Received from simulator_server server  (16873468 Bytes). getTask: train time: 0.11282181739807129 seconds\n",
      "I0601 18:00:05.270359 140659256891200 fed_client.py:91] pull_task completed. Task name:train Status:True \n",
      "I0601 18:00:05.270645 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=train, id=42980685-a93e-4664-b2e2-9e89ea7f2802\n",
      "I0601 18:00:05.271328 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: invoking task executor <class 'nemo_nvflare.learner_executor.NemoLearnerExecutor'>\n",
      "I0601 18:00:05.271556 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Client trainer got task: train\n",
      "I0601 18:00:05.271800 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Configuring the Learner...\n",
      "I0601 18:00:05.275068 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Training with global_batch_size 64 and micro_batch_size 4\n",
      "I0601 18:00:05.279564 140659256891200 accelerator_connector.py:758] Using 16bit None Automatic Mixed Precision (AMP)\n",
      "I0601 18:00:05.315083 140659256891200 setup.py:163] GPU available: True (cuda), used: True\n",
      "I0601 18:00:05.315623 140659256891200 setup.py:166] TPU available: False, using: 0 TPU cores\n",
      "I0601 18:00:05.315812 140659256891200 setup.py:169] IPU available: False, using: 0 IPUs\n",
      "I0601 18:00:05.315978 140659256891200 setup.py:172] HPU available: False, using: 0 HPUs\n",
      "I0601 18:00:05.316808 140659256891200 setup.py:121] `Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "I0601 18:00:05.330354 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Model config - seed: 1234\n",
      "nemo_path: /tmp/nvflare/nemo/gpt_p-tuning_local_345M/simulate_job/app_site-3/megatron_gpt_345m_sentiment.nemo\n",
      "virtual_prompt_style: P_TUNING\n",
      "tensor_model_parallel_size: 1\n",
      "pipeline_model_parallel_size: 1\n",
      "global_batch_size: 64\n",
      "micro_batch_size: 4\n",
      "validation_global_batch_size: ${model.global_batch_size}\n",
      "validation_micro_batch_size: ${model.micro_batch_size}\n",
      "validation_drop_last: false\n",
      "report_validation_metric: false\n",
      "validation_metric: accuracy\n",
      "restore_path: null\n",
      "language_model_path: /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/megatron_gpt_345m.nemo\n",
      "save_nemo_on_validation_end: true\n",
      "existing_tasks: []\n",
      "new_tasks:\n",
      "- chat\n",
      "sequence_parallel: false\n",
      "activations_checkpoint_granularity: null\n",
      "activations_checkpoint_method: null\n",
      "activations_checkpoint_num_layers: null\n",
      "task_templates:\n",
      "- taskname: sentiment\n",
      "  prompt_template: <|VIRTUAL_PROMPT_0|> {sentence} sentiment:{label}\n",
      "  total_virtual_tokens: 10\n",
      "  virtual_token_splits:\n",
      "  - 10\n",
      "  truncate_field: null\n",
      "  answer_only_loss: true\n",
      "  answer_field: label\n",
      "- taskname: chat\n",
      "  prompt_template: <|VIRTUAL_PROMPT_0|> {input} answer:{output}\n",
      "  total_virtual_tokens: 10\n",
      "  virtual_token_splits:\n",
      "  - 10\n",
      "  truncate_field: null\n",
      "  answer_only_loss: true\n",
      "  answer_field: output\n",
      "prompt_tuning:\n",
      "  new_prompt_init_methods:\n",
      "  - text\n",
      "  new_prompt_init_text:\n",
      "  - some init text goes here\n",
      "p_tuning:\n",
      "  encoder_type: mlp\n",
      "  dropout: 0.0\n",
      "  num_layers: 2\n",
      "  encoder_hidden: 2048\n",
      "  init_std: 0.023\n",
      "data:\n",
      "  train_ds:\n",
      "  - /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/data/FinancialPhraseBank-v1.0_split/site-2.jsonl\n",
      "  validation_ds:\n",
      "  - /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/data/FinancialPhraseBank-v1.0/financial_phrase_bank_val.jsonl\n",
      "  add_eos: true\n",
      "  shuffle: true\n",
      "  num_workers: 8\n",
      "  pin_memory: true\n",
      "  train_cache_data_path: null\n",
      "  validation_cache_data_path: null\n",
      "  test_cache_data_path: null\n",
      "  load_cache: false\n",
      "  max_seq_length: 1024\n",
      "  min_seq_length: 1\n",
      "optim:\n",
      "  name: fused_adam\n",
      "  lr: 0.0001\n",
      "  weight_decay: 0.01\n",
      "  betas:\n",
      "  - 0.9\n",
      "  - 0.98\n",
      "  sched:\n",
      "    name: CosineAnnealing\n",
      "    warmup_steps: 50\n",
      "    min_lr: 0.0\n",
      "    constant_steps: 0\n",
      "    monitor: val_loss\n",
      "    reduce_on_plateau: false\n",
      "    max_steps: 11000\n",
      "inference:\n",
      "  greedy: false\n",
      "  top_k: 0\n",
      "  top_p: 0.9\n",
      "  temperature: 1.0\n",
      "  tokens_to_generate: 30\n",
      "  repetition_penalty: 1.2\n",
      "  min_tokens_to_generate: 0\n",
      "precision: 16\n",
      "\n",
      "I0601 18:00:05.332788 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Trainer config - devices: 1\n",
      "accelerator: gpu\n",
      "num_nodes: 1\n",
      "precision: 16\n",
      "logger: true\n",
      "enable_checkpointing: false\n",
      "replace_sampler_ddp: false\n",
      "max_epochs: -1\n",
      "max_steps: -1\n",
      "log_every_n_steps: 10\n",
      "val_check_interval: 1.0\n",
      "gradient_clip_val: 1.0\n",
      "resume_from_checkpoint: null\n",
      "benchmark: false\n",
      "default_root_dir: /tmp/nvflare/nemo/gpt_p-tuning_local_345M/simulate_job/app_site-3\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 18:00:05,548 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-2, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: assigned task to client site-2: name=train, id=e277103e-8b4a-4a10-9202-cf52a937c773\n",
      "2023-06-01 18:00:05,550 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-2, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: sent task assignment to client. client_name:site-2 task_id:e277103e-8b4a-4a10-9202-cf52a937c773\n",
      "2023-06-01 18:00:05,594 - GetTaskCommand - INFO - return task to client.  client_name: site-2  task_name: train   task_id: e277103e-8b4a-4a10-9202-cf52a937c773  sharable_header_task_id: e277103e-8b4a-4a10-9202-cf52a937c773\n",
      "2023-06-01 18:00:05,632 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-1, peer_run=simulate_job, task_name=train, task_id=18a4c4ec-0554-46c6-8c61-a85b3b1a3521]: assigned task to client site-1: name=train, id=18a4c4ec-0554-46c6-8c61-a85b3b1a3521\n",
      "2023-06-01 18:00:05,634 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-1, peer_run=simulate_job, task_name=train, task_id=18a4c4ec-0554-46c6-8c61-a85b3b1a3521]: sent task assignment to client. client_name:site-1 task_id:18a4c4ec-0554-46c6-8c61-a85b3b1a3521\n",
      "2023-06-01 18:00:05,681 - GetTaskCommand - INFO - return task to client.  client_name: site-1  task_name: train   task_id: 18a4c4ec-0554-46c6-8c61-a85b3b1a3521  sharable_header_task_id: 18a4c4ec-0554-46c6-8c61-a85b3b1a3521\n",
      "2023-06-01 18:00:05,773 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-1, peer_run=simulate_job]: got result from client site-1 for task: name=train, id=18a4c4ec-0554-46c6-8c61-a85b3b1a3521\n",
      "2023-06-01 18:00:05,775 - ServerRunner - ERROR - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-1, peer_run=simulate_job, peer_rc=EXECUTION_EXCEPTION, task_name=train, task_id=18a4c4ec-0554-46c6-8c61-a85b3b1a3521]: Aborting current RUN due to FATAL_SYSTEM_ERROR received: Result from site-1 is bad, error code: EXECUTION_EXCEPTION. ScatterAndGather exiting at round 0.\n",
      "2023-06-01 18:00:05,777 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-1, peer_run=simulate_job, peer_rc=EXECUTION_EXCEPTION, task_name=train, task_id=18a4c4ec-0554-46c6-8c61-a85b3b1a3521]: asked to abort - triggered abort_signal to stop the RUN\n",
      "2023-06-01 18:00:05,778 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-1, peer_run=simulate_job, peer_rc=EXECUTION_EXCEPTION, task_name=train, task_id=18a4c4ec-0554-46c6-8c61-a85b3b1a3521]: finished processing client result by scatter_and_gather\n",
      "2023-06-01 18:00:05,780 - SubmitUpdateCommand - INFO - submit_update process. client_name:site-1   task_id:18a4c4ec-0554-46c6-8c61-a85b3b1a3521\n",
      "2023-06-01 18:00:05,680 - Communicator - INFO - Received from simulator_server server  (16873468 Bytes). getTask: train time: 0.10965943336486816 seconds\n",
      "2023-06-01 18:00:05,681 - FederatedClient - INFO - pull_task completed. Task name:train Status:True \n",
      "2023-06-01 18:00:05,681 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=train, id=e277103e-8b4a-4a10-9202-cf52a937c773\n",
      "2023-06-01 18:00:05,682 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: invoking task executor <class 'nemo_nvflare.learner_executor.NemoLearnerExecutor'>\n",
      "2023-06-01 18:00:05,682 - NemoLearnerExecutor - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Client trainer got task: train\n",
      "2023-06-01 18:00:05,682 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Configuring the Learner...\n",
      "2023-06-01 18:00:05,685 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Training with global_batch_size 64 and micro_batch_size 4\n",
      "2023-06-01 18:00:05,690 - pytorch_lightning.utilities.rank_zero - INFO - Using 16bit None Automatic Mixed Precision (AMP)\n",
      "2023-06-01 18:00:05,725 - pytorch_lightning.utilities.rank_zero - INFO - GPU available: True (cuda), used: True\n",
      "2023-06-01 18:00:05,726 - pytorch_lightning.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores\n",
      "2023-06-01 18:00:05,726 - pytorch_lightning.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs\n",
      "2023-06-01 18:00:05,726 - pytorch_lightning.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs\n",
      "2023-06-01 18:00:05,727 - pytorch_lightning.utilities.rank_zero - INFO - `Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "2023-06-01 18:00:05,741 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Model config - seed: 1234\n",
      "nemo_path: /tmp/nvflare/nemo/gpt_p-tuning_local_345M/simulate_job/app_site-2/megatron_gpt_345m_sentiment.nemo\n",
      "virtual_prompt_style: P_TUNING\n",
      "tensor_model_parallel_size: 1\n",
      "pipeline_model_parallel_size: 1\n",
      "global_batch_size: 64\n",
      "micro_batch_size: 4\n",
      "validation_global_batch_size: ${model.global_batch_size}\n",
      "validation_micro_batch_size: ${model.micro_batch_size}\n",
      "validation_drop_last: false\n",
      "report_validation_metric: false\n",
      "validation_metric: accuracy\n",
      "restore_path: null\n",
      "language_model_path: /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/megatron_gpt_345m.nemo\n",
      "save_nemo_on_validation_end: true\n",
      "existing_tasks: []\n",
      "new_tasks:\n",
      "- chat\n",
      "sequence_parallel: false\n",
      "activations_checkpoint_granularity: null\n",
      "activations_checkpoint_method: null\n",
      "activations_checkpoint_num_layers: null\n",
      "task_templates:\n",
      "- taskname: sentiment\n",
      "  prompt_template: <|VIRTUAL_PROMPT_0|> {sentence} sentiment:{label}\n",
      "  total_virtual_tokens: 10\n",
      "  virtual_token_splits:\n",
      "  - 10\n",
      "  truncate_field: null\n",
      "  answer_only_loss: true\n",
      "  answer_field: label\n",
      "- taskname: chat\n",
      "  prompt_template: <|VIRTUAL_PROMPT_0|> {input} answer:{output}\n",
      "  total_virtual_tokens: 10\n",
      "  virtual_token_splits:\n",
      "  - 10\n",
      "  truncate_field: null\n",
      "  answer_only_loss: true\n",
      "  answer_field: output\n",
      "prompt_tuning:\n",
      "  new_prompt_init_methods:\n",
      "  - text\n",
      "  new_prompt_init_text:\n",
      "  - some init text goes here\n",
      "p_tuning:\n",
      "  encoder_type: mlp\n",
      "  dropout: 0.0\n",
      "  num_layers: 2\n",
      "  encoder_hidden: 2048\n",
      "  init_std: 0.023\n",
      "data:\n",
      "  train_ds:\n",
      "  - /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/data/FinancialPhraseBank-v1.0_split/site-1.jsonl\n",
      "  validation_ds:\n",
      "  - /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/data/FinancialPhraseBank-v1.0/financial_phrase_bank_val.jsonl\n",
      "  add_eos: true\n",
      "  shuffle: true\n",
      "  num_workers: 8\n",
      "  pin_memory: true\n",
      "  train_cache_data_path: null\n",
      "  validation_cache_data_path: null\n",
      "  test_cache_data_path: null\n",
      "  load_cache: false\n",
      "  max_seq_length: 1024\n",
      "  min_seq_length: 1\n",
      "optim:\n",
      "  name: fused_adam\n",
      "  lr: 0.0001\n",
      "  weight_decay: 0.01\n",
      "  betas:\n",
      "  - 0.9\n",
      "  - 0.98\n",
      "  sched:\n",
      "    name: CosineAnnealing\n",
      "    warmup_steps: 50\n",
      "    min_lr: 0.0\n",
      "    constant_steps: 0\n",
      "    monitor: val_loss\n",
      "    reduce_on_plateau: false\n",
      "    max_steps: 11000\n",
      "inference:\n",
      "  greedy: false\n",
      "  top_k: 0\n",
      "  top_p: 0.9\n",
      "  temperature: 1.0\n",
      "  tokens_to_generate: 30\n",
      "  repetition_penalty: 1.2\n",
      "  min_tokens_to_generate: 0\n",
      "precision: 16\n",
      "\n",
      "[NeMo I 2023-06-01 18:00:05 megatron_init:225] Rank 0 has data parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:00:05 megatron_init:228] All data parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:00:05 megatron_init:229] Ranks 0 has data parallel rank: 0\n",
      "2023-06-01 18:00:05,743 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Trainer config - devices: 1\n",
      "accelerator: gpu\n",
      "num_nodes: 1\n",
      "precision: 16\n",
      "logger: true\n",
      "enable_checkpointing: false\n",
      "replace_sampler_ddp: false\n",
      "max_epochs: -1\n",
      "max_steps: -1\n",
      "log_every_n_steps: 10\n",
      "val_check_interval: 1.0\n",
      "gradient_clip_val: 1.0\n",
      "resume_from_checkpoint: null\n",
      "benchmark: false\n",
      "default_root_dir: /tmp/nvflare/nemo/gpt_p-tuning_local_345M/simulate_job/app_site-2\n",
      "\n",
      "[NeMo I 2023-06-01 18:00:05 megatron_init:237] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:00:05 megatron_init:238] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:00:05 megatron_init:248] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:00:05 megatron_init:252] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:00:05 megatron_init:253] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2023-06-01 18:00:05 megatron_init:267] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:00:05 megatron_init:279] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2023-06-01 18:00:05 megatron_init:285] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:00:05 megatron_init:286] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2023-06-01 18:00:05 megatron_init:287] All embedding group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:00:05 megatron_init:288] Rank 0 has embedding rank: 0\n",
      "2023-06-01 18:00:05,759 - Communicator - INFO - Received from simulator_server server  (16873468 Bytes). getTask: train time: 0.11234784126281738 seconds\n",
      "2023-06-01 18:00:05,760 - FederatedClient - INFO - pull_task completed. Task name:train Status:True \n",
      "2023-06-01 18:00:05,761 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=train, id=18a4c4ec-0554-46c6-8c61-a85b3b1a3521\n",
      "2023-06-01 18:00:05,761 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=18a4c4ec-0554-46c6-8c61-a85b3b1a3521]: invoking task executor <class 'nemo_nvflare.learner_executor.NemoLearnerExecutor'>\n",
      "2023-06-01 18:00:05,761 - NemoLearnerExecutor - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=18a4c4ec-0554-46c6-8c61-a85b3b1a3521]: Client trainer got task: train\n",
      "2023-06-01 18:00:05,762 - PromptLearner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=18a4c4ec-0554-46c6-8c61-a85b3b1a3521]: Configuring the Learner...\n",
      "2023-06-01 18:00:05,763 - NemoLearnerExecutor - ERROR - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=18a4c4ec-0554-46c6-8c61-a85b3b1a3521]: learner execute exception: No such file /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/data/FinancialPhraseBank-v1.0_split/site-0.jsonl!\n",
      "2023-06-01 18:00:05,769 - NemoLearnerExecutor - ERROR - Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/nvflare/app_common/executors/learner_executor.py\", line 77, in execute\n",
      "    return self.train(shareable, fl_ctx, abort_signal)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/nvflare/app_common/executors/learner_executor.py\", line 94, in train\n",
      "    validate_result: Shareable = self.learner.validate(shareable, fl_ctx, abort_signal)\n",
      "  File \"/workspace/Code/nvflare/nemo_nvflare/integration/nemo/nemo_nvflare/prompt_learner.py\", line 342, in validate\n",
      "    self._configure(fl_ctx)\n",
      "  File \"/workspace/Code/nvflare/nemo_nvflare/integration/nemo/nemo_nvflare/prompt_learner.py\", line 231, in _configure\n",
      "    self.config.model.data.train_ds = set_datafile_paths(self.train_ds_files, self.app_root)\n",
      "  File \"/workspace/Code/nvflare/nemo_nvflare/integration/nemo/nemo_nvflare/prompt_learner.py\", line 51, in set_datafile_paths\n",
      "    raise ValueError(f\"No such file {f}!\")\n",
      "ValueError: No such file /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/data/FinancialPhraseBank-v1.0_split/site-0.jsonl!\n",
      "\n",
      "2023-06-01 18:00:05,769 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=18a4c4ec-0554-46c6-8c61-a85b3b1a3521]: finished processing task\n",
      "2023-06-01 18:00:05,771 - FederatedClient - INFO - Starting to push execute result.\n",
      "2023-06-01 18:00:05,782 - Communicator - INFO -  SubmitUpdate size: 513 Bytes. time: 0.011070728302001953 seconds\n",
      "2023-06-01 18:00:05,783 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=18a4c4ec-0554-46c6-8c61-a85b3b1a3521]: result sent to server for task: name=train, id=18a4c4ec-0554-46c6-8c61-a85b3b1a3521\n",
      "2023-06-01 18:00:05,783 - ClientTaskWorker - INFO - Finished one task run for client: site-1 interval: 2 task_processed: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:00:05.680258 140711777445632 communicator.py:200] Received from simulator_server server  (16873468 Bytes). getTask: train time: 0.10965943336486816 seconds\n",
      "I0601 18:00:05.681457 140713251325760 fed_client.py:91] pull_task completed. Task name:train Status:True \n",
      "I0601 18:00:05.681739 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=train, id=e277103e-8b4a-4a10-9202-cf52a937c773\n",
      "I0601 18:00:05.682413 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: invoking task executor <class 'nemo_nvflare.learner_executor.NemoLearnerExecutor'>\n",
      "I0601 18:00:05.682653 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Client trainer got task: train\n",
      "I0601 18:00:05.682909 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Configuring the Learner...\n",
      "I0601 18:00:05.685759 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Training with global_batch_size 64 and micro_batch_size 4\n",
      "I0601 18:00:05.690311 140713251325760 accelerator_connector.py:758] Using 16bit None Automatic Mixed Precision (AMP)\n",
      "I0601 18:00:05.725998 140713251325760 setup.py:163] GPU available: True (cuda), used: True\n",
      "I0601 18:00:05.726551 140713251325760 setup.py:166] TPU available: False, using: 0 TPU cores\n",
      "I0601 18:00:05.726742 140713251325760 setup.py:169] IPU available: False, using: 0 IPUs\n",
      "I0601 18:00:05.726904 140713251325760 setup.py:172] HPU available: False, using: 0 HPUs\n",
      "I0601 18:00:05.727766 140713251325760 setup.py:121] `Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "I0601 18:00:05.741422 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Model config - seed: 1234\n",
      "nemo_path: /tmp/nvflare/nemo/gpt_p-tuning_local_345M/simulate_job/app_site-2/megatron_gpt_345m_sentiment.nemo\n",
      "virtual_prompt_style: P_TUNING\n",
      "tensor_model_parallel_size: 1\n",
      "pipeline_model_parallel_size: 1\n",
      "global_batch_size: 64\n",
      "micro_batch_size: 4\n",
      "validation_global_batch_size: ${model.global_batch_size}\n",
      "validation_micro_batch_size: ${model.micro_batch_size}\n",
      "validation_drop_last: false\n",
      "report_validation_metric: false\n",
      "validation_metric: accuracy\n",
      "restore_path: null\n",
      "language_model_path: /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/megatron_gpt_345m.nemo\n",
      "save_nemo_on_validation_end: true\n",
      "existing_tasks: []\n",
      "new_tasks:\n",
      "- chat\n",
      "sequence_parallel: false\n",
      "activations_checkpoint_granularity: null\n",
      "activations_checkpoint_method: null\n",
      "activations_checkpoint_num_layers: null\n",
      "task_templates:\n",
      "- taskname: sentiment\n",
      "  prompt_template: <|VIRTUAL_PROMPT_0|> {sentence} sentiment:{label}\n",
      "  total_virtual_tokens: 10\n",
      "  virtual_token_splits:\n",
      "  - 10\n",
      "  truncate_field: null\n",
      "  answer_only_loss: true\n",
      "  answer_field: label\n",
      "- taskname: chat\n",
      "  prompt_template: <|VIRTUAL_PROMPT_0|> {input} answer:{output}\n",
      "  total_virtual_tokens: 10\n",
      "  virtual_token_splits:\n",
      "  - 10\n",
      "  truncate_field: null\n",
      "  answer_only_loss: true\n",
      "  answer_field: output\n",
      "prompt_tuning:\n",
      "  new_prompt_init_methods:\n",
      "  - text\n",
      "  new_prompt_init_text:\n",
      "  - some init text goes here\n",
      "p_tuning:\n",
      "  encoder_type: mlp\n",
      "  dropout: 0.0\n",
      "  num_layers: 2\n",
      "  encoder_hidden: 2048\n",
      "  init_std: 0.023\n",
      "data:\n",
      "  train_ds:\n",
      "  - /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/data/FinancialPhraseBank-v1.0_split/site-1.jsonl\n",
      "  validation_ds:\n",
      "  - /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/data/FinancialPhraseBank-v1.0/financial_phrase_bank_val.jsonl\n",
      "  add_eos: true\n",
      "  shuffle: true\n",
      "  num_workers: 8\n",
      "  pin_memory: true\n",
      "  train_cache_data_path: null\n",
      "  validation_cache_data_path: null\n",
      "  test_cache_data_path: null\n",
      "  load_cache: false\n",
      "  max_seq_length: 1024\n",
      "  min_seq_length: 1\n",
      "optim:\n",
      "  name: fused_adam\n",
      "  lr: 0.0001\n",
      "  weight_decay: 0.01\n",
      "  betas:\n",
      "  - 0.9\n",
      "  - 0.98\n",
      "  sched:\n",
      "    name: CosineAnnealing\n",
      "    warmup_steps: 50\n",
      "    min_lr: 0.0\n",
      "    constant_steps: 0\n",
      "    monitor: val_loss\n",
      "    reduce_on_plateau: false\n",
      "    max_steps: 11000\n",
      "inference:\n",
      "  greedy: false\n",
      "  top_k: 0\n",
      "  top_p: 0.9\n",
      "  temperature: 1.0\n",
      "  tokens_to_generate: 30\n",
      "  repetition_penalty: 1.2\n",
      "  min_tokens_to_generate: 0\n",
      "precision: 16\n",
      "\n",
      "I0601 18:00:05.743874 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Trainer config - devices: 1\n",
      "accelerator: gpu\n",
      "num_nodes: 1\n",
      "precision: 16\n",
      "logger: true\n",
      "enable_checkpointing: false\n",
      "replace_sampler_ddp: false\n",
      "max_epochs: -1\n",
      "max_steps: -1\n",
      "log_every_n_steps: 10\n",
      "val_check_interval: 1.0\n",
      "gradient_clip_val: 1.0\n",
      "resume_from_checkpoint: null\n",
      "benchmark: false\n",
      "default_root_dir: /tmp/nvflare/nemo/gpt_p-tuning_local_345M/simulate_job/app_site-2\n",
      "\n",
      "23-06-01 18:00:05 - PID:2482 - rank:(0, 0, 0, 0) - microbatches.py:39 - INFO - setting number of micro-batches to constant 16\n",
      "I0601 18:00:05.759565 140670335465216 communicator.py:200] Received from simulator_server server  (16873468 Bytes). getTask: train time: 0.11234784126281738 seconds\n",
      "I0601 18:00:05.760789 140671809345344 fed_client.py:91] pull_task completed. Task name:train Status:True \n",
      "I0601 18:00:05.761059 140671809345344 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=train, id=18a4c4ec-0554-46c6-8c61-a85b3b1a3521\n",
      "I0601 18:00:05.761697 140671809345344 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=18a4c4ec-0554-46c6-8c61-a85b3b1a3521]: invoking task executor <class 'nemo_nvflare.learner_executor.NemoLearnerExecutor'>\n",
      "I0601 18:00:05.761934 140671809345344 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=18a4c4ec-0554-46c6-8c61-a85b3b1a3521]: Client trainer got task: train\n",
      "I0601 18:00:05.762196 140671809345344 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=18a4c4ec-0554-46c6-8c61-a85b3b1a3521]: Configuring the Learner...\n",
      "E0601 18:00:05.763789 140671809345344 fl_component.py:216] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=18a4c4ec-0554-46c6-8c61-a85b3b1a3521]: learner execute exception: No such file /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/data/FinancialPhraseBank-v1.0_split/site-0.jsonl!\n",
      "E0601 18:00:05.769187 140671809345344 fl_component.py:218] Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/nvflare/app_common/executors/learner_executor.py\", line 77, in execute\n",
      "    return self.train(shareable, fl_ctx, abort_signal)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/nvflare/app_common/executors/learner_executor.py\", line 94, in train\n",
      "    validate_result: Shareable = self.learner.validate(shareable, fl_ctx, abort_signal)\n",
      "  File \"/workspace/Code/nvflare/nemo_nvflare/integration/nemo/nemo_nvflare/prompt_learner.py\", line 342, in validate\n",
      "    self._configure(fl_ctx)\n",
      "  File \"/workspace/Code/nvflare/nemo_nvflare/integration/nemo/nemo_nvflare/prompt_learner.py\", line 231, in _configure\n",
      "    self.config.model.data.train_ds = set_datafile_paths(self.train_ds_files, self.app_root)\n",
      "  File \"/workspace/Code/nvflare/nemo_nvflare/integration/nemo/nemo_nvflare/prompt_learner.py\", line 51, in set_datafile_paths\n",
      "    raise ValueError(f\"No such file {f}!\")\n",
      "ValueError: No such file /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/data/FinancialPhraseBank-v1.0_split/site-0.jsonl!\n",
      "\n",
      "I0601 18:00:05.769827 140671809345344 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=18a4c4ec-0554-46c6-8c61-a85b3b1a3521]: finished processing task\n",
      "I0601 18:00:05.771257 140670536800000 fed_client_base.py:296] Starting to push execute result.\n",
      "I0601 18:00:05.782540 140670536800000 communicator.py:268]  SubmitUpdate size: 513 Bytes. time: 0.011070728302001953 seconds\n",
      "I0601 18:00:05.783432 140671809345344 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=18a4c4ec-0554-46c6-8c61-a85b3b1a3521]: result sent to server for task: name=train, id=18a4c4ec-0554-46c6-8c61-a85b3b1a3521\n",
      "I0601 18:00:05.783787 140671809345344 simulator_worker.py:94] Finished one task run for client: site-1 interval: 2 task_processed: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 18:00:05,929 - ScatterAndGather - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: Abort signal received. Exiting at round 0.\n",
      "2023-06-01 18:00:05,931 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: Workflow: scatter_and_gather finalizing ...\n",
      "[NeMo I 2023-06-01 18:00:06 megatron_init:225] Rank 0 has data parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:00:06 megatron_init:228] All data parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:00:06 megatron_init:229] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2023-06-01 18:00:06 megatron_init:237] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:00:06 megatron_init:238] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:00:06 megatron_init:248] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:00:06 megatron_init:252] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:00:06 megatron_init:253] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2023-06-01 18:00:06 megatron_init:267] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:00:06 megatron_init:279] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2023-06-01 18:00:06 megatron_init:285] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:00:06 megatron_init:286] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2023-06-01 18:00:06 megatron_init:287] All embedding group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:00:06 megatron_init:288] Rank 0 has embedding rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23-06-01 18:00:06 - PID:2481 - rank:(0, 0, 0, 0) - microbatches.py:39 - INFO - setting number of micro-batches to constant 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 18:00:06,426 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: ABOUT_TO_END_RUN fired\n",
      "2023-06-01 18:00:06,427 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: END_RUN fired\n",
      "2023-06-01 18:00:06,429 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: Server runner finished.\n",
      "2023-06-01 18:00:07,789 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-1, peer_run=simulate_job]: server runner is finalizing - asked client to end the run\n",
      "2023-06-01 18:00:07,801 - GetTaskCommand - INFO - return task to client.  client_name: site-1  task_name: __end_run__   task_id:   sharable_header_task_id: \n",
      "2023-06-01 18:00:07,807 - FederatedClient - INFO - pull_task completed. Task name:__end_run__ Status:True \n",
      "2023-06-01 18:00:07,807 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: server asked to end the run\n",
      "2023-06-01 18:00:07,807 - ClientTaskWorker - INFO - End the Simulator run.\n",
      "2023-06-01 18:00:07,808 - ClientTaskWorker - INFO - Clean up ClientRunner for : site-1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:00:07.807184 140671809345344 fed_client.py:91] pull_task completed. Task name:__end_run__ Status:True \n",
      "I0601 18:00:07.807564 140671809345344 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: server asked to end the run\n",
      "I0601 18:00:07.807730 140671809345344 simulator_worker.py:102] End the Simulator run.\n",
      "I0601 18:00:07.808275 140671809345344 simulator_worker.py:125] Clean up ClientRunner for : site-1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 18:00:08,361 - SimulatorServer - INFO - Server app stopped.\n",
      "\n",
      "\n",
      "2023-06-01 18:00:08,607 - nvflare.fuel.hci.server.hci - INFO - Admin Server localhost on Port 55737 shutdown!\n",
      "2023-06-01 18:00:10,132 - SimulatorServer - INFO - shutting down server\n",
      "2023-06-01 18:00:10,135 - SimulatorServer - INFO - canceling sync locks\n",
      "2023-06-01 18:00:10,136 - SimulatorServer - INFO - server off\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:225] Rank 0 has data parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:228] All data parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:229] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:237] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:238] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:248] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:252] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:253] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:267] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:279] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:285] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:286] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:287] All embedding group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:288] Rank 0 has embedding rank: 0\n",
      "[NeMo I 2023-06-01 18:00:32 tokenizer_utils:204] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: /tmp/tmp83exrfyo/bfcdca5e44814366bdb5dcd651325152_gpt2-vocab.json, and merges file: /tmp/tmp83exrfyo/315a11fd68be49d6abdb34363e8c4997_gpt2-merge.txt\n",
      "[NeMo I 2023-06-01 18:00:32 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /tmp/tmp83exrfyo/bfcdca5e44814366bdb5dcd651325152_gpt2-vocab.json, merges_files: /tmp/tmp83exrfyo/315a11fd68be49d6abdb34363e8c4997_gpt2-merge.txt, special_tokens_dict: {}, and use_fast: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-06-01 18:00:32 modelPT:245] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-01 18:00:32 megatron_init:225] Rank 0 has data parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:228] All data parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:229] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:237] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:238] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:248] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:252] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:253] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:267] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:279] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:285] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:286] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:287] All embedding group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:00:32 megatron_init:288] Rank 0 has embedding rank: 0\n",
      "[NeMo I 2023-06-01 18:00:32 tokenizer_utils:204] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: /tmp/tmpawp0ymg5/bfcdca5e44814366bdb5dcd651325152_gpt2-vocab.json, and merges file: /tmp/tmpawp0ymg5/315a11fd68be49d6abdb34363e8c4997_gpt2-merge.txt\n",
      "[NeMo I 2023-06-01 18:00:32 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /tmp/tmpawp0ymg5/bfcdca5e44814366bdb5dcd651325152_gpt2-vocab.json, merges_files: /tmp/tmpawp0ymg5/315a11fd68be49d6abdb34363e8c4997_gpt2-merge.txt, special_tokens_dict: {}, and use_fast: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-06-01 18:00:32 modelPT:245] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 665/665 [00:00<00:00, 133kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 4.19MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 843kB/s]Using sep_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using pad_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-01 18:00:36 megatron_base_model:205] Padded vocab_size: 50304, original vocab_size: 50257, dummy tokens: 47.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Using sep_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using pad_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-01 18:00:36 megatron_base_model:205] Padded vocab_size: 50304, original vocab_size: 50257, dummy tokens: 47.\n",
      "[NeMo I 2023-06-01 18:00:38 nlp_overrides:374] Model MegatronGPTModel was successfully restored from /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/megatron_gpt_345m.nemo.\n",
      "[NeMo I 2023-06-01 18:00:38 auto_tokenizer:172] 10 special tokens added, resize your model accordingly.\n",
      "[NeMo I 2023-06-01 18:00:38 nlp_overrides:374] Model MegatronGPTModel was successfully restored from /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/megatron_gpt_345m.nemo.\n",
      "[NeMo I 2023-06-01 18:00:38 auto_tokenizer:172] 10 special tokens added, resize your model accordingly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n",
      "Using pad_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-01 18:01:10 megatron_init:225] Rank 0 has data parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:01:10 megatron_init:228] All data parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:01:10 megatron_init:229] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2023-06-01 18:01:10 megatron_init:237] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:01:10 megatron_init:238] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:01:10 megatron_init:248] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:01:10 megatron_init:252] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:01:10 megatron_init:253] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2023-06-01 18:01:10 megatron_init:267] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:01:10 megatron_init:279] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2023-06-01 18:01:10 megatron_init:285] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:01:10 megatron_init:286] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2023-06-01 18:01:10 megatron_init:287] All embedding group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:01:10 megatron_init:288] Rank 0 has embedding rank: 0\n",
      "[NeMo I 2023-06-01 18:01:10 tokenizer_utils:204] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: /tmp/tmp9ez_lqt2/bfcdca5e44814366bdb5dcd651325152_gpt2-vocab.json, and merges file: /tmp/tmp9ez_lqt2/315a11fd68be49d6abdb34363e8c4997_gpt2-merge.txt\n",
      "[NeMo I 2023-06-01 18:01:10 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /tmp/tmp9ez_lqt2/bfcdca5e44814366bdb5dcd651325152_gpt2-vocab.json, merges_files: /tmp/tmp9ez_lqt2/315a11fd68be49d6abdb34363e8c4997_gpt2-merge.txt, special_tokens_dict: {}, and use_fast: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-06-01 18:01:10 modelPT:245] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-01 18:01:11 megatron_init:225] Rank 0 has data parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:01:11 megatron_init:228] All data parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:01:11 megatron_init:229] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2023-06-01 18:01:11 megatron_init:237] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:01:11 megatron_init:238] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:01:11 megatron_init:248] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:01:11 megatron_init:252] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:01:11 megatron_init:253] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2023-06-01 18:01:11 megatron_init:267] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:01:11 megatron_init:279] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2023-06-01 18:01:11 megatron_init:285] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:01:11 megatron_init:286] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2023-06-01 18:01:11 megatron_init:287] All embedding group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:01:11 megatron_init:288] Rank 0 has embedding rank: 0\n",
      "[NeMo I 2023-06-01 18:01:11 tokenizer_utils:204] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: /tmp/tmp7lv4nex7/bfcdca5e44814366bdb5dcd651325152_gpt2-vocab.json, and merges file: /tmp/tmp7lv4nex7/315a11fd68be49d6abdb34363e8c4997_gpt2-merge.txt\n",
      "[NeMo I 2023-06-01 18:01:11 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /tmp/tmp7lv4nex7/bfcdca5e44814366bdb5dcd651325152_gpt2-vocab.json, merges_files: /tmp/tmp7lv4nex7/315a11fd68be49d6abdb34363e8c4997_gpt2-merge.txt, special_tokens_dict: {}, and use_fast: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-06-01 18:01:11 modelPT:245] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
      "Using sep_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using pad_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-01 18:01:12 megatron_base_model:205] Padded vocab_size: 50304, original vocab_size: 50257, dummy tokens: 47.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using pad_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-01 18:01:12 megatron_base_model:205] Padded vocab_size: 50304, original vocab_size: 50257, dummy tokens: 47.\n",
      "[NeMo I 2023-06-01 18:01:13 nlp_overrides:374] Model MegatronGPTModel was successfully restored from /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/megatron_gpt_345m.nemo.\n",
      "[NeMo I 2023-06-01 18:01:13 auto_tokenizer:172] 10 special tokens added, resize your model accordingly.\n",
      "2023-06-01 18:01:13,927 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Initialized model <class 'nemo_nvflare.fed_megatron_gpt_prompt_learning_model.FedMegatronGPTPromptLearningModel'> and prompt encoder <class 'nemo.collections.nlp.modules.common.prompt_encoder.PromptEncoder'>\n",
      "2023-06-01 18:01:13,938 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Loaded 7 of 7 weights\n",
      "2023-06-01 18:01:13,945 - lightning_fabric.utilities.distributed - INFO - Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "2023-06-01 18:01:13,950 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "2023-06-01 18:01:13,950 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
      "2023-06-01 18:01:13,950 - pytorch_lightning.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "2023-06-01 18:01:13,952 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "2023-06-01 18:01:13,953 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
      "2023-06-01 18:01:13,954 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:3 to store for rank: 0\n",
      "2023-06-01 18:01:13,954 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:3 with 1 nodes.\n",
      "2023-06-01 18:01:13,956 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:4 to store for rank: 0\n",
      "2023-06-01 18:01:13,956 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:4 with 1 nodes.\n",
      "2023-06-01 18:01:13,957 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:5 to store for rank: 0\n",
      "2023-06-01 18:01:13,958 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:5 with 1 nodes.\n",
      "2023-06-01 18:01:13,959 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:6 to store for rank: 0\n",
      "2023-06-01 18:01:13,960 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:6 with 1 nodes.\n",
      "2023-06-01 18:01:13,961 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:7 to store for rank: 0\n",
      "2023-06-01 18:01:13,962 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:7 with 1 nodes.\n",
      "2023-06-01 18:01:13,963 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:8 to store for rank: 0\n",
      "2023-06-01 18:01:13,963 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:8 with 1 nodes.\n",
      "2023-06-01 18:01:13,965 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:9 to store for rank: 0\n",
      "2023-06-01 18:01:13,965 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:9 with 1 nodes.\n",
      "2023-06-01 18:01:13,966 - pytorch_lightning.loggers.tensorboard - WARNING - Missing logger folder: /tmp/nvflare/nemo/gpt_p-tuning_local_345M/simulate_job/app_site-2/lightning_logs\n",
      "[NeMo I 2023-06-01 18:01:13 nlp_overrides:374] Model MegatronGPTModel was successfully restored from /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/megatron_gpt_345m.nemo.\n",
      "[NeMo I 2023-06-01 18:01:14 auto_tokenizer:172] 10 special tokens added, resize your model accordingly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n",
      "I0601 18:01:13.927469 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Initialized model <class 'nemo_nvflare.fed_megatron_gpt_prompt_learning_model.FedMegatronGPTPromptLearningModel'> and prompt encoder <class 'nemo.collections.nlp.modules.common.prompt_encoder.PromptEncoder'>\n",
      "I0601 18:01:13.938830 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Loaded 7 of 7 weights\n",
      "I0601 18:01:13.945666 140713251325760 distributed.py:244] Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "I0601 18:01:13.950233 140713251325760 distributed_c10d.py:393] Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "I0601 18:01:13.950562 140713251325760 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
      "I0601 18:01:13.950893 140713251325760 distributed.py:248] ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "I0601 18:01:13.952943 140713251325760 distributed_c10d.py:393] Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "I0601 18:01:13.953239 140713251325760 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
      "I0601 18:01:13.954531 140713251325760 distributed_c10d.py:393] Added key: store_based_barrier_key:3 to store for rank: 0\n",
      "I0601 18:01:13.954822 140713251325760 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:3 with 1 nodes.\n",
      "I0601 18:01:13.956051 140713251325760 distributed_c10d.py:393] Added key: store_based_barrier_key:4 to store for rank: 0\n",
      "I0601 18:01:13.956351 140713251325760 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:4 with 1 nodes.\n",
      "I0601 18:01:13.957773 140713251325760 distributed_c10d.py:393] Added key: store_based_barrier_key:5 to store for rank: 0\n",
      "I0601 18:01:13.958206 140713251325760 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:5 with 1 nodes.\n",
      "I0601 18:01:13.959816 140713251325760 distributed_c10d.py:393] Added key: store_based_barrier_key:6 to store for rank: 0\n",
      "I0601 18:01:13.960155 140713251325760 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:6 with 1 nodes.\n",
      "I0601 18:01:13.961617 140713251325760 distributed_c10d.py:393] Added key: store_based_barrier_key:7 to store for rank: 0\n",
      "I0601 18:01:13.962038 140713251325760 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:7 with 1 nodes.\n",
      "I0601 18:01:13.963584 140713251325760 distributed_c10d.py:393] Added key: store_based_barrier_key:8 to store for rank: 0\n",
      "I0601 18:01:13.963921 140713251325760 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:8 with 1 nodes.\n",
      "I0601 18:01:13.965072 140713251325760 distributed_c10d.py:393] Added key: store_based_barrier_key:9 to store for rank: 0\n",
      "I0601 18:01:13.965359 140713251325760 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:9 with 1 nodes.\n",
      "W0601 18:01:13.966121 140713251325760 tensorboard.py:237] Missing logger folder: /tmp/nvflare/nemo/gpt_p-tuning_local_345M/simulate_job/app_site-2/lightning_logs\n",
      "Using pad_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 18:01:14,077 - PromptLearner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Initialized model <class 'nemo_nvflare.fed_megatron_gpt_prompt_learning_model.FedMegatronGPTPromptLearningModel'> and prompt encoder <class 'nemo.collections.nlp.modules.common.prompt_encoder.PromptEncoder'>\n",
      "2023-06-01 18:01:14,087 - PromptLearner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Loaded 7 of 7 weights\n",
      "2023-06-01 18:01:14,092 - lightning_fabric.utilities.distributed - INFO - Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "2023-06-01 18:01:14,095 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "2023-06-01 18:01:14,095 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
      "2023-06-01 18:01:14,096 - pytorch_lightning.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "2023-06-01 18:01:14,098 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "2023-06-01 18:01:14,098 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
      "2023-06-01 18:01:14,099 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:3 to store for rank: 0\n",
      "2023-06-01 18:01:14,099 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:3 with 1 nodes.\n",
      "2023-06-01 18:01:14,100 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:4 to store for rank: 0\n",
      "2023-06-01 18:01:14,100 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:4 with 1 nodes.\n",
      "2023-06-01 18:01:14,102 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:5 to store for rank: 0\n",
      "2023-06-01 18:01:14,102 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:5 with 1 nodes.\n",
      "2023-06-01 18:01:14,103 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:6 to store for rank: 0\n",
      "2023-06-01 18:01:14,103 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:6 with 1 nodes.\n",
      "2023-06-01 18:01:14,104 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:7 to store for rank: 0\n",
      "2023-06-01 18:01:14,104 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:7 with 1 nodes.\n",
      "2023-06-01 18:01:14,105 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:8 to store for rank: 0\n",
      "2023-06-01 18:01:14,106 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:8 with 1 nodes.\n",
      "2023-06-01 18:01:14,107 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:9 to store for rank: 0\n",
      "2023-06-01 18:01:14,107 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:9 with 1 nodes.\n",
      "2023-06-01 18:01:14,108 - pytorch_lightning.loggers.tensorboard - WARNING - Missing logger folder: /tmp/nvflare/nemo/gpt_p-tuning_local_345M/simulate_job/app_site-3/lightning_logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:01:14.077955 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Initialized model <class 'nemo_nvflare.fed_megatron_gpt_prompt_learning_model.FedMegatronGPTPromptLearningModel'> and prompt encoder <class 'nemo.collections.nlp.modules.common.prompt_encoder.PromptEncoder'>\n",
      "I0601 18:01:14.087286 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Loaded 7 of 7 weights\n",
      "I0601 18:01:14.092693 140659256891200 distributed.py:244] Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "I0601 18:01:14.095425 140659256891200 distributed_c10d.py:393] Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "I0601 18:01:14.095743 140659256891200 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
      "I0601 18:01:14.096036 140659256891200 distributed.py:248] ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "I0601 18:01:14.098060 140659256891200 distributed_c10d.py:393] Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "I0601 18:01:14.098347 140659256891200 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
      "I0601 18:01:14.099405 140659256891200 distributed_c10d.py:393] Added key: store_based_barrier_key:3 to store for rank: 0\n",
      "I0601 18:01:14.099666 140659256891200 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:3 with 1 nodes.\n",
      "I0601 18:01:14.100740 140659256891200 distributed_c10d.py:393] Added key: store_based_barrier_key:4 to store for rank: 0\n",
      "I0601 18:01:14.100994 140659256891200 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:4 with 1 nodes.\n",
      "I0601 18:01:14.102067 140659256891200 distributed_c10d.py:393] Added key: store_based_barrier_key:5 to store for rank: 0\n",
      "I0601 18:01:14.102343 140659256891200 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:5 with 1 nodes.\n",
      "I0601 18:01:14.103407 140659256891200 distributed_c10d.py:393] Added key: store_based_barrier_key:6 to store for rank: 0\n",
      "I0601 18:01:14.103658 140659256891200 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:6 with 1 nodes.\n",
      "I0601 18:01:14.104683 140659256891200 distributed_c10d.py:393] Added key: store_based_barrier_key:7 to store for rank: 0\n",
      "I0601 18:01:14.104933 140659256891200 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:7 with 1 nodes.\n",
      "I0601 18:01:14.105987 140659256891200 distributed_c10d.py:393] Added key: store_based_barrier_key:8 to store for rank: 0\n",
      "I0601 18:01:14.106286 140659256891200 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:8 with 1 nodes.\n",
      "I0601 18:01:14.107360 140659256891200 distributed_c10d.py:393] Added key: store_based_barrier_key:9 to store for rank: 0\n",
      "I0601 18:01:14.107622 140659256891200 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:9 with 1 nodes.\n",
      "W0601 18:01:14.108319 140659256891200 tensorboard.py:237] Missing logger folder: /tmp/nvflare/nemo/gpt_p-tuning_local_345M/simulate_job/app_site-3/lightning_logs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-01 18:01:15 gpt_prompt_learning_dataset:85] Loading and tokenizing dataset ... \n",
      "[NeMo I 2023-06-01 18:01:15 gpt_prompt_learning_dataset:85] Loading and tokenizing dataset ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "604it [00:00, 818.55it/s]\n",
      "604it [00:00, 793.51it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-01 18:01:16 gpt_prompt_learning_dataset:196] Skipped 0 sentences, sequence length too short or too long even after truncation\n",
      "[NeMo I 2023-06-01 18:01:16 gpt_prompt_learning_dataset:85] Loading and tokenizing dataset ... \n",
      "[NeMo I 2023-06-01 18:01:16 gpt_prompt_learning_dataset:196] Skipped 0 sentences, sequence length too short or too long even after truncation\n",
      "[NeMo I 2023-06-01 18:01:16 gpt_prompt_learning_dataset:85] Loading and tokenizing dataset ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "226it [00:00, 890.19it/s]\n",
      "I0601 18:01:16.408701 140659256891200 cuda.py:58] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "226it [00:00, 902.85it/s]\n",
      "I0601 18:01:16.450244 140713251325760 cuda.py:58] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-01 18:01:16 gpt_prompt_learning_dataset:196] Skipped 0 sentences, sequence length too short or too long even after truncation\n",
      "2023-06-01 18:01:16,408 - pytorch_lightning.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[NeMo I 2023-06-01 18:01:16 gpt_prompt_learning_dataset:196] Skipped 0 sentences, sequence length too short or too long even after truncation\n",
      "2023-06-01 18:01:16,450 - pytorch_lightning.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Validation: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-06-01 18:01:16 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel/utils.py:81: UserWarning: This function is only for unittest\n",
      "      warnings.warn(\"This function is only for unittest\")\n",
      "    \n",
      "[NeMo W 2023-06-01 18:01:16 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel/utils.py:81: UserWarning: This function is only for unittest\n",
      "      warnings.warn(\"This function is only for unittest\")\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 4/4 [00:06<00:00,  1.64s/it]2023-06-01 18:01:24,199 - root - INFO - global_model_val_loss: 6.832405090332031\n",
      "Validation DataLoader 0: 100%|██████████| 4/4 [00:06<00:00,  1.64s/it]2023-06-01 18:01:24,207 - root - INFO - global_model_val_loss: 6.832405090332031\n",
      "\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│\u001b[36m \u001b[0m\u001b[36m  global_model_val_loss  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    6.832405090332031    \u001b[0m\u001b[35m \u001b[0m│\n",
      "└───────────────────────────┴───────────────────────────┘\n",
      "Validation DataLoader 0: 100%|██████████| 4/4 [00:06<00:00,  1.64s/it]\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│\u001b[36m \u001b[0m\u001b[36m  global_model_val_loss  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    6.832405090332031    \u001b[0m\u001b[35m \u001b[0m│\n",
      "└───────────────────────────┴───────────────────────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:01:24.199280 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] global_model_val_loss: 6.832405090332031\n",
      "I0601 18:01:24.207840 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] global_model_val_loss: 6.832405090332031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 18:01:24,752 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Global_model global_model_val_loss: 6.832405090332031\n",
      "2023-06-01 18:01:24,753 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Current/Total Round: 1/1\n",
      "2023-06-01 18:01:24,753 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Client identity: site-2\n",
      "2023-06-01 18:01:24,767 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Loaded 7 of 7 weights\n",
      "2023-06-01 18:01:24,767 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Start training in round 0\n",
      "2023-06-01 18:01:24,772 - pytorch_lightning.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "2023-06-01 18:01:24,789 - PromptLearner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Global_model global_model_val_loss: 6.832405090332031\n",
      "2023-06-01 18:01:24,791 - PromptLearner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Current/Total Round: 1/1\n",
      "2023-06-01 18:01:24,791 - PromptLearner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Client identity: site-3\n",
      "2023-06-01 18:01:24,806 - PromptLearner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Loaded 7 of 7 weights\n",
      "2023-06-01 18:01:24,806 - PromptLearner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Start training in round 0\n",
      "2023-06-01 18:01:24,812 - pytorch_lightning.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:01:24.752224 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Global_model global_model_val_loss: 6.832405090332031\n",
      "I0601 18:01:24.753607 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Current/Total Round: 1/1\n",
      "I0601 18:01:24.753800 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Client identity: site-2\n",
      "I0601 18:01:24.767098 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Loaded 7 of 7 weights\n",
      "I0601 18:01:24.767334 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Start training in round 0\n",
      "I0601 18:01:24.772452 140713251325760 cuda.py:58] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "I0601 18:01:24.789638 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Global_model global_model_val_loss: 6.832405090332031\n",
      "I0601 18:01:24.791022 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Current/Total Round: 1/1\n",
      "I0601 18:01:24.791221 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Client identity: site-3\n",
      "I0601 18:01:24.806621 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Loaded 7 of 7 weights\n",
      "I0601 18:01:24.806901 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Start training in round 0\n",
      "I0601 18:01:24.812609 140659256891200 cuda.py:58] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-01 18:01:24 nlp_overrides:105] Configuring DDP for model parallelism.\n",
      "[NeMo I 2023-06-01 18:01:24 nlp_overrides:105] Configuring DDP for model parallelism.\n",
      "[NeMo I 2023-06-01 18:01:25 modelPT:722] Optimizer config = FusedAdam (\n",
      "    Parameter Group 0\n",
      "        betas: [0.9, 0.98]\n",
      "        bias_correction: True\n",
      "        eps: 1e-08\n",
      "        lr: 0.0001\n",
      "        weight_decay: 0.01\n",
      "    )\n",
      "[NeMo I 2023-06-01 18:01:25 lr_scheduler:910] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7ffa0e1bd490>\" \n",
      "    will be used during training (effective maximum steps = 11000) - \n",
      "    Parameters : \n",
      "    (warmup_steps: 50\n",
      "    min_lr: 0.0\n",
      "    constant_steps: 0\n",
      "    max_steps: 11000\n",
      "    )\n",
      "[NeMo I 2023-06-01 18:01:25 modelPT:722] Optimizer config = FusedAdam (\n",
      "    Parameter Group 0\n",
      "        betas: [0.9, 0.98]\n",
      "        bias_correction: True\n",
      "        eps: 1e-08\n",
      "        lr: 0.0001\n",
      "        weight_decay: 0.01\n",
      "    )\n",
      "[NeMo I 2023-06-01 18:01:25 lr_scheduler:910] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7fed7c0453a0>\" \n",
      "    will be used during training (effective maximum steps = 11000) - \n",
      "    Parameters : \n",
      "    (warmup_steps: 50\n",
      "    min_lr: 0.0\n",
      "    constant_steps: 0\n",
      "    max_steps: 11000\n",
      "    )\n",
      "2023-06-01 18:01:25,022 - pytorch_lightning.callbacks.model_summary - INFO - \n",
      "  | Name            | Type                   | Params\n",
      "-----------------------------------------------------------\n",
      "0 | frozen_model    | MegatronGPTModel       | 354 M \n",
      "1 | word_embeddings | VocabParallelEmbedding | 51.5 M\n",
      "2 | prompt_encoder  | PromptEncoder          | 4.2 M \n",
      "-----------------------------------------------------------\n",
      "4.2 M     Trainable params\n",
      "354 M     Non-trainable params\n",
      "359 M     Total params\n",
      "718.178   Total estimated model params size (MB)\n",
      "Sanity Checking: 0it [00:00, ?it/s]2023-06-01 18:01:25,037 - pytorch_lightning.callbacks.model_summary - INFO - \n",
      "  | Name            | Type                   | Params\n",
      "-----------------------------------------------------------\n",
      "0 | frozen_model    | MegatronGPTModel       | 354 M \n",
      "1 | word_embeddings | VocabParallelEmbedding | 51.5 M\n",
      "2 | prompt_encoder  | PromptEncoder          | 4.2 M \n",
      "-----------------------------------------------------------\n",
      "4.2 M     Trainable params\n",
      "354 M     Non-trainable params\n",
      "359 M     Total params\n",
      "718.178   Total estimated model params size (MB)\n",
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:01:25.022401 140713251325760 model_summary.py:83] \n",
      "  | Name            | Type                   | Params\n",
      "-----------------------------------------------------------\n",
      "0 | frozen_model    | MegatronGPTModel       | 354 M \n",
      "1 | word_embeddings | VocabParallelEmbedding | 51.5 M\n",
      "2 | prompt_encoder  | PromptEncoder          | 4.2 M \n",
      "-----------------------------------------------------------\n",
      "4.2 M     Trainable params\n",
      "354 M     Non-trainable params\n",
      "359 M     Total params\n",
      "718.178   Total estimated model params size (MB)\n",
      "I0601 18:01:25.037023 140659256891200 model_summary.py:83] \n",
      "  | Name            | Type                   | Params\n",
      "-----------------------------------------------------------\n",
      "0 | frozen_model    | MegatronGPTModel       | 354 M \n",
      "1 | word_embeddings | VocabParallelEmbedding | 51.5 M\n",
      "2 | prompt_encoder  | PromptEncoder          | 4.2 M \n",
      "-----------------------------------------------------------\n",
      "4.2 M     Trainable params\n",
      "354 M     Non-trainable params\n",
      "359 M     Total params\n",
      "718.178   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:02<00:00,  1.03s/it]2023-06-01 18:01:27,423 - root - INFO - val_loss: 6.231474876403809\n",
      "                                                                           2023-06-01 18:01:27,426 - root - INFO - val_loss: 6.231474876403809\n",
      "Epoch 0:   0%|          | 0/13 [00:00<?, ?it/s]                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:01:27.423478 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 6.231474876403809\n",
      "I0601 18:01:27.426760 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 6.231474876403809\n",
      "[NeMo W 2023-06-01 18:01:27 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (9) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "      rank_zero_warn(\n",
      "    \n",
      "[NeMo W 2023-06-01 18:01:27 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (9) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "      rank_zero_warn(\n",
      "    \n",
      "[NeMo W 2023-06-01 18:01:32 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:232: UserWarning: You called `self.log('global_step', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "      warning_cache.warn(\n",
      "    \n",
      "[NeMo W 2023-06-01 18:01:32 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:232: UserWarning: You called `self.log('global_step', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "      warning_cache.warn(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   8%|▊         | 1/13 [00:05<01:06,  5.56s/it, loss=8.21, v_num=0, reduced_train_loss=8.210, global_step=0.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-06-01 18:01:32 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "      warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  69%|██████▉   | 9/13 [00:19<00:08,  2.20s/it, loss=6.62, v_num=0, reduced_train_loss=5.410, global_step=8.000]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  69%|██████▉   | 9/13 [00:20<00:09,  2.27s/it, loss=6.76, v_num=0, reduced_train_loss=5.550, global_step=8.000]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  77%|███████▋  | 10/13 [00:20<00:06,  2.07s/it, loss=6.62, v_num=0, reduced_train_loss=5.410, global_step=8.000]\n",
      "Epoch 0:  77%|███████▋  | 10/13 [00:21<00:06,  2.14s/it, loss=6.76, v_num=0, reduced_train_loss=5.550, global_step=8.000]\n",
      "Epoch 0:  85%|████████▍ | 11/13 [00:21<00:03,  1.97s/it, loss=6.62, v_num=0, reduced_train_loss=5.410, global_step=8.000]\n",
      "Epoch 0:  85%|████████▍ | 11/13 [00:22<00:04,  2.03s/it, loss=6.76, v_num=0, reduced_train_loss=5.550, global_step=8.000]\n",
      "Epoch 0:  92%|█████████▏| 12/13 [00:22<00:01,  1.89s/it, loss=6.62, v_num=0, reduced_train_loss=5.410, global_step=8.000]\n",
      "Epoch 0: 100%|██████████| 13/13 [00:22<00:00,  1.75s/it, loss=6.62, v_num=0, reduced_train_loss=5.410, global_step=8.000]2023-06-01 18:01:50,145 - root - INFO - val_loss: 4.991292953491211\n",
      "Epoch 0: 100%|██████████| 13/13 [00:22<00:00,  1.75s/it, loss=6.62, v_num=0, reduced_train_loss=5.410, global_step=8.000, val_loss=4.990]\n",
      "Epoch 1:   0%|          | 0/13 [00:00<?, ?it/s, loss=6.62, v_num=0, reduced_train_loss=5.410, global_step=8.000, val_loss=4.990]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:01:50.145513 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 4.991292953491211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0:  92%|█████████▏| 12/13 [00:23<00:01,  1.94s/it, loss=6.76, v_num=0, reduced_train_loss=5.550, global_step=8.000]\n",
      "Epoch 0: 100%|██████████| 13/13 [00:23<00:00,  1.80s/it, loss=6.76, v_num=0, reduced_train_loss=5.550, global_step=8.000]2023-06-01 18:01:50,801 - root - INFO - val_loss: 5.130880355834961\n",
      "Epoch 0: 100%|██████████| 13/13 [00:23<00:00,  1.80s/it, loss=6.76, v_num=0, reduced_train_loss=5.550, global_step=8.000, val_loss=5.130]\n",
      "Epoch 1:   0%|          | 0/13 [00:00<?, ?it/s, loss=6.76, v_num=0, reduced_train_loss=5.550, global_step=8.000, val_loss=5.130]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:01:50.801930 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 5.130880355834961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  69%|██████▉   | 9/13 [00:16<00:07,  1.80s/it, loss=5.49, v_num=0, reduced_train_loss=3.260, global_step=17.00, val_loss=4.990]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 9/13 [00:16<00:07,  1.79s/it, loss=5.71, v_num=0, reduced_train_loss=3.580, global_step=17.00, val_loss=5.130]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 10/13 [00:17<00:05,  1.72s/it, loss=5.49, v_num=0, reduced_train_loss=3.260, global_step=17.00, val_loss=4.990]\n",
      "Epoch 1:  77%|███████▋  | 10/13 [00:17<00:05,  1.71s/it, loss=5.71, v_num=0, reduced_train_loss=3.580, global_step=17.00, val_loss=5.130]\n",
      "Epoch 1:  85%|████████▍ | 11/13 [00:18<00:03,  1.65s/it, loss=5.49, v_num=0, reduced_train_loss=3.260, global_step=17.00, val_loss=4.990]\n",
      "Epoch 1:  85%|████████▍ | 11/13 [00:18<00:03,  1.64s/it, loss=5.71, v_num=0, reduced_train_loss=3.580, global_step=17.00, val_loss=5.130]\n",
      "Epoch 1:  92%|█████████▏| 12/13 [00:19<00:01,  1.60s/it, loss=5.49, v_num=0, reduced_train_loss=3.260, global_step=17.00, val_loss=4.990]\n",
      "Epoch 1: 100%|██████████| 13/13 [00:19<00:00,  1.48s/it, loss=5.49, v_num=0, reduced_train_loss=3.260, global_step=17.00, val_loss=4.990]2023-06-01 18:02:09,403 - root - INFO - val_loss: 2.129469394683838\n",
      "Epoch 1: 100%|██████████| 13/13 [00:19<00:00,  1.48s/it, loss=5.49, v_num=0, reduced_train_loss=3.260, global_step=17.00, val_loss=2.130]\n",
      "Epoch 2:   0%|          | 0/13 [00:00<?, ?it/s, loss=5.49, v_num=0, reduced_train_loss=3.260, global_step=17.00, val_loss=2.130]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:02:09.403805 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 2.129469394683838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1:  92%|█████████▏| 12/13 [00:18<00:01,  1.58s/it, loss=5.71, v_num=0, reduced_train_loss=3.580, global_step=17.00, val_loss=5.130]\n",
      "Epoch 1: 100%|██████████| 13/13 [00:19<00:00,  1.47s/it, loss=5.71, v_num=0, reduced_train_loss=3.580, global_step=17.00, val_loss=5.130]2023-06-01 18:02:09,869 - root - INFO - val_loss: 2.3115713596343994\n",
      "Epoch 1: 100%|██████████| 13/13 [00:19<00:00,  1.47s/it, loss=5.71, v_num=0, reduced_train_loss=3.580, global_step=17.00, val_loss=2.310]\n",
      "Epoch 2:   0%|          | 0/13 [00:00<?, ?it/s, loss=5.71, v_num=0, reduced_train_loss=3.580, global_step=17.00, val_loss=2.310]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:02:09.869889 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 2.3115713596343994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  69%|██████▉   | 9/13 [00:16<00:07,  1.81s/it, loss=3.23, v_num=0, reduced_train_loss=0.734, global_step=26.00, val_loss=2.130]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 9/13 [00:16<00:07,  1.81s/it, loss=3.57, v_num=0, reduced_train_loss=0.778, global_step=26.00, val_loss=2.310]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 10/13 [00:17<00:05,  1.73s/it, loss=3.23, v_num=0, reduced_train_loss=0.734, global_step=26.00, val_loss=2.130]\n",
      "Epoch 2:  77%|███████▋  | 10/13 [00:17<00:05,  1.73s/it, loss=3.57, v_num=0, reduced_train_loss=0.778, global_step=26.00, val_loss=2.310]\n",
      "Epoch 2:  85%|████████▍ | 11/13 [00:18<00:03,  1.66s/it, loss=3.23, v_num=0, reduced_train_loss=0.734, global_step=26.00, val_loss=2.130]\n",
      "Epoch 2:  85%|████████▍ | 11/13 [00:18<00:03,  1.66s/it, loss=3.57, v_num=0, reduced_train_loss=0.778, global_step=26.00, val_loss=2.310]\n",
      "Epoch 2:  92%|█████████▏| 12/13 [00:19<00:01,  1.60s/it, loss=3.23, v_num=0, reduced_train_loss=0.734, global_step=26.00, val_loss=2.130]\n",
      "Epoch 2: 100%|██████████| 13/13 [00:19<00:00,  1.49s/it, loss=3.23, v_num=0, reduced_train_loss=0.734, global_step=26.00, val_loss=2.130]2023-06-01 18:02:28,750 - root - INFO - val_loss: 0.39972931146621704\n",
      "Epoch 2: 100%|██████████| 13/13 [00:19<00:00,  1.49s/it, loss=3.23, v_num=0, reduced_train_loss=0.734, global_step=26.00, val_loss=0.400]\n",
      "Epoch 3:   0%|          | 0/13 [00:00<?, ?it/s, loss=3.23, v_num=0, reduced_train_loss=0.734, global_step=26.00, val_loss=0.400]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:02:28.750339 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.39972931146621704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2:  92%|█████████▏| 12/13 [00:19<00:01,  1.60s/it, loss=3.57, v_num=0, reduced_train_loss=0.778, global_step=26.00, val_loss=2.310]\n",
      "Epoch 2: 100%|██████████| 13/13 [00:19<00:00,  1.48s/it, loss=3.57, v_num=0, reduced_train_loss=0.778, global_step=26.00, val_loss=2.310]2023-06-01 18:02:29,153 - root - INFO - val_loss: 0.5346519947052002\n",
      "Epoch 2: 100%|██████████| 13/13 [00:19<00:00,  1.48s/it, loss=3.57, v_num=0, reduced_train_loss=0.778, global_step=26.00, val_loss=0.535]\n",
      "Epoch 3:   0%|          | 0/13 [00:00<?, ?it/s, loss=3.57, v_num=0, reduced_train_loss=0.778, global_step=26.00, val_loss=0.535]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:02:29.153979 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.5346519947052002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  69%|██████▉   | 9/13 [00:16<00:07,  1.82s/it, loss=1.31, v_num=0, reduced_train_loss=0.465, global_step=35.00, val_loss=0.400]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 9/13 [00:16<00:07,  1.82s/it, loss=1.54, v_num=0, reduced_train_loss=0.502, global_step=35.00, val_loss=0.535]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 10/13 [00:17<00:05,  1.74s/it, loss=1.31, v_num=0, reduced_train_loss=0.465, global_step=35.00, val_loss=0.400]\n",
      "Epoch 3:  77%|███████▋  | 10/13 [00:17<00:05,  1.74s/it, loss=1.54, v_num=0, reduced_train_loss=0.502, global_step=35.00, val_loss=0.535]\n",
      "Epoch 3:  85%|████████▍ | 11/13 [00:18<00:03,  1.67s/it, loss=1.31, v_num=0, reduced_train_loss=0.465, global_step=35.00, val_loss=0.400]\n",
      "Epoch 3:  85%|████████▍ | 11/13 [00:18<00:03,  1.67s/it, loss=1.54, v_num=0, reduced_train_loss=0.502, global_step=35.00, val_loss=0.535]\n",
      "Epoch 3:  92%|█████████▏| 12/13 [00:19<00:01,  1.61s/it, loss=1.31, v_num=0, reduced_train_loss=0.465, global_step=35.00, val_loss=0.400]\n",
      "Epoch 3: 100%|██████████| 13/13 [00:19<00:00,  1.49s/it, loss=1.31, v_num=0, reduced_train_loss=0.465, global_step=35.00, val_loss=0.400]2023-06-01 18:02:48,101 - root - INFO - val_loss: 0.3097499907016754\n",
      "Epoch 3: 100%|██████████| 13/13 [00:19<00:00,  1.49s/it, loss=1.31, v_num=0, reduced_train_loss=0.465, global_step=35.00, val_loss=0.310]\n",
      "Epoch 4:   0%|          | 0/13 [00:00<?, ?it/s, loss=1.31, v_num=0, reduced_train_loss=0.465, global_step=35.00, val_loss=0.310]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:02:48.101423 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.3097499907016754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3:  92%|█████████▏| 12/13 [00:19<00:01,  1.61s/it, loss=1.54, v_num=0, reduced_train_loss=0.502, global_step=35.00, val_loss=0.535]\n",
      "Epoch 3: 100%|██████████| 13/13 [00:19<00:00,  1.49s/it, loss=1.54, v_num=0, reduced_train_loss=0.502, global_step=35.00, val_loss=0.535]2023-06-01 18:02:48,578 - root - INFO - val_loss: 0.3871537148952484\n",
      "Epoch 3: 100%|██████████| 13/13 [00:19<00:00,  1.49s/it, loss=1.54, v_num=0, reduced_train_loss=0.502, global_step=35.00, val_loss=0.387]\n",
      "Epoch 4:   0%|          | 0/13 [00:00<?, ?it/s, loss=1.54, v_num=0, reduced_train_loss=0.502, global_step=35.00, val_loss=0.387]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:02:48.578599 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.3871537148952484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  69%|██████▉   | 9/13 [00:16<00:07,  1.81s/it, loss=0.548, v_num=0, reduced_train_loss=0.413, global_step=44.00, val_loss=0.310]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  69%|██████▉   | 9/13 [00:16<00:07,  1.83s/it, loss=0.63, v_num=0, reduced_train_loss=0.561, global_step=44.00, val_loss=0.387]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  77%|███████▋  | 10/13 [00:17<00:05,  1.73s/it, loss=0.548, v_num=0, reduced_train_loss=0.413, global_step=44.00, val_loss=0.310]\n",
      "Epoch 4:  77%|███████▋  | 10/13 [00:17<00:05,  1.75s/it, loss=0.63, v_num=0, reduced_train_loss=0.561, global_step=44.00, val_loss=0.387]\n",
      "Epoch 4:  85%|████████▍ | 11/13 [00:18<00:03,  1.66s/it, loss=0.548, v_num=0, reduced_train_loss=0.413, global_step=44.00, val_loss=0.310]\n",
      "Epoch 4:  85%|████████▍ | 11/13 [00:18<00:03,  1.68s/it, loss=0.63, v_num=0, reduced_train_loss=0.561, global_step=44.00, val_loss=0.387]\n",
      "Epoch 4:  92%|█████████▏| 12/13 [00:19<00:01,  1.60s/it, loss=0.548, v_num=0, reduced_train_loss=0.413, global_step=44.00, val_loss=0.310]\n",
      "Epoch 4: 100%|██████████| 13/13 [00:19<00:00,  1.48s/it, loss=0.548, v_num=0, reduced_train_loss=0.413, global_step=44.00, val_loss=0.310]2023-06-01 18:03:07,373 - root - INFO - val_loss: 0.2139081358909607\n",
      "Epoch 4: 100%|██████████| 13/13 [00:19<00:00,  1.48s/it, loss=0.548, v_num=0, reduced_train_loss=0.413, global_step=44.00, val_loss=0.214]\n",
      "Epoch 5:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.548, v_num=0, reduced_train_loss=0.413, global_step=44.00, val_loss=0.214]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:03:07.373527 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.2139081358909607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.63, v_num=0, reduced_train_loss=0.561, global_step=44.00, val_loss=0.387]\n",
      "Epoch 4: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.63, v_num=0, reduced_train_loss=0.561, global_step=44.00, val_loss=0.387]2023-06-01 18:03:08,163 - root - INFO - val_loss: 0.31660202145576477\n",
      "Epoch 4: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.63, v_num=0, reduced_train_loss=0.561, global_step=44.00, val_loss=0.317]\n",
      "Epoch 5:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.63, v_num=0, reduced_train_loss=0.561, global_step=44.00, val_loss=0.317]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:03:08.163386 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.31660202145576477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  69%|██████▉   | 9/13 [00:16<00:07,  1.82s/it, loss=0.433, v_num=0, reduced_train_loss=0.397, global_step=53.00, val_loss=0.214]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  69%|██████▉   | 9/13 [00:16<00:07,  1.81s/it, loss=0.513, v_num=0, reduced_train_loss=0.363, global_step=53.00, val_loss=0.317]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  77%|███████▋  | 10/13 [00:17<00:05,  1.74s/it, loss=0.433, v_num=0, reduced_train_loss=0.397, global_step=53.00, val_loss=0.214]\n",
      "Epoch 5:  77%|███████▋  | 10/13 [00:17<00:05,  1.73s/it, loss=0.513, v_num=0, reduced_train_loss=0.363, global_step=53.00, val_loss=0.317]\n",
      "Epoch 5:  85%|████████▍ | 11/13 [00:18<00:03,  1.67s/it, loss=0.433, v_num=0, reduced_train_loss=0.397, global_step=53.00, val_loss=0.214]\n",
      "Epoch 5:  85%|████████▍ | 11/13 [00:18<00:03,  1.66s/it, loss=0.513, v_num=0, reduced_train_loss=0.363, global_step=53.00, val_loss=0.317]\n",
      "Epoch 5:  92%|█████████▏| 12/13 [00:19<00:01,  1.61s/it, loss=0.433, v_num=0, reduced_train_loss=0.397, global_step=53.00, val_loss=0.214]\n",
      "Epoch 5: 100%|██████████| 13/13 [00:19<00:00,  1.49s/it, loss=0.433, v_num=0, reduced_train_loss=0.397, global_step=53.00, val_loss=0.214]2023-06-01 18:03:26,739 - root - INFO - val_loss: 0.19116896390914917\n",
      "Epoch 5: 100%|██████████| 13/13 [00:19<00:00,  1.49s/it, loss=0.433, v_num=0, reduced_train_loss=0.397, global_step=53.00, val_loss=0.191]\n",
      "Epoch 6:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.433, v_num=0, reduced_train_loss=0.397, global_step=53.00, val_loss=0.191]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:03:26.739750 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.19116896390914917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5:  92%|█████████▏| 12/13 [00:19<00:01,  1.61s/it, loss=0.513, v_num=0, reduced_train_loss=0.363, global_step=53.00, val_loss=0.317]\n",
      "Epoch 5: 100%|██████████| 13/13 [00:19<00:00,  1.49s/it, loss=0.513, v_num=0, reduced_train_loss=0.363, global_step=53.00, val_loss=0.317]2023-06-01 18:03:27,512 - root - INFO - val_loss: 0.21267980337142944\n",
      "Epoch 5: 100%|██████████| 13/13 [00:19<00:00,  1.49s/it, loss=0.513, v_num=0, reduced_train_loss=0.363, global_step=53.00, val_loss=0.213]\n",
      "Epoch 6:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.513, v_num=0, reduced_train_loss=0.363, global_step=53.00, val_loss=0.213]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:03:27.512576 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.21267980337142944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  69%|██████▉   | 9/13 [00:16<00:07,  1.83s/it, loss=0.356, v_num=0, reduced_train_loss=0.206, global_step=62.00, val_loss=0.191]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  69%|██████▉   | 9/13 [00:16<00:07,  1.82s/it, loss=0.423, v_num=0, reduced_train_loss=0.318, global_step=62.00, val_loss=0.213]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  77%|███████▋  | 10/13 [00:17<00:05,  1.75s/it, loss=0.356, v_num=0, reduced_train_loss=0.206, global_step=62.00, val_loss=0.191]\n",
      "Epoch 6:  77%|███████▋  | 10/13 [00:17<00:05,  1.74s/it, loss=0.423, v_num=0, reduced_train_loss=0.318, global_step=62.00, val_loss=0.213]\n",
      "Epoch 6:  85%|████████▍ | 11/13 [00:18<00:03,  1.68s/it, loss=0.356, v_num=0, reduced_train_loss=0.206, global_step=62.00, val_loss=0.191]\n",
      "Epoch 6:  85%|████████▍ | 11/13 [00:18<00:03,  1.66s/it, loss=0.423, v_num=0, reduced_train_loss=0.318, global_step=62.00, val_loss=0.213]\n",
      "Epoch 6:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.356, v_num=0, reduced_train_loss=0.206, global_step=62.00, val_loss=0.191]\n",
      "Epoch 6: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.356, v_num=0, reduced_train_loss=0.206, global_step=62.00, val_loss=0.191]2023-06-01 18:03:46,349 - root - INFO - val_loss: 0.1411426067352295\n",
      "Epoch 6: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.356, v_num=0, reduced_train_loss=0.206, global_step=62.00, val_loss=0.141]\n",
      "Epoch 7:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.356, v_num=0, reduced_train_loss=0.206, global_step=62.00, val_loss=0.141]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:03:46.349517 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.1411426067352295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6:  92%|█████████▏| 12/13 [00:19<00:01,  1.61s/it, loss=0.423, v_num=0, reduced_train_loss=0.318, global_step=62.00, val_loss=0.213]\n",
      "Epoch 6: 100%|██████████| 13/13 [00:19<00:00,  1.49s/it, loss=0.423, v_num=0, reduced_train_loss=0.318, global_step=62.00, val_loss=0.213]2023-06-01 18:03:46,900 - root - INFO - val_loss: 0.20767417550086975\n",
      "Epoch 6: 100%|██████████| 13/13 [00:19<00:00,  1.49s/it, loss=0.423, v_num=0, reduced_train_loss=0.318, global_step=62.00, val_loss=0.208]\n",
      "Epoch 7:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.423, v_num=0, reduced_train_loss=0.318, global_step=62.00, val_loss=0.208]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:03:46.900951 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.20767417550086975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  69%|██████▉   | 9/13 [00:16<00:07,  1.84s/it, loss=0.292, v_num=0, reduced_train_loss=0.236, global_step=71.00, val_loss=0.141]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  69%|██████▉   | 9/13 [00:16<00:07,  1.84s/it, loss=0.352, v_num=0, reduced_train_loss=0.320, global_step=71.00, val_loss=0.208]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  77%|███████▋  | 10/13 [00:17<00:05,  1.75s/it, loss=0.292, v_num=0, reduced_train_loss=0.236, global_step=71.00, val_loss=0.141]\n",
      "Epoch 7:  77%|███████▋  | 10/13 [00:17<00:05,  1.75s/it, loss=0.352, v_num=0, reduced_train_loss=0.320, global_step=71.00, val_loss=0.208]\n",
      "Epoch 7:  85%|████████▍ | 11/13 [00:18<00:03,  1.69s/it, loss=0.292, v_num=0, reduced_train_loss=0.236, global_step=71.00, val_loss=0.141]\n",
      "Epoch 7:  85%|████████▍ | 11/13 [00:18<00:03,  1.68s/it, loss=0.352, v_num=0, reduced_train_loss=0.320, global_step=71.00, val_loss=0.208]\n",
      "Epoch 7:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.292, v_num=0, reduced_train_loss=0.236, global_step=71.00, val_loss=0.141]\n",
      "Epoch 7: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.292, v_num=0, reduced_train_loss=0.236, global_step=71.00, val_loss=0.141]2023-06-01 18:04:06,004 - root - INFO - val_loss: 0.12022870779037476\n",
      "Epoch 7: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.292, v_num=0, reduced_train_loss=0.236, global_step=71.00, val_loss=0.120]\n",
      "Epoch 8:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.292, v_num=0, reduced_train_loss=0.236, global_step=71.00, val_loss=0.120]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:04:06.004587 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.12022870779037476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7:  92%|█████████▏| 12/13 [00:19<00:01,  1.62s/it, loss=0.352, v_num=0, reduced_train_loss=0.320, global_step=71.00, val_loss=0.208]\n",
      "Epoch 7: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.352, v_num=0, reduced_train_loss=0.320, global_step=71.00, val_loss=0.208]2023-06-01 18:04:06,430 - root - INFO - val_loss: 0.13132905960083008\n",
      "Epoch 7: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.352, v_num=0, reduced_train_loss=0.320, global_step=71.00, val_loss=0.131]\n",
      "Epoch 8:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.352, v_num=0, reduced_train_loss=0.320, global_step=71.00, val_loss=0.131]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:04:06.430940 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.13132905960083008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  69%|██████▉   | 9/13 [00:16<00:07,  1.81s/it, loss=0.232, v_num=0, reduced_train_loss=0.180, global_step=80.00, val_loss=0.120]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  69%|██████▉   | 9/13 [00:16<00:07,  1.82s/it, loss=0.322, v_num=0, reduced_train_loss=0.303, global_step=80.00, val_loss=0.131]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  77%|███████▋  | 10/13 [00:17<00:05,  1.73s/it, loss=0.232, v_num=0, reduced_train_loss=0.180, global_step=80.00, val_loss=0.120]\n",
      "Epoch 8:  77%|███████▋  | 10/13 [00:17<00:05,  1.74s/it, loss=0.322, v_num=0, reduced_train_loss=0.303, global_step=80.00, val_loss=0.131]\n",
      "Epoch 8:  85%|████████▍ | 11/13 [00:18<00:03,  1.66s/it, loss=0.232, v_num=0, reduced_train_loss=0.180, global_step=80.00, val_loss=0.120]\n",
      "Epoch 8:  85%|████████▍ | 11/13 [00:18<00:03,  1.67s/it, loss=0.322, v_num=0, reduced_train_loss=0.303, global_step=80.00, val_loss=0.131]\n",
      "Epoch 8:  92%|█████████▏| 12/13 [00:19<00:01,  1.61s/it, loss=0.232, v_num=0, reduced_train_loss=0.180, global_step=80.00, val_loss=0.120]\n",
      "Epoch 8: 100%|██████████| 13/13 [00:19<00:00,  1.49s/it, loss=0.232, v_num=0, reduced_train_loss=0.180, global_step=80.00, val_loss=0.120]2023-06-01 18:04:25,348 - root - INFO - val_loss: 0.12506113946437836\n",
      "Epoch 8: 100%|██████████| 13/13 [00:19<00:00,  1.49s/it, loss=0.232, v_num=0, reduced_train_loss=0.180, global_step=80.00, val_loss=0.125]\n",
      "Epoch 9:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.232, v_num=0, reduced_train_loss=0.180, global_step=80.00, val_loss=0.125]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:04:25.348242 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.12506113946437836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8:  92%|█████████▏| 12/13 [00:19<00:01,  1.61s/it, loss=0.322, v_num=0, reduced_train_loss=0.303, global_step=80.00, val_loss=0.131]\n",
      "Epoch 8: 100%|██████████| 13/13 [00:19<00:00,  1.49s/it, loss=0.322, v_num=0, reduced_train_loss=0.303, global_step=80.00, val_loss=0.131]2023-06-01 18:04:25,797 - root - INFO - val_loss: 0.1160048171877861\n",
      "Epoch 8: 100%|██████████| 13/13 [00:19<00:00,  1.49s/it, loss=0.322, v_num=0, reduced_train_loss=0.303, global_step=80.00, val_loss=0.116]\n",
      "Epoch 9:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.322, v_num=0, reduced_train_loss=0.303, global_step=80.00, val_loss=0.116]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:04:25.797415 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.1160048171877861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  69%|██████▉   | 9/13 [00:16<00:07,  1.83s/it, loss=0.208, v_num=0, reduced_train_loss=0.145, global_step=89.00, val_loss=0.125]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  69%|██████▉   | 9/13 [00:16<00:07,  1.86s/it, loss=0.279, v_num=0, reduced_train_loss=0.177, global_step=89.00, val_loss=0.116]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  77%|███████▋  | 10/13 [00:17<00:05,  1.75s/it, loss=0.208, v_num=0, reduced_train_loss=0.145, global_step=89.00, val_loss=0.125]\n",
      "Epoch 9:  77%|███████▋  | 10/13 [00:17<00:05,  1.77s/it, loss=0.279, v_num=0, reduced_train_loss=0.177, global_step=89.00, val_loss=0.116]\n",
      "Epoch 9:  85%|████████▍ | 11/13 [00:18<00:03,  1.68s/it, loss=0.208, v_num=0, reduced_train_loss=0.145, global_step=89.00, val_loss=0.125]\n",
      "Epoch 9:  85%|████████▍ | 11/13 [00:18<00:03,  1.70s/it, loss=0.279, v_num=0, reduced_train_loss=0.177, global_step=89.00, val_loss=0.116]\n",
      "Epoch 9:  92%|█████████▏| 12/13 [00:19<00:01,  1.62s/it, loss=0.208, v_num=0, reduced_train_loss=0.145, global_step=89.00, val_loss=0.125]\n",
      "Epoch 9: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.208, v_num=0, reduced_train_loss=0.145, global_step=89.00, val_loss=0.125]2023-06-01 18:04:44,831 - root - INFO - val_loss: 0.1013915166258812\n",
      "Epoch 9: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.208, v_num=0, reduced_train_loss=0.145, global_step=89.00, val_loss=0.101]\n",
      "Epoch 10:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.208, v_num=0, reduced_train_loss=0.145, global_step=89.00, val_loss=0.101]        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:04:44.831470 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.1013915166258812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9:  92%|█████████▏| 12/13 [00:19<00:01,  1.64s/it, loss=0.279, v_num=0, reduced_train_loss=0.177, global_step=89.00, val_loss=0.116]\n",
      "Epoch 9: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.279, v_num=0, reduced_train_loss=0.177, global_step=89.00, val_loss=0.116]2023-06-01 18:04:45,498 - root - INFO - val_loss: 0.11481466144323349\n",
      "Epoch 9: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.279, v_num=0, reduced_train_loss=0.177, global_step=89.00, val_loss=0.115]\n",
      "Epoch 10:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.279, v_num=0, reduced_train_loss=0.177, global_step=89.00, val_loss=0.115]        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:04:45.498575 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.11481466144323349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  69%|██████▉   | 9/13 [00:17<00:07,  1.93s/it, loss=0.185, v_num=0, reduced_train_loss=0.180, global_step=98.00, val_loss=0.101]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:  69%|██████▉   | 9/13 [00:17<00:07,  1.91s/it, loss=0.255, v_num=0, reduced_train_loss=0.184, global_step=98.00, val_loss=0.115]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:  77%|███████▋  | 10/13 [00:18<00:05,  1.83s/it, loss=0.185, v_num=0, reduced_train_loss=0.180, global_step=98.00, val_loss=0.101]\n",
      "Epoch 10:  77%|███████▋  | 10/13 [00:18<00:05,  1.83s/it, loss=0.255, v_num=0, reduced_train_loss=0.184, global_step=98.00, val_loss=0.115]\n",
      "Epoch 10:  85%|████████▍ | 11/13 [00:19<00:03,  1.75s/it, loss=0.185, v_num=0, reduced_train_loss=0.180, global_step=98.00, val_loss=0.101]\n",
      "Epoch 10:  85%|████████▍ | 11/13 [00:19<00:03,  1.75s/it, loss=0.255, v_num=0, reduced_train_loss=0.184, global_step=98.00, val_loss=0.115]\n",
      "Epoch 10:  92%|█████████▏| 12/13 [00:20<00:01,  1.69s/it, loss=0.185, v_num=0, reduced_train_loss=0.180, global_step=98.00, val_loss=0.101]\n",
      "Epoch 10: 100%|██████████| 13/13 [00:20<00:00,  1.56s/it, loss=0.185, v_num=0, reduced_train_loss=0.180, global_step=98.00, val_loss=0.101]2023-06-01 18:05:05,138 - root - INFO - val_loss: 0.08494291454553604\n",
      "Epoch 10: 100%|██████████| 13/13 [00:20<00:00,  1.56s/it, loss=0.185, v_num=0, reduced_train_loss=0.180, global_step=98.00, val_loss=0.0849]\n",
      "Epoch 11:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.185, v_num=0, reduced_train_loss=0.180, global_step=98.00, val_loss=0.0849]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:05:05.138164 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.08494291454553604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10:  92%|█████████▏| 12/13 [00:20<00:01,  1.68s/it, loss=0.255, v_num=0, reduced_train_loss=0.184, global_step=98.00, val_loss=0.115]\n",
      "Epoch 10: 100%|██████████| 13/13 [00:20<00:00,  1.56s/it, loss=0.255, v_num=0, reduced_train_loss=0.184, global_step=98.00, val_loss=0.115]2023-06-01 18:05:05,782 - root - INFO - val_loss: 0.15055806934833527\n",
      "Epoch 10: 100%|██████████| 13/13 [00:20<00:00,  1.56s/it, loss=0.255, v_num=0, reduced_train_loss=0.184, global_step=98.00, val_loss=0.151]\n",
      "Epoch 11:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.255, v_num=0, reduced_train_loss=0.184, global_step=98.00, val_loss=0.151]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:05:05.782470 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.15055806934833527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  69%|██████▉   | 9/13 [00:16<00:07,  1.82s/it, loss=0.175, v_num=0, reduced_train_loss=0.120, global_step=107.0, val_loss=0.0849]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:  69%|██████▉   | 9/13 [00:16<00:07,  1.88s/it, loss=0.219, v_num=0, reduced_train_loss=0.176, global_step=107.0, val_loss=0.151]9]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:  85%|████████▍ | 11/13 [00:18<00:03,  1.69s/it, loss=0.175, v_num=0, reduced_train_loss=0.120, global_step=107.0, val_loss=0.0849]\n",
      "Epoch 11:  77%|███████▋  | 10/13 [00:17<00:05,  1.80s/it, loss=0.219, v_num=0, reduced_train_loss=0.176, global_step=107.0, val_loss=0.151]\n",
      "Epoch 11:  85%|████████▍ | 11/13 [00:19<00:03,  1.73s/it, loss=0.219, v_num=0, reduced_train_loss=0.176, global_step=107.0, val_loss=0.151]\n",
      "Epoch 11:  92%|█████████▏| 12/13 [00:19<00:01,  1.65s/it, loss=0.175, v_num=0, reduced_train_loss=0.120, global_step=107.0, val_loss=0.0849]\n",
      "Epoch 11: 100%|██████████| 13/13 [00:19<00:00,  1.53s/it, loss=0.175, v_num=0, reduced_train_loss=0.120, global_step=107.0, val_loss=0.0849]2023-06-01 18:05:25,001 - root - INFO - val_loss: 0.1008821427822113\n",
      "Epoch 11: 100%|██████████| 13/13 [00:19<00:00,  1.53s/it, loss=0.175, v_num=0, reduced_train_loss=0.120, global_step=107.0, val_loss=0.101] \n",
      "Epoch 12:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.175, v_num=0, reduced_train_loss=0.120, global_step=107.0, val_loss=0.101]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:05:25.001159 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.1008821427822113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11:  92%|█████████▏| 12/13 [00:20<00:01,  1.67s/it, loss=0.219, v_num=0, reduced_train_loss=0.176, global_step=107.0, val_loss=0.151]\n",
      "Epoch 11: 100%|██████████| 13/13 [00:20<00:00,  1.55s/it, loss=0.219, v_num=0, reduced_train_loss=0.176, global_step=107.0, val_loss=0.151]2023-06-01 18:05:25,918 - root - INFO - val_loss: 0.134514719247818\n",
      "Epoch 11: 100%|██████████| 13/13 [00:20<00:00,  1.55s/it, loss=0.219, v_num=0, reduced_train_loss=0.176, global_step=107.0, val_loss=0.135]\n",
      "Epoch 12:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.219, v_num=0, reduced_train_loss=0.176, global_step=107.0, val_loss=0.135]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:05:25.918585 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.134514719247818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:  69%|██████▉   | 9/13 [00:16<00:07,  1.83s/it, loss=0.157, v_num=0, reduced_train_loss=0.125, global_step=116.0, val_loss=0.101] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:  69%|██████▉   | 9/13 [00:16<00:07,  1.86s/it, loss=0.199, v_num=0, reduced_train_loss=0.181, global_step=116.0, val_loss=0.135]]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:  85%|████████▍ | 11/13 [00:18<00:03,  1.68s/it, loss=0.157, v_num=0, reduced_train_loss=0.125, global_step=116.0, val_loss=0.101]\n",
      "Epoch 12:  77%|███████▋  | 10/13 [00:17<00:05,  1.77s/it, loss=0.199, v_num=0, reduced_train_loss=0.181, global_step=116.0, val_loss=0.135]\n",
      "Epoch 12:  92%|█████████▏| 12/13 [00:19<00:01,  1.62s/it, loss=0.157, v_num=0, reduced_train_loss=0.125, global_step=116.0, val_loss=0.101]\n",
      "Epoch 12: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.157, v_num=0, reduced_train_loss=0.125, global_step=116.0, val_loss=0.101]2023-06-01 18:05:44,498 - root - INFO - val_loss: 0.10436573624610901\n",
      "Epoch 12: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.157, v_num=0, reduced_train_loss=0.125, global_step=116.0, val_loss=0.104]\n",
      "Epoch 13:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.157, v_num=0, reduced_train_loss=0.125, global_step=116.0, val_loss=0.104]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:05:44.498316 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.10436573624610901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12:  85%|████████▍ | 11/13 [00:18<00:03,  1.72s/it, loss=0.199, v_num=0, reduced_train_loss=0.181, global_step=116.0, val_loss=0.135]\n",
      "Epoch 12:  92%|█████████▏| 12/13 [00:19<00:01,  1.66s/it, loss=0.199, v_num=0, reduced_train_loss=0.181, global_step=116.0, val_loss=0.135]\n",
      "Epoch 12: 100%|██████████| 13/13 [00:19<00:00,  1.54s/it, loss=0.199, v_num=0, reduced_train_loss=0.181, global_step=116.0, val_loss=0.135]2023-06-01 18:05:45,919 - root - INFO - val_loss: 0.09570994228124619\n",
      "Epoch 12: 100%|██████████| 13/13 [00:19<00:00,  1.54s/it, loss=0.199, v_num=0, reduced_train_loss=0.181, global_step=116.0, val_loss=0.0957]\n",
      "Epoch 13:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.199, v_num=0, reduced_train_loss=0.181, global_step=116.0, val_loss=0.0957]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:05:45.919863 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.09570994228124619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  69%|██████▉   | 9/13 [00:16<00:07,  1.85s/it, loss=0.128, v_num=0, reduced_train_loss=0.134, global_step=125.0, val_loss=0.104]]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13:  69%|██████▉   | 9/13 [00:16<00:07,  1.84s/it, loss=0.194, v_num=0, reduced_train_loss=0.180, global_step=125.0, val_loss=0.0957]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13:  85%|████████▍ | 11/13 [00:18<00:03,  1.69s/it, loss=0.128, v_num=0, reduced_train_loss=0.134, global_step=125.0, val_loss=0.104]\n",
      "Epoch 13:  77%|███████▋  | 10/13 [00:17<00:05,  1.76s/it, loss=0.194, v_num=0, reduced_train_loss=0.180, global_step=125.0, val_loss=0.0957]\n",
      "Epoch 13:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.128, v_num=0, reduced_train_loss=0.134, global_step=125.0, val_loss=0.104]\n",
      "Epoch 13: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.128, v_num=0, reduced_train_loss=0.134, global_step=125.0, val_loss=0.104]2023-06-01 18:06:04,107 - root - INFO - val_loss: 0.09089447557926178\n",
      "Epoch 13: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.128, v_num=0, reduced_train_loss=0.134, global_step=125.0, val_loss=0.0909]\n",
      "Epoch 14:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.128, v_num=0, reduced_train_loss=0.134, global_step=125.0, val_loss=0.0909]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:06:04.107512 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.09089447557926178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13:  85%|████████▍ | 11/13 [00:18<00:03,  1.69s/it, loss=0.194, v_num=0, reduced_train_loss=0.180, global_step=125.0, val_loss=0.0957]\n",
      "Epoch 13:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.194, v_num=0, reduced_train_loss=0.180, global_step=125.0, val_loss=0.0957]\n",
      "Epoch 13: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.194, v_num=0, reduced_train_loss=0.180, global_step=125.0, val_loss=0.0957]2023-06-01 18:06:05,597 - root - INFO - val_loss: 0.11376456916332245\n",
      "Epoch 13: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.194, v_num=0, reduced_train_loss=0.180, global_step=125.0, val_loss=0.114] \n",
      "Epoch 14:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.194, v_num=0, reduced_train_loss=0.180, global_step=125.0, val_loss=0.114]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:06:05.597873 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.11376456916332245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:  69%|██████▉   | 9/13 [00:16<00:07,  1.83s/it, loss=0.126, v_num=0, reduced_train_loss=0.0841, global_step=134.0, val_loss=0.0909]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14:  69%|██████▉   | 9/13 [00:16<00:07,  1.85s/it, loss=0.175, v_num=0, reduced_train_loss=0.132, global_step=134.0, val_loss=0.114]09]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14:  85%|████████▍ | 11/13 [00:18<00:03,  1.68s/it, loss=0.126, v_num=0, reduced_train_loss=0.0841, global_step=134.0, val_loss=0.0909]\n",
      "Epoch 14:  77%|███████▋  | 10/13 [00:17<00:05,  1.77s/it, loss=0.175, v_num=0, reduced_train_loss=0.132, global_step=134.0, val_loss=0.114]\n",
      "Epoch 14:  92%|█████████▏| 12/13 [00:19<00:01,  1.62s/it, loss=0.126, v_num=0, reduced_train_loss=0.0841, global_step=134.0, val_loss=0.0909]\n",
      "Epoch 14: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.126, v_num=0, reduced_train_loss=0.0841, global_step=134.0, val_loss=0.0909]2023-06-01 18:06:23,620 - root - INFO - val_loss: 0.07008767873048782\n",
      "Epoch 14: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.126, v_num=0, reduced_train_loss=0.0841, global_step=134.0, val_loss=0.0701]\n",
      "Epoch 15:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.126, v_num=0, reduced_train_loss=0.0841, global_step=134.0, val_loss=0.0701]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:06:23.620007 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.07008767873048782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14:  85%|████████▍ | 11/13 [00:18<00:03,  1.70s/it, loss=0.175, v_num=0, reduced_train_loss=0.132, global_step=134.0, val_loss=0.114]\n",
      "Epoch 14:  92%|█████████▏| 12/13 [00:19<00:01,  1.64s/it, loss=0.175, v_num=0, reduced_train_loss=0.132, global_step=134.0, val_loss=0.114]\n",
      "Epoch 14: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.175, v_num=0, reduced_train_loss=0.132, global_step=134.0, val_loss=0.114]2023-06-01 18:06:25,328 - root - INFO - val_loss: 0.10617248713970184\n",
      "Epoch 14: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.175, v_num=0, reduced_train_loss=0.132, global_step=134.0, val_loss=0.106]\n",
      "Epoch 15:   8%|▊         | 1/13 [00:01<00:21,  1.82s/it, loss=0.128, v_num=0, reduced_train_loss=0.211, global_step=135.0, val_loss=0.0701] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:06:25.328665 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.10617248713970184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:  69%|██████▉   | 9/13 [00:16<00:07,  1.83s/it, loss=0.118, v_num=0, reduced_train_loss=0.132, global_step=143.0, val_loss=0.0701] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15:  62%|██████▏   | 8/13 [00:14<00:09,  1.86s/it, loss=0.162, v_num=0, reduced_train_loss=0.191, global_step=142.0, val_loss=0.106]\n",
      "Epoch 15:  77%|███████▋  | 10/13 [00:17<00:05,  1.75s/it, loss=0.118, v_num=0, reduced_train_loss=0.132, global_step=143.0, val_loss=0.0701]\n",
      "Epoch 15:  69%|██████▉   | 9/13 [00:16<00:07,  1.86s/it, loss=0.163, v_num=0, reduced_train_loss=0.221, global_step=143.0, val_loss=0.106]1]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15:  92%|█████████▏| 12/13 [00:19<00:01,  1.62s/it, loss=0.118, v_num=0, reduced_train_loss=0.132, global_step=143.0, val_loss=0.0701]\n",
      "Epoch 15: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.118, v_num=0, reduced_train_loss=0.132, global_step=143.0, val_loss=0.0701]\n",
      "Epoch 15:  77%|███████▋  | 10/13 [00:17<00:05,  1.78s/it, loss=0.163, v_num=0, reduced_train_loss=0.221, global_step=143.0, val_loss=0.106]2023-06-01 18:06:43,113 - root - INFO - val_loss: 0.0541568323969841\n",
      "Epoch 15: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.118, v_num=0, reduced_train_loss=0.132, global_step=143.0, val_loss=0.0542]\n",
      "Epoch 16:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.118, v_num=0, reduced_train_loss=0.132, global_step=143.0, val_loss=0.0542]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:06:43.113163 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.0541568323969841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16:   8%|▊         | 1/13 [00:01<00:22,  1.90s/it, loss=0.112, v_num=0, reduced_train_loss=0.0454, global_step=144.0, val_loss=0.0542]\n",
      "Epoch 15:  92%|█████████▏| 12/13 [00:19<00:01,  1.65s/it, loss=0.163, v_num=0, reduced_train_loss=0.221, global_step=143.0, val_loss=0.106]\n",
      "Epoch 15: 100%|██████████| 13/13 [00:19<00:00,  1.53s/it, loss=0.163, v_num=0, reduced_train_loss=0.221, global_step=143.0, val_loss=0.106]2023-06-01 18:06:45,240 - root - INFO - val_loss: 0.08977265655994415\n",
      "Epoch 15: 100%|██████████| 13/13 [00:19<00:00,  1.53s/it, loss=0.163, v_num=0, reduced_train_loss=0.221, global_step=143.0, val_loss=0.0898]\n",
      "Epoch 16:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.163, v_num=0, reduced_train_loss=0.221, global_step=143.0, val_loss=0.0898]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:06:45.240375 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.08977265655994415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  69%|██████▉   | 9/13 [00:16<00:07,  1.85s/it, loss=0.106, v_num=0, reduced_train_loss=0.129, global_step=152.0, val_loss=0.0542] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 16:  62%|██████▏   | 8/13 [00:14<00:09,  1.85s/it, loss=0.154, v_num=0, reduced_train_loss=0.173, global_step=151.0, val_loss=0.0898]\n",
      "Epoch 16:  77%|███████▋  | 10/13 [00:17<00:05,  1.77s/it, loss=0.106, v_num=0, reduced_train_loss=0.129, global_step=152.0, val_loss=0.0542]\n",
      "Epoch 16:  69%|██████▉   | 9/13 [00:16<00:07,  1.85s/it, loss=0.149, v_num=0, reduced_train_loss=0.111, global_step=152.0, val_loss=0.0898]]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 16:  92%|█████████▏| 12/13 [00:19<00:01,  1.64s/it, loss=0.106, v_num=0, reduced_train_loss=0.129, global_step=152.0, val_loss=0.0542]\n",
      "Epoch 16: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.106, v_num=0, reduced_train_loss=0.129, global_step=152.0, val_loss=0.0542]2023-06-01 18:07:02,919 - root - INFO - val_loss: 0.0644853487610817\n",
      "\n",
      "Epoch 16: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.106, v_num=0, reduced_train_loss=0.129, global_step=152.0, val_loss=0.0645]\n",
      "Epoch 17:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.106, v_num=0, reduced_train_loss=0.129, global_step=152.0, val_loss=0.0645]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:07:02.919969 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.0644853487610817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17:   8%|▊         | 1/13 [00:01<00:22,  1.85s/it, loss=0.106, v_num=0, reduced_train_loss=0.0792, global_step=153.0, val_loss=0.0645]\n",
      "Epoch 16:  92%|█████████▏| 12/13 [00:19<00:01,  1.64s/it, loss=0.149, v_num=0, reduced_train_loss=0.111, global_step=152.0, val_loss=0.0898]\n",
      "Epoch 16: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.149, v_num=0, reduced_train_loss=0.111, global_step=152.0, val_loss=0.0898]2023-06-01 18:07:04,977 - root - INFO - val_loss: 0.09590989351272583\n",
      "Epoch 16: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.149, v_num=0, reduced_train_loss=0.111, global_step=152.0, val_loss=0.0959]\n",
      "Epoch 17:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.149, v_num=0, reduced_train_loss=0.111, global_step=152.0, val_loss=0.0959]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:07:04.977424 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.09590989351272583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  69%|██████▉   | 9/13 [00:16<00:07,  1.82s/it, loss=0.106, v_num=0, reduced_train_loss=0.0784, global_step=161.0, val_loss=0.0645] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 17:  62%|██████▏   | 8/13 [00:14<00:09,  1.86s/it, loss=0.147, v_num=0, reduced_train_loss=0.0614, global_step=160.0, val_loss=0.0959]\n",
      "Epoch 17:  77%|███████▋  | 10/13 [00:17<00:05,  1.74s/it, loss=0.106, v_num=0, reduced_train_loss=0.0784, global_step=161.0, val_loss=0.0645]\n",
      "Epoch 17:  69%|██████▉   | 9/13 [00:16<00:07,  1.86s/it, loss=0.142, v_num=0, reduced_train_loss=0.0589, global_step=161.0, val_loss=0.0959]]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 17:  92%|█████████▏| 12/13 [00:19<00:01,  1.61s/it, loss=0.106, v_num=0, reduced_train_loss=0.0784, global_step=161.0, val_loss=0.0645]\n",
      "Epoch 17: 100%|██████████| 13/13 [00:19<00:00,  1.49s/it, loss=0.106, v_num=0, reduced_train_loss=0.0784, global_step=161.0, val_loss=0.0645]2023-06-01 18:07:22,286 - root - INFO - val_loss: 0.051474712789058685\n",
      "Epoch 17: 100%|██████████| 13/13 [00:19<00:00,  1.49s/it, loss=0.106, v_num=0, reduced_train_loss=0.0784, global_step=161.0, val_loss=0.0515]\n",
      "Epoch 18:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.106, v_num=0, reduced_train_loss=0.0784, global_step=161.0, val_loss=0.0515]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:07:22.286593 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.051474712789058685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17:  77%|███████▋  | 10/13 [00:17<00:05,  1.78s/it, loss=0.142, v_num=0, reduced_train_loss=0.0589, global_step=161.0, val_loss=0.0959]\n",
      "Epoch 18:   8%|▊         | 1/13 [00:01<00:22,  1.89s/it, loss=0.106, v_num=0, reduced_train_loss=0.073, global_step=162.0, val_loss=0.0515] ]\n",
      "Epoch 17:  92%|█████████▏| 12/13 [00:19<00:01,  1.65s/it, loss=0.142, v_num=0, reduced_train_loss=0.0589, global_step=161.0, val_loss=0.0959]\n",
      "Epoch 17: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.142, v_num=0, reduced_train_loss=0.0589, global_step=161.0, val_loss=0.0959]2023-06-01 18:07:24,799 - root - INFO - val_loss: 0.08990500867366791\n",
      "Epoch 17: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.142, v_num=0, reduced_train_loss=0.0589, global_step=161.0, val_loss=0.0899]\n",
      "Epoch 18:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.142, v_num=0, reduced_train_loss=0.0589, global_step=161.0, val_loss=0.0899]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:07:24.799031 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.08990500867366791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  69%|██████▉   | 9/13 [00:16<00:07,  1.82s/it, loss=0.102, v_num=0, reduced_train_loss=0.0874, global_step=170.0, val_loss=0.0515]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 18:  62%|██████▏   | 8/13 [00:14<00:09,  1.86s/it, loss=0.133, v_num=0, reduced_train_loss=0.155, global_step=169.0, val_loss=0.0899]5]\n",
      "Epoch 18:  69%|██████▉   | 9/13 [00:16<00:07,  1.86s/it, loss=0.136, v_num=0, reduced_train_loss=0.199, global_step=170.0, val_loss=0.0899]5]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 18:  92%|█████████▏| 12/13 [00:19<00:01,  1.61s/it, loss=0.102, v_num=0, reduced_train_loss=0.0874, global_step=170.0, val_loss=0.0515]\n",
      "Epoch 18: 100%|██████████| 13/13 [00:19<00:00,  1.49s/it, loss=0.102, v_num=0, reduced_train_loss=0.0874, global_step=170.0, val_loss=0.0515]2023-06-01 18:07:41,667 - root - INFO - val_loss: 0.06365110725164413\n",
      "Epoch 18: 100%|██████████| 13/13 [00:19<00:00,  1.49s/it, loss=0.102, v_num=0, reduced_train_loss=0.0874, global_step=170.0, val_loss=0.0637]\n",
      "Epoch 19:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.102, v_num=0, reduced_train_loss=0.0874, global_step=170.0, val_loss=0.0637]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:07:41.667587 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.06365110725164413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19:   8%|▊         | 1/13 [00:01<00:22,  1.91s/it, loss=0.0992, v_num=0, reduced_train_loss=0.0774, global_step=171.0, val_loss=0.0637]\n",
      "Epoch 18:  85%|████████▍ | 11/13 [00:18<00:03,  1.71s/it, loss=0.136, v_num=0, reduced_train_loss=0.199, global_step=170.0, val_loss=0.0899]\n",
      "Epoch 18:  92%|█████████▏| 12/13 [00:19<00:01,  1.65s/it, loss=0.136, v_num=0, reduced_train_loss=0.199, global_step=170.0, val_loss=0.0899]\n",
      "Epoch 18: 100%|██████████| 13/13 [00:19<00:00,  1.53s/it, loss=0.136, v_num=0, reduced_train_loss=0.199, global_step=170.0, val_loss=0.0899]2023-06-01 18:07:44,691 - root - INFO - val_loss: 0.08345378935337067\n",
      "Epoch 18: 100%|██████████| 13/13 [00:19<00:00,  1.53s/it, loss=0.136, v_num=0, reduced_train_loss=0.199, global_step=170.0, val_loss=0.0835]\n",
      "Epoch 19:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.136, v_num=0, reduced_train_loss=0.199, global_step=170.0, val_loss=0.0835]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:07:44.691220 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.08345378935337067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  69%|██████▉   | 9/13 [00:16<00:07,  1.83s/it, loss=0.0997, v_num=0, reduced_train_loss=0.0571, global_step=179.0, val_loss=0.0637]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 19:  62%|██████▏   | 8/13 [00:14<00:09,  1.84s/it, loss=0.13, v_num=0, reduced_train_loss=0.200, global_step=178.0, val_loss=0.0835] 37]\n",
      "Epoch 19:  85%|████████▍ | 11/13 [00:18<00:03,  1.68s/it, loss=0.0997, v_num=0, reduced_train_loss=0.0571, global_step=179.0, val_loss=0.0637]\n",
      "Epoch 19:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.0997, v_num=0, reduced_train_loss=0.0571, global_step=179.0, val_loss=0.0637]\n",
      "Epoch 19:  69%|██████▉   | 9/13 [00:16<00:07,  1.84s/it, loss=0.13, v_num=0, reduced_train_loss=0.200, global_step=178.0, val_loss=0.0835]2023-06-01 18:08:01,260 - root - INFO - val_loss: 0.05994737520813942\n",
      "Epoch 19: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0997, v_num=0, reduced_train_loss=0.0571, global_step=179.0, val_loss=0.0599]\n",
      "Epoch 20:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0997, v_num=0, reduced_train_loss=0.0571, global_step=179.0, val_loss=0.0599]         \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:08:01.260590 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.05994737520813942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20:   8%|▊         | 1/13 [00:01<00:22,  1.86s/it, loss=0.0973, v_num=0, reduced_train_loss=0.138, global_step=180.0, val_loss=0.0599] \n",
      "Epoch 19:  85%|████████▍ | 11/13 [00:18<00:03,  1.69s/it, loss=0.131, v_num=0, reduced_train_loss=0.173, global_step=179.0, val_loss=0.0835]\n",
      "Epoch 19:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.131, v_num=0, reduced_train_loss=0.173, global_step=179.0, val_loss=0.0835]\n",
      "Epoch 19: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.131, v_num=0, reduced_train_loss=0.173, global_step=179.0, val_loss=0.0835]2023-06-01 18:08:04,390 - root - INFO - val_loss: 0.07826338708400726\n",
      "Epoch 19: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.131, v_num=0, reduced_train_loss=0.173, global_step=179.0, val_loss=0.0783]\n",
      "Epoch 20:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.131, v_num=0, reduced_train_loss=0.173, global_step=179.0, val_loss=0.0783]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:08:04.390181 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.07826338708400726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  69%|██████▉   | 9/13 [00:16<00:07,  1.85s/it, loss=0.101, v_num=0, reduced_train_loss=0.182, global_step=188.0, val_loss=0.0599]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 20:  62%|██████▏   | 8/13 [00:14<00:09,  1.85s/it, loss=0.134, v_num=0, reduced_train_loss=0.148, global_step=187.0, val_loss=0.0783]]\n",
      "Epoch 20:  85%|████████▍ | 11/13 [00:18<00:03,  1.69s/it, loss=0.101, v_num=0, reduced_train_loss=0.182, global_step=188.0, val_loss=0.0599]\n",
      "Epoch 20:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.101, v_num=0, reduced_train_loss=0.182, global_step=188.0, val_loss=0.0599]\n",
      "Epoch 20: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.101, v_num=0, reduced_train_loss=0.182, global_step=188.0, val_loss=0.0599]2023-06-01 18:08:20,892 - root - INFO - val_loss: 0.08986059576272964\n",
      "Epoch 20: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.101, v_num=0, reduced_train_loss=0.182, global_step=188.0, val_loss=0.0899]\n",
      "Epoch 21:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.101, v_num=0, reduced_train_loss=0.182, global_step=188.0, val_loss=0.0899]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:08:20.892435 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.08986059576272964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  69%|██████▉   | 9/13 [00:16<00:07,  1.85s/it, loss=0.131, v_num=0, reduced_train_loss=0.0903, global_step=188.0, val_loss=0.0783]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 21:   8%|▊         | 1/13 [00:01<00:23,  1.93s/it, loss=0.11, v_num=0, reduced_train_loss=0.223, global_step=189.0, val_loss=0.0899] 3]\n",
      "Epoch 20:  85%|████████▍ | 11/13 [00:18<00:03,  1.70s/it, loss=0.131, v_num=0, reduced_train_loss=0.0903, global_step=188.0, val_loss=0.0783]\n",
      "Epoch 20:  92%|█████████▏| 12/13 [00:19<00:01,  1.64s/it, loss=0.131, v_num=0, reduced_train_loss=0.0903, global_step=188.0, val_loss=0.0783]\n",
      "Epoch 20: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.131, v_num=0, reduced_train_loss=0.0903, global_step=188.0, val_loss=0.0783]2023-06-01 18:08:24,111 - root - INFO - val_loss: 0.09582322090864182\n",
      "Epoch 20: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.131, v_num=0, reduced_train_loss=0.0903, global_step=188.0, val_loss=0.0958]\n",
      "Epoch 21:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.131, v_num=0, reduced_train_loss=0.0903, global_step=188.0, val_loss=0.0958]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:08:24.111446 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.09582322090864182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  69%|██████▉   | 9/13 [00:16<00:07,  1.84s/it, loss=0.119, v_num=0, reduced_train_loss=0.111, global_step=197.0, val_loss=0.0899] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 21:  62%|██████▏   | 8/13 [00:14<00:09,  1.84s/it, loss=0.129, v_num=0, reduced_train_loss=0.126, global_step=196.0, val_loss=0.0958]]\n",
      "Epoch 21:  85%|████████▍ | 11/13 [00:18<00:03,  1.68s/it, loss=0.119, v_num=0, reduced_train_loss=0.111, global_step=197.0, val_loss=0.0899]\n",
      "Epoch 21:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.119, v_num=0, reduced_train_loss=0.111, global_step=197.0, val_loss=0.0899]\n",
      "Epoch 21: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.119, v_num=0, reduced_train_loss=0.111, global_step=197.0, val_loss=0.0899]2023-06-01 18:08:40,503 - root - INFO - val_loss: 0.05841206759214401\n",
      "Epoch 21: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.119, v_num=0, reduced_train_loss=0.111, global_step=197.0, val_loss=0.0584]\n",
      "Epoch 22:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.119, v_num=0, reduced_train_loss=0.111, global_step=197.0, val_loss=0.0584]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:08:40.503492 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.05841206759214401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  69%|██████▉   | 9/13 [00:16<00:07,  1.84s/it, loss=0.123, v_num=0, reduced_train_loss=0.0722, global_step=197.0, val_loss=0.0958]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 22:   8%|▊         | 1/13 [00:01<00:22,  1.87s/it, loss=0.117, v_num=0, reduced_train_loss=0.102, global_step=198.0, val_loss=0.0584]8]\n",
      "Epoch 21:  85%|████████▍ | 11/13 [00:18<00:03,  1.69s/it, loss=0.123, v_num=0, reduced_train_loss=0.0722, global_step=197.0, val_loss=0.0958]\n",
      "Epoch 21:  92%|█████████▏| 12/13 [00:19<00:01,  1.62s/it, loss=0.123, v_num=0, reduced_train_loss=0.0722, global_step=197.0, val_loss=0.0958]\n",
      "Epoch 21: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.123, v_num=0, reduced_train_loss=0.0722, global_step=197.0, val_loss=0.0958]2023-06-01 18:08:43,687 - root - INFO - val_loss: 0.08032045513391495\n",
      "Epoch 21: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.123, v_num=0, reduced_train_loss=0.0722, global_step=197.0, val_loss=0.0803]\n",
      "Epoch 22:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.123, v_num=0, reduced_train_loss=0.0722, global_step=197.0, val_loss=0.0803]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:08:43.687682 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.08032045513391495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  69%|██████▉   | 9/13 [00:16<00:07,  1.88s/it, loss=0.128, v_num=0, reduced_train_loss=0.116, global_step=206.0, val_loss=0.0584] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 22:  62%|██████▏   | 8/13 [00:14<00:09,  1.84s/it, loss=0.131, v_num=0, reduced_train_loss=0.136, global_step=205.0, val_loss=0.0803]]\n",
      "Epoch 22:  69%|██████▉   | 9/13 [00:16<00:07,  1.84s/it, loss=0.132, v_num=0, reduced_train_loss=0.147, global_step=206.0, val_loss=0.0803]]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 22:  92%|█████████▏| 12/13 [00:19<00:01,  1.65s/it, loss=0.128, v_num=0, reduced_train_loss=0.116, global_step=206.0, val_loss=0.0584]\n",
      "Epoch 22: 100%|██████████| 13/13 [00:19<00:00,  1.53s/it, loss=0.128, v_num=0, reduced_train_loss=0.116, global_step=206.0, val_loss=0.0584]2023-06-01 18:09:00,423 - root - INFO - val_loss: 0.053931303322315216\n",
      "Epoch 22: 100%|██████████| 13/13 [00:19<00:00,  1.53s/it, loss=0.128, v_num=0, reduced_train_loss=0.116, global_step=206.0, val_loss=0.0539]\n",
      "Epoch 23:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.128, v_num=0, reduced_train_loss=0.116, global_step=206.0, val_loss=0.0539]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:09:00.423516 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.053931303322315216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22:  77%|███████▋  | 10/13 [00:17<00:05,  1.76s/it, loss=0.132, v_num=0, reduced_train_loss=0.147, global_step=206.0, val_loss=0.0803]\n",
      "Epoch 23:   8%|▊         | 1/13 [00:01<00:23,  1.95s/it, loss=0.125, v_num=0, reduced_train_loss=0.0787, global_step=207.0, val_loss=0.0539]\n",
      "Epoch 22:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.132, v_num=0, reduced_train_loss=0.147, global_step=206.0, val_loss=0.0803]\n",
      "Epoch 22: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.132, v_num=0, reduced_train_loss=0.147, global_step=206.0, val_loss=0.0803]2023-06-01 18:09:03,338 - root - INFO - val_loss: 0.10133230686187744\n",
      "Epoch 22: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.132, v_num=0, reduced_train_loss=0.147, global_step=206.0, val_loss=0.101] \n",
      "Epoch 23:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.132, v_num=0, reduced_train_loss=0.147, global_step=206.0, val_loss=0.101]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:09:03.338592 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.10133230686187744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  69%|██████▉   | 9/13 [00:16<00:07,  1.85s/it, loss=0.114, v_num=0, reduced_train_loss=0.0967, global_step=215.0, val_loss=0.0539]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 23:  62%|██████▏   | 8/13 [00:14<00:09,  1.85s/it, loss=0.13, v_num=0, reduced_train_loss=0.0818, global_step=214.0, val_loss=0.101] \n",
      "Epoch 23:  77%|███████▋  | 10/13 [00:17<00:05,  1.78s/it, loss=0.114, v_num=0, reduced_train_loss=0.0967, global_step=215.0, val_loss=0.0539]\n",
      "Epoch 23:  69%|██████▉   | 9/13 [00:16<00:07,  1.86s/it, loss=0.129, v_num=0, reduced_train_loss=0.146, global_step=215.0, val_loss=0.101]39]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 23:  92%|█████████▏| 12/13 [00:19<00:01,  1.65s/it, loss=0.114, v_num=0, reduced_train_loss=0.0967, global_step=215.0, val_loss=0.0539]\n",
      "Epoch 23: 100%|██████████| 13/13 [00:19<00:00,  1.53s/it, loss=0.114, v_num=0, reduced_train_loss=0.0967, global_step=215.0, val_loss=0.0539]2023-06-01 18:09:20,305 - root - INFO - val_loss: 0.048957034945487976\n",
      "Epoch 23: 100%|██████████| 13/13 [00:19<00:00,  1.53s/it, loss=0.114, v_num=0, reduced_train_loss=0.0967, global_step=215.0, val_loss=0.049] \n",
      "Epoch 24:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.114, v_num=0, reduced_train_loss=0.0967, global_step=215.0, val_loss=0.049]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:09:20.305953 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.048957034945487976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23:  77%|███████▋  | 10/13 [00:17<00:05,  1.78s/it, loss=0.129, v_num=0, reduced_train_loss=0.146, global_step=215.0, val_loss=0.101]\n",
      "Epoch 24:   8%|▊         | 1/13 [00:01<00:22,  1.86s/it, loss=0.115, v_num=0, reduced_train_loss=0.141, global_step=216.0, val_loss=0.049] \n",
      "Epoch 23:  92%|█████████▏| 12/13 [00:19<00:01,  1.65s/it, loss=0.129, v_num=0, reduced_train_loss=0.146, global_step=215.0, val_loss=0.101]\n",
      "Epoch 23: 100%|██████████| 13/13 [00:19<00:00,  1.53s/it, loss=0.129, v_num=0, reduced_train_loss=0.146, global_step=215.0, val_loss=0.101]2023-06-01 18:09:23,219 - root - INFO - val_loss: 0.08367011696100235\n",
      "Epoch 23: 100%|██████████| 13/13 [00:19<00:00,  1.53s/it, loss=0.129, v_num=0, reduced_train_loss=0.146, global_step=215.0, val_loss=0.0837]\n",
      "Epoch 24:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.129, v_num=0, reduced_train_loss=0.146, global_step=215.0, val_loss=0.0837]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:09:23.219537 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.08367011696100235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24:  69%|██████▉   | 9/13 [00:16<00:07,  1.82s/it, loss=0.106, v_num=0, reduced_train_loss=0.0582, global_step=224.0, val_loss=0.049] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 24:  62%|██████▏   | 8/13 [00:15<00:09,  1.89s/it, loss=0.111, v_num=0, reduced_train_loss=0.113, global_step=223.0, val_loss=0.0837]]\n",
      "Epoch 24:  85%|████████▍ | 11/13 [00:18<00:03,  1.66s/it, loss=0.106, v_num=0, reduced_train_loss=0.0582, global_step=224.0, val_loss=0.049]\n",
      "Epoch 24:  92%|█████████▏| 12/13 [00:19<00:01,  1.60s/it, loss=0.106, v_num=0, reduced_train_loss=0.0582, global_step=224.0, val_loss=0.049]\n",
      "Epoch 24: 100%|██████████| 13/13 [00:19<00:00,  1.48s/it, loss=0.106, v_num=0, reduced_train_loss=0.0582, global_step=224.0, val_loss=0.049]2023-06-01 18:09:39,627 - root - INFO - val_loss: 0.047372132539749146\n",
      "Epoch 24: 100%|██████████| 13/13 [00:19<00:00,  1.49s/it, loss=0.106, v_num=0, reduced_train_loss=0.0582, global_step=224.0, val_loss=0.0474]\n",
      "Epoch 25:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.106, v_num=0, reduced_train_loss=0.0582, global_step=224.0, val_loss=0.0474]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:09:39.627806 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.047372132539749146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24:  69%|██████▉   | 9/13 [00:16<00:07,  1.88s/it, loss=0.108, v_num=0, reduced_train_loss=0.0782, global_step=224.0, val_loss=0.0837]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 25:   8%|▊         | 1/13 [00:01<00:23,  1.95s/it, loss=0.103, v_num=0, reduced_train_loss=0.122, global_step=225.0, val_loss=0.0474] ]\n",
      "Epoch 24:  85%|████████▍ | 11/13 [00:18<00:03,  1.72s/it, loss=0.108, v_num=0, reduced_train_loss=0.0782, global_step=224.0, val_loss=0.0837]\n",
      "Epoch 24:  92%|█████████▏| 12/13 [00:19<00:01,  1.65s/it, loss=0.108, v_num=0, reduced_train_loss=0.0782, global_step=224.0, val_loss=0.0837]\n",
      "Epoch 24: 100%|██████████| 13/13 [00:19<00:00,  1.53s/it, loss=0.108, v_num=0, reduced_train_loss=0.0782, global_step=224.0, val_loss=0.0837]2023-06-01 18:09:43,149 - root - INFO - val_loss: 0.06828837096691132\n",
      "Epoch 24: 100%|██████████| 13/13 [00:19<00:00,  1.53s/it, loss=0.108, v_num=0, reduced_train_loss=0.0782, global_step=224.0, val_loss=0.0683]\n",
      "Epoch 25:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.108, v_num=0, reduced_train_loss=0.0782, global_step=224.0, val_loss=0.0683]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:09:43.149822 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.06828837096691132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25:  69%|██████▉   | 9/13 [00:16<00:07,  1.84s/it, loss=0.089, v_num=0, reduced_train_loss=0.090, global_step=233.0, val_loss=0.0474]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 25:  62%|██████▏   | 8/13 [00:14<00:09,  1.85s/it, loss=0.1, v_num=0, reduced_train_loss=0.0598, global_step=232.0, val_loss=0.0683]  \n",
      "Epoch 25:  85%|████████▍ | 11/13 [00:18<00:03,  1.70s/it, loss=0.089, v_num=0, reduced_train_loss=0.090, global_step=233.0, val_loss=0.0474]\n",
      "Epoch 25:  92%|█████████▏| 12/13 [00:19<00:01,  1.64s/it, loss=0.089, v_num=0, reduced_train_loss=0.090, global_step=233.0, val_loss=0.0474]\n",
      "Epoch 25: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.089, v_num=0, reduced_train_loss=0.090, global_step=233.0, val_loss=0.0474]2023-06-01 18:09:59,349 - root - INFO - val_loss: 0.04980413615703583\n",
      "Epoch 25: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.089, v_num=0, reduced_train_loss=0.090, global_step=233.0, val_loss=0.0498]\n",
      "Epoch 26:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.089, v_num=0, reduced_train_loss=0.090, global_step=233.0, val_loss=0.0498]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:09:59.349560 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.04980413615703583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25:  69%|██████▉   | 9/13 [00:16<00:07,  1.85s/it, loss=0.104, v_num=0, reduced_train_loss=0.162, global_step=233.0, val_loss=0.0683]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 26:   8%|▊         | 1/13 [00:01<00:23,  1.92s/it, loss=0.0892, v_num=0, reduced_train_loss=0.0912, global_step=234.0, val_loss=0.0498]\n",
      "Epoch 25:  85%|████████▍ | 11/13 [00:18<00:03,  1.70s/it, loss=0.104, v_num=0, reduced_train_loss=0.162, global_step=233.0, val_loss=0.0683]\n",
      "Epoch 25:  92%|█████████▏| 12/13 [00:19<00:01,  1.64s/it, loss=0.104, v_num=0, reduced_train_loss=0.162, global_step=233.0, val_loss=0.0683]\n",
      "Epoch 25: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.104, v_num=0, reduced_train_loss=0.162, global_step=233.0, val_loss=0.0683]2023-06-01 18:10:02,883 - root - INFO - val_loss: 0.06904532015323639\n",
      "Epoch 25: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.104, v_num=0, reduced_train_loss=0.162, global_step=233.0, val_loss=0.069] \n",
      "Epoch 26:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.104, v_num=0, reduced_train_loss=0.162, global_step=233.0, val_loss=0.069]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:10:02.883841 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.06904532015323639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26:  69%|██████▉   | 9/13 [00:16<00:07,  1.87s/it, loss=0.0792, v_num=0, reduced_train_loss=0.0858, global_step=242.0, val_loss=0.0498]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 26:  62%|██████▏   | 8/13 [00:14<00:09,  1.83s/it, loss=0.097, v_num=0, reduced_train_loss=0.0436, global_step=241.0, val_loss=0.069]98]\n",
      "Epoch 26:  85%|████████▍ | 11/13 [00:18<00:03,  1.71s/it, loss=0.0792, v_num=0, reduced_train_loss=0.0858, global_step=242.0, val_loss=0.0498]\n",
      "Epoch 26:  92%|█████████▏| 12/13 [00:19<00:01,  1.64s/it, loss=0.0792, v_num=0, reduced_train_loss=0.0858, global_step=242.0, val_loss=0.0498]\n",
      "Epoch 26: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.0792, v_num=0, reduced_train_loss=0.0858, global_step=242.0, val_loss=0.0498]2023-06-01 18:10:19,161 - root - INFO - val_loss: 0.0479462705552578\n",
      "Epoch 26: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.0792, v_num=0, reduced_train_loss=0.0858, global_step=242.0, val_loss=0.0479]\n",
      "Epoch 27:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0792, v_num=0, reduced_train_loss=0.0858, global_step=242.0, val_loss=0.0479]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:10:19.161563 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.0479462705552578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26:  69%|██████▉   | 9/13 [00:16<00:07,  1.83s/it, loss=0.0974, v_num=0, reduced_train_loss=0.132, global_step=242.0, val_loss=0.069]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 27:   8%|▊         | 1/13 [00:01<00:22,  1.90s/it, loss=0.0769, v_num=0, reduced_train_loss=0.0758, global_step=243.0, val_loss=0.0479]\n",
      "Epoch 26:  85%|████████▍ | 11/13 [00:18<00:03,  1.68s/it, loss=0.0974, v_num=0, reduced_train_loss=0.132, global_step=242.0, val_loss=0.069]\n",
      "Epoch 26:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.0974, v_num=0, reduced_train_loss=0.132, global_step=242.0, val_loss=0.069]\n",
      "Epoch 26: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0974, v_num=0, reduced_train_loss=0.132, global_step=242.0, val_loss=0.069]2023-06-01 18:10:22,501 - root - INFO - val_loss: 0.08676748722791672\n",
      "Epoch 26: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0974, v_num=0, reduced_train_loss=0.132, global_step=242.0, val_loss=0.0868]\n",
      "Epoch 27:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0974, v_num=0, reduced_train_loss=0.132, global_step=242.0, val_loss=0.0868]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:10:22.501736 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.08676748722791672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27:  69%|██████▉   | 9/13 [00:16<00:07,  1.84s/it, loss=0.0787, v_num=0, reduced_train_loss=0.0561, global_step=251.0, val_loss=0.0479]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 27:  62%|██████▏   | 8/13 [00:14<00:09,  1.83s/it, loss=0.0834, v_num=0, reduced_train_loss=0.0551, global_step=250.0, val_loss=0.0868]]\n",
      "Epoch 27:  85%|████████▍ | 11/13 [00:18<00:03,  1.69s/it, loss=0.0787, v_num=0, reduced_train_loss=0.0561, global_step=251.0, val_loss=0.0479]\n",
      "Epoch 27:  92%|█████████▏| 12/13 [00:19<00:01,  1.62s/it, loss=0.0787, v_num=0, reduced_train_loss=0.0561, global_step=251.0, val_loss=0.0479]\n",
      "Epoch 27: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.0787, v_num=0, reduced_train_loss=0.0561, global_step=251.0, val_loss=0.0479]2023-06-01 18:10:38,734 - root - INFO - val_loss: 0.060201387852430344\n",
      "Epoch 27: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0787, v_num=0, reduced_train_loss=0.0561, global_step=251.0, val_loss=0.0602]\n",
      "Epoch 28:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0787, v_num=0, reduced_train_loss=0.0561, global_step=251.0, val_loss=0.0602]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:10:38.734540 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.060201387852430344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27:  69%|██████▉   | 9/13 [00:16<00:07,  1.83s/it, loss=0.0857, v_num=0, reduced_train_loss=0.0866, global_step=251.0, val_loss=0.0868]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 28:   8%|▊         | 1/13 [00:01<00:23,  1.99s/it, loss=0.0819, v_num=0, reduced_train_loss=0.112, global_step=252.0, val_loss=0.0602] ]\n",
      "Epoch 27:  85%|████████▍ | 11/13 [00:18<00:03,  1.68s/it, loss=0.0857, v_num=0, reduced_train_loss=0.0866, global_step=251.0, val_loss=0.0868]\n",
      "Epoch 27:  92%|█████████▏| 12/13 [00:19<00:01,  1.62s/it, loss=0.0857, v_num=0, reduced_train_loss=0.0866, global_step=251.0, val_loss=0.0868]\n",
      "Epoch 27: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.0857, v_num=0, reduced_train_loss=0.0866, global_step=251.0, val_loss=0.0868]2023-06-01 18:10:42,048 - root - INFO - val_loss: 0.06863566488027573\n",
      "Epoch 27: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.0857, v_num=0, reduced_train_loss=0.0866, global_step=251.0, val_loss=0.0686]\n",
      "Epoch 28:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0857, v_num=0, reduced_train_loss=0.0866, global_step=251.0, val_loss=0.0686]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:10:42.048174 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.06863566488027573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28:  69%|██████▉   | 9/13 [00:16<00:07,  1.88s/it, loss=0.0784, v_num=0, reduced_train_loss=0.0436, global_step=260.0, val_loss=0.0602]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 28:  62%|██████▏   | 8/13 [00:14<00:09,  1.84s/it, loss=0.08, v_num=0, reduced_train_loss=0.0942, global_step=259.0, val_loss=0.0686] 2]\n",
      "Epoch 28:  85%|████████▍ | 11/13 [00:18<00:03,  1.72s/it, loss=0.0784, v_num=0, reduced_train_loss=0.0436, global_step=260.0, val_loss=0.0602]\n",
      "Epoch 28:  69%|██████▉   | 9/13 [00:16<00:07,  1.84s/it, loss=0.0774, v_num=0, reduced_train_loss=0.0831, global_step=260.0, val_loss=0.0686]]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 28: 100%|██████████| 13/13 [00:19<00:00,  1.53s/it, loss=0.0784, v_num=0, reduced_train_loss=0.0436, global_step=260.0, val_loss=0.0602]\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A2023-06-01 18:10:58,664 - root - INFO - val_loss: 0.042932722717523575\n",
      "Epoch 28: 100%|██████████| 13/13 [00:19<00:00,  1.53s/it, loss=0.0784, v_num=0, reduced_train_loss=0.0436, global_step=260.0, val_loss=0.0429]\n",
      "Epoch 29:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0784, v_num=0, reduced_train_loss=0.0436, global_step=260.0, val_loss=0.0429]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:10:58.664318 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.042932722717523575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29:   8%|▊         | 1/13 [00:01<00:21,  1.83s/it, loss=0.0778, v_num=0, reduced_train_loss=0.0278, global_step=261.0, val_loss=0.0429]]\n",
      "Epoch 28:  85%|████████▍ | 11/13 [00:18<00:03,  1.70s/it, loss=0.0774, v_num=0, reduced_train_loss=0.0831, global_step=260.0, val_loss=0.0686]\n",
      "Epoch 28:  92%|█████████▏| 12/13 [00:19<00:01,  1.64s/it, loss=0.0774, v_num=0, reduced_train_loss=0.0831, global_step=260.0, val_loss=0.0686]\n",
      "Epoch 28: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.0774, v_num=0, reduced_train_loss=0.0831, global_step=260.0, val_loss=0.0686]2023-06-01 18:11:01,776 - root - INFO - val_loss: 0.07661425322294235\n",
      "Epoch 28: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.0774, v_num=0, reduced_train_loss=0.0831, global_step=260.0, val_loss=0.0766]\n",
      "Epoch 29:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0774, v_num=0, reduced_train_loss=0.0831, global_step=260.0, val_loss=0.0766]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:11:01.776426 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.07661425322294235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29:  69%|██████▉   | 9/13 [00:16<00:07,  1.85s/it, loss=0.0774, v_num=0, reduced_train_loss=0.0934, global_step=269.0, val_loss=0.0429]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 29:  62%|██████▏   | 8/13 [00:14<00:09,  1.83s/it, loss=0.0807, v_num=0, reduced_train_loss=0.131, global_step=268.0, val_loss=0.0766] ]\n",
      "Epoch 29:  85%|████████▍ | 11/13 [00:18<00:03,  1.69s/it, loss=0.0774, v_num=0, reduced_train_loss=0.0934, global_step=269.0, val_loss=0.0429]\n",
      "Epoch 29:  92%|█████████▏| 12/13 [00:19<00:01,  1.62s/it, loss=0.0774, v_num=0, reduced_train_loss=0.0934, global_step=269.0, val_loss=0.0429]\n",
      "Epoch 29:  69%|██████▉   | 9/13 [00:16<00:07,  1.83s/it, loss=0.0851, v_num=0, reduced_train_loss=0.177, global_step=269.0, val_loss=0.0766]2023-06-01 18:11:18,241 - root - INFO - val_loss: 0.048060305416584015\n",
      "\n",
      "Epoch 29: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0774, v_num=0, reduced_train_loss=0.0934, global_step=269.0, val_loss=0.0481]\n",
      "Epoch 30:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0774, v_num=0, reduced_train_loss=0.0934, global_step=269.0, val_loss=0.0481]         \n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:11:18.241319 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.048060305416584015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30:   8%|▊         | 1/13 [00:01<00:22,  1.85s/it, loss=0.0741, v_num=0, reduced_train_loss=0.0342, global_step=270.0, val_loss=0.0481]\n",
      "Epoch 29:  85%|████████▍ | 11/13 [00:18<00:03,  1.69s/it, loss=0.0851, v_num=0, reduced_train_loss=0.177, global_step=269.0, val_loss=0.0766]\n",
      "Epoch 29:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.0851, v_num=0, reduced_train_loss=0.177, global_step=269.0, val_loss=0.0766]\n",
      "Epoch 29: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0851, v_num=0, reduced_train_loss=0.177, global_step=269.0, val_loss=0.0766]2023-06-01 18:11:21,429 - root - INFO - val_loss: 0.0540040023624897\n",
      "Epoch 29: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0851, v_num=0, reduced_train_loss=0.177, global_step=269.0, val_loss=0.054] \n",
      "Epoch 30:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0851, v_num=0, reduced_train_loss=0.177, global_step=269.0, val_loss=0.054]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:11:21.429900 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.0540040023624897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30:  69%|██████▉   | 9/13 [00:16<00:07,  1.83s/it, loss=0.0794, v_num=0, reduced_train_loss=0.114, global_step=278.0, val_loss=0.0481] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 30:  62%|██████▏   | 8/13 [00:14<00:09,  1.85s/it, loss=0.0924, v_num=0, reduced_train_loss=0.069, global_step=277.0, val_loss=0.054]1]\n",
      "Epoch 30:  85%|████████▍ | 11/13 [00:18<00:03,  1.68s/it, loss=0.0794, v_num=0, reduced_train_loss=0.114, global_step=278.0, val_loss=0.0481]\n",
      "Epoch 30:  92%|█████████▏| 12/13 [00:19<00:01,  1.61s/it, loss=0.0794, v_num=0, reduced_train_loss=0.114, global_step=278.0, val_loss=0.0481]\n",
      "Epoch 30: 100%|██████████| 13/13 [00:19<00:00,  1.49s/it, loss=0.0794, v_num=0, reduced_train_loss=0.114, global_step=278.0, val_loss=0.0481]2023-06-01 18:11:37,685 - root - INFO - val_loss: 0.03813297301530838\n",
      "Epoch 30: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.0794, v_num=0, reduced_train_loss=0.114, global_step=278.0, val_loss=0.0381]\n",
      "Epoch 31:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0794, v_num=0, reduced_train_loss=0.114, global_step=278.0, val_loss=0.0381]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:11:37.685600 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.03813297301530838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30:  69%|██████▉   | 9/13 [00:16<00:07,  1.85s/it, loss=0.0912, v_num=0, reduced_train_loss=0.0654, global_step=278.0, val_loss=0.054]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 31:   8%|▊         | 1/13 [00:01<00:22,  1.90s/it, loss=0.0781, v_num=0, reduced_train_loss=0.0434, global_step=279.0, val_loss=0.0381]\n",
      "Epoch 30:  85%|████████▍ | 11/13 [00:18<00:03,  1.70s/it, loss=0.0912, v_num=0, reduced_train_loss=0.0654, global_step=278.0, val_loss=0.054]\n",
      "Epoch 30:  92%|█████████▏| 12/13 [00:19<00:01,  1.64s/it, loss=0.0912, v_num=0, reduced_train_loss=0.0654, global_step=278.0, val_loss=0.054]\n",
      "Epoch 30: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.0912, v_num=0, reduced_train_loss=0.0654, global_step=278.0, val_loss=0.054]2023-06-01 18:11:41,187 - root - INFO - val_loss: 0.06673140823841095\n",
      "Epoch 30: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.0912, v_num=0, reduced_train_loss=0.0654, global_step=278.0, val_loss=0.0667]\n",
      "Epoch 31:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0912, v_num=0, reduced_train_loss=0.0654, global_step=278.0, val_loss=0.0667]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:11:41.187021 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.06673140823841095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31:  69%|██████▉   | 9/13 [00:16<00:07,  1.82s/it, loss=0.0739, v_num=0, reduced_train_loss=0.0325, global_step=287.0, val_loss=0.0381]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 31:  54%|█████▍    | 7/13 [00:13<00:11,  1.86s/it, loss=0.0888, v_num=0, reduced_train_loss=0.126, global_step=285.0, val_loss=0.0667] \n",
      "Epoch 31:  77%|███████▋  | 10/13 [00:17<00:05,  1.74s/it, loss=0.0739, v_num=0, reduced_train_loss=0.0325, global_step=287.0, val_loss=0.0381]\n",
      "Epoch 31:  62%|██████▏   | 8/13 [00:14<00:09,  1.86s/it, loss=0.0882, v_num=0, reduced_train_loss=0.0348, global_step=286.0, val_loss=0.0667]]\n",
      "Epoch 31:  92%|█████████▏| 12/13 [00:19<00:01,  1.61s/it, loss=0.0739, v_num=0, reduced_train_loss=0.0325, global_step=287.0, val_loss=0.0381]\n",
      "Epoch 31: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.0739, v_num=0, reduced_train_loss=0.0325, global_step=287.0, val_loss=0.0381]2023-06-01 18:11:57,141 - root - INFO - val_loss: 0.0388767346739769\n",
      "Epoch 31: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.0739, v_num=0, reduced_train_loss=0.0325, global_step=287.0, val_loss=0.0389]\n",
      "Epoch 32:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0739, v_num=0, reduced_train_loss=0.0325, global_step=287.0, val_loss=0.0389]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:11:57.141323 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.0388767346739769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31:  69%|██████▉   | 9/13 [00:16<00:07,  1.86s/it, loss=0.0875, v_num=0, reduced_train_loss=0.0822, global_step=287.0, val_loss=0.0667]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 32:   8%|▊         | 1/13 [00:01<00:22,  1.91s/it, loss=0.0762, v_num=0, reduced_train_loss=0.0778, global_step=288.0, val_loss=0.0389]]\n",
      "Epoch 32:  15%|█▌        | 2/13 [00:03<00:20,  1.84s/it, loss=0.0761, v_num=0, reduced_train_loss=0.0906, global_step=289.0, val_loss=0.0389]]\n",
      "Epoch 31:  92%|█████████▏| 12/13 [00:19<00:01,  1.65s/it, loss=0.0875, v_num=0, reduced_train_loss=0.0822, global_step=287.0, val_loss=0.0667]\n",
      "Epoch 31: 100%|██████████| 13/13 [00:19<00:00,  1.53s/it, loss=0.0875, v_num=0, reduced_train_loss=0.0822, global_step=287.0, val_loss=0.0667]2023-06-01 18:12:01,070 - root - INFO - val_loss: 0.06519195437431335\n",
      "Epoch 31: 100%|██████████| 13/13 [00:19<00:00,  1.53s/it, loss=0.0875, v_num=0, reduced_train_loss=0.0822, global_step=287.0, val_loss=0.0652]\n",
      "Epoch 32:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0875, v_num=0, reduced_train_loss=0.0822, global_step=287.0, val_loss=0.0652]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:12:01.070364 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.06519195437431335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32:  69%|██████▉   | 9/13 [00:16<00:07,  1.83s/it, loss=0.0765, v_num=0, reduced_train_loss=0.0361, global_step=296.0, val_loss=0.0389]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 32:  54%|█████▍    | 7/13 [00:12<00:11,  1.85s/it, loss=0.0818, v_num=0, reduced_train_loss=0.119, global_step=294.0, val_loss=0.0652] \n",
      "Epoch 32:  77%|███████▋  | 10/13 [00:17<00:05,  1.75s/it, loss=0.0765, v_num=0, reduced_train_loss=0.0361, global_step=296.0, val_loss=0.0389]\n",
      "Epoch 32:  62%|██████▏   | 8/13 [00:14<00:09,  1.86s/it, loss=0.0816, v_num=0, reduced_train_loss=0.081, global_step=295.0, val_loss=0.0652]9]\n",
      "Epoch 32:  92%|█████████▏| 12/13 [00:19<00:01,  1.62s/it, loss=0.0765, v_num=0, reduced_train_loss=0.0361, global_step=296.0, val_loss=0.0389]\n",
      "Epoch 32: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.0765, v_num=0, reduced_train_loss=0.0361, global_step=296.0, val_loss=0.0389]2023-06-01 18:12:16,687 - root - INFO - val_loss: 0.03998851031064987\n",
      "Epoch 32: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.0765, v_num=0, reduced_train_loss=0.0361, global_step=296.0, val_loss=0.040] \n",
      "Epoch 33:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0765, v_num=0, reduced_train_loss=0.0361, global_step=296.0, val_loss=0.040]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:12:16.687155 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.03998851031064987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32:  69%|██████▉   | 9/13 [00:16<00:07,  1.86s/it, loss=0.08, v_num=0, reduced_train_loss=0.0315, global_step=296.0, val_loss=0.0652] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 33:   8%|▊         | 1/13 [00:01<00:22,  1.91s/it, loss=0.0724, v_num=0, reduced_train_loss=0.0399, global_step=297.0, val_loss=0.040]\n",
      "Epoch 32:  77%|███████▋  | 10/13 [00:17<00:05,  1.78s/it, loss=0.08, v_num=0, reduced_train_loss=0.0315, global_step=296.0, val_loss=0.0652]\n",
      "Epoch 33:  15%|█▌        | 2/13 [00:03<00:20,  1.86s/it, loss=0.0678, v_num=0, reduced_train_loss=0.0214, global_step=298.0, val_loss=0.040]\n",
      "Epoch 32:  92%|█████████▏| 12/13 [00:19<00:01,  1.66s/it, loss=0.08, v_num=0, reduced_train_loss=0.0315, global_step=296.0, val_loss=0.0652]\n",
      "Epoch 32: 100%|██████████| 13/13 [00:19<00:00,  1.53s/it, loss=0.08, v_num=0, reduced_train_loss=0.0315, global_step=296.0, val_loss=0.0652]2023-06-01 18:12:21,023 - root - INFO - val_loss: 0.07516853511333466\n",
      "Epoch 32: 100%|██████████| 13/13 [00:19<00:00,  1.53s/it, loss=0.08, v_num=0, reduced_train_loss=0.0315, global_step=296.0, val_loss=0.0752]\n",
      "Epoch 33:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.08, v_num=0, reduced_train_loss=0.0315, global_step=296.0, val_loss=0.0752]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:12:21.023462 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.07516853511333466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33:  69%|██████▉   | 9/13 [00:16<00:07,  1.84s/it, loss=0.0737, v_num=0, reduced_train_loss=0.0592, global_step=305.0, val_loss=0.040] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 33:  54%|█████▍    | 7/13 [00:12<00:11,  1.85s/it, loss=0.0819, v_num=0, reduced_train_loss=0.0401, global_step=303.0, val_loss=0.0752]\n",
      "Epoch 33:  77%|███████▋  | 10/13 [00:17<00:05,  1.76s/it, loss=0.0737, v_num=0, reduced_train_loss=0.0592, global_step=305.0, val_loss=0.040]\n",
      "Epoch 33:  62%|██████▏   | 8/13 [00:14<00:09,  1.85s/it, loss=0.0857, v_num=0, reduced_train_loss=0.133, global_step=304.0, val_loss=0.0752] \n",
      "Epoch 33:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.0737, v_num=0, reduced_train_loss=0.0592, global_step=305.0, val_loss=0.040]\n",
      "Epoch 33: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0737, v_num=0, reduced_train_loss=0.0592, global_step=305.0, val_loss=0.040]2023-06-01 18:12:36,355 - root - INFO - val_loss: 0.04380851984024048\n",
      "Epoch 33: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0737, v_num=0, reduced_train_loss=0.0592, global_step=305.0, val_loss=0.0438]\n",
      "Epoch 34:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0737, v_num=0, reduced_train_loss=0.0592, global_step=305.0, val_loss=0.0438]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:12:36.355930 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.04380851984024048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33:  69%|██████▉   | 9/13 [00:16<00:07,  1.85s/it, loss=0.0855, v_num=0, reduced_train_loss=0.122, global_step=305.0, val_loss=0.0752]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 34:   8%|▊         | 1/13 [00:01<00:22,  1.86s/it, loss=0.0732, v_num=0, reduced_train_loss=0.0286, global_step=306.0, val_loss=0.0438]\n",
      "Epoch 33:  77%|███████▋  | 10/13 [00:17<00:05,  1.77s/it, loss=0.0855, v_num=0, reduced_train_loss=0.122, global_step=305.0, val_loss=0.0752]\n",
      "Epoch 34:  15%|█▌        | 2/13 [00:03<00:20,  1.88s/it, loss=0.0739, v_num=0, reduced_train_loss=0.0478, global_step=307.0, val_loss=0.0438]\n",
      "Epoch 33:  92%|█████████▏| 12/13 [00:19<00:01,  1.64s/it, loss=0.0855, v_num=0, reduced_train_loss=0.122, global_step=305.0, val_loss=0.0752]\n",
      "Epoch 33: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.0855, v_num=0, reduced_train_loss=0.122, global_step=305.0, val_loss=0.0752]2023-06-01 18:12:40,794 - root - INFO - val_loss: 0.1067880243062973\n",
      "Epoch 33: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.0855, v_num=0, reduced_train_loss=0.122, global_step=305.0, val_loss=0.107] \n",
      "Epoch 34:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0855, v_num=0, reduced_train_loss=0.122, global_step=305.0, val_loss=0.107]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:12:40.794283 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.1067880243062973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34:  69%|██████▉   | 9/13 [00:16<00:07,  1.87s/it, loss=0.0669, v_num=0, reduced_train_loss=0.0813, global_step=314.0, val_loss=0.0438]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 34:  54%|█████▍    | 7/13 [00:12<00:11,  1.84s/it, loss=0.0818, v_num=0, reduced_train_loss=0.0615, global_step=312.0, val_loss=0.107]\n",
      "Epoch 34:  77%|███████▋  | 10/13 [00:17<00:05,  1.78s/it, loss=0.0669, v_num=0, reduced_train_loss=0.0813, global_step=314.0, val_loss=0.0438]\n",
      "Epoch 34:  62%|██████▏   | 8/13 [00:14<00:09,  1.84s/it, loss=0.0829, v_num=0, reduced_train_loss=0.0735, global_step=313.0, val_loss=0.107]8]\n",
      "Epoch 34:  92%|█████████▏| 12/13 [00:19<00:01,  1.64s/it, loss=0.0669, v_num=0, reduced_train_loss=0.0813, global_step=314.0, val_loss=0.0438]\n",
      "Epoch 34: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.0669, v_num=0, reduced_train_loss=0.0813, global_step=314.0, val_loss=0.0438]2023-06-01 18:12:56,089 - root - INFO - val_loss: 0.030008822679519653\n",
      "Epoch 34: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.0669, v_num=0, reduced_train_loss=0.0813, global_step=314.0, val_loss=0.030] \n",
      "Epoch 35:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0669, v_num=0, reduced_train_loss=0.0813, global_step=314.0, val_loss=0.030]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:12:56.089313 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.030008822679519653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34:  69%|██████▉   | 9/13 [00:16<00:07,  1.83s/it, loss=0.0799, v_num=0, reduced_train_loss=0.0589, global_step=314.0, val_loss=0.107]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 35:   8%|▊         | 1/13 [00:01<00:22,  1.89s/it, loss=0.0659, v_num=0, reduced_train_loss=0.0332, global_step=315.0, val_loss=0.030]\n",
      "Epoch 34:  77%|███████▋  | 10/13 [00:17<00:05,  1.75s/it, loss=0.0799, v_num=0, reduced_train_loss=0.0589, global_step=314.0, val_loss=0.107]\n",
      "Epoch 35:  15%|█▌        | 2/13 [00:03<00:20,  1.85s/it, loss=0.0681, v_num=0, reduced_train_loss=0.081, global_step=316.0, val_loss=0.030] ]\n",
      "Epoch 34:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.0799, v_num=0, reduced_train_loss=0.0589, global_step=314.0, val_loss=0.107]\n",
      "Epoch 34: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0799, v_num=0, reduced_train_loss=0.0589, global_step=314.0, val_loss=0.107]2023-06-01 18:13:00,390 - root - INFO - val_loss: 0.07581052929162979\n",
      "Epoch 34: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0799, v_num=0, reduced_train_loss=0.0589, global_step=314.0, val_loss=0.0758]\n",
      "Epoch 35:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0799, v_num=0, reduced_train_loss=0.0589, global_step=314.0, val_loss=0.0758]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:13:00.390986 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.07581052929162979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35:  69%|██████▉   | 9/13 [00:16<00:07,  1.88s/it, loss=0.0715, v_num=0, reduced_train_loss=0.0472, global_step=323.0, val_loss=0.030]]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 35:  54%|█████▍    | 7/13 [00:12<00:11,  1.84s/it, loss=0.0796, v_num=0, reduced_train_loss=0.0427, global_step=321.0, val_loss=0.0758]\n",
      "Epoch 35:  77%|███████▋  | 10/13 [00:17<00:05,  1.80s/it, loss=0.0715, v_num=0, reduced_train_loss=0.0472, global_step=323.0, val_loss=0.030]\n",
      "Epoch 35:  62%|██████▏   | 8/13 [00:14<00:09,  1.85s/it, loss=0.0773, v_num=0, reduced_train_loss=0.0727, global_step=322.0, val_loss=0.0758]\n",
      "Epoch 35:  92%|█████████▏| 12/13 [00:19<00:01,  1.65s/it, loss=0.0715, v_num=0, reduced_train_loss=0.0472, global_step=323.0, val_loss=0.030]\n",
      "Epoch 35: 100%|██████████| 13/13 [00:19<00:00,  1.53s/it, loss=0.0715, v_num=0, reduced_train_loss=0.0472, global_step=323.0, val_loss=0.030]2023-06-01 18:13:16,011 - root - INFO - val_loss: 0.040537260472774506\n",
      "Epoch 35: 100%|██████████| 13/13 [00:19<00:00,  1.53s/it, loss=0.0715, v_num=0, reduced_train_loss=0.0472, global_step=323.0, val_loss=0.0405]\n",
      "Epoch 36:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0715, v_num=0, reduced_train_loss=0.0472, global_step=323.0, val_loss=0.0405]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:13:16.011679 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.040537260472774506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35:  69%|██████▉   | 9/13 [00:16<00:07,  1.84s/it, loss=0.0778, v_num=0, reduced_train_loss=0.0502, global_step=323.0, val_loss=0.0758]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 36:   8%|▊         | 1/13 [00:01<00:22,  1.84s/it, loss=0.0654, v_num=0, reduced_train_loss=0.138, global_step=324.0, val_loss=0.0405] \n",
      "Epoch 35:  77%|███████▋  | 10/13 [00:17<00:05,  1.76s/it, loss=0.0778, v_num=0, reduced_train_loss=0.0502, global_step=323.0, val_loss=0.0758]\n",
      "Epoch 36:  15%|█▌        | 2/13 [00:03<00:20,  1.86s/it, loss=0.0691, v_num=0, reduced_train_loss=0.133, global_step=325.0, val_loss=0.0405]8]\n",
      "Epoch 35:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.0778, v_num=0, reduced_train_loss=0.0502, global_step=323.0, val_loss=0.0758]\n",
      "Epoch 35: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0778, v_num=0, reduced_train_loss=0.0502, global_step=323.0, val_loss=0.0758]2023-06-01 18:13:20,019 - root - INFO - val_loss: 0.08194859325885773\n",
      "Epoch 35: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0778, v_num=0, reduced_train_loss=0.0502, global_step=323.0, val_loss=0.0819]\n",
      "Epoch 36:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0778, v_num=0, reduced_train_loss=0.0502, global_step=323.0, val_loss=0.0819]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:13:20.019932 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.08194859325885773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36:  69%|██████▉   | 9/13 [00:16<00:07,  1.84s/it, loss=0.0676, v_num=0, reduced_train_loss=0.0203, global_step=332.0, val_loss=0.0405]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 36:  54%|█████▍    | 7/13 [00:12<00:11,  1.85s/it, loss=0.08, v_num=0, reduced_train_loss=0.0589, global_step=330.0, val_loss=0.0819] \n",
      "Epoch 36:  77%|███████▋  | 10/13 [00:17<00:05,  1.76s/it, loss=0.0676, v_num=0, reduced_train_loss=0.0203, global_step=332.0, val_loss=0.0405]\n",
      "Epoch 36:  62%|██████▏   | 8/13 [00:14<00:09,  1.85s/it, loss=0.0785, v_num=0, reduced_train_loss=0.0755, global_step=331.0, val_loss=0.0819]]\n",
      "Epoch 36:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.0676, v_num=0, reduced_train_loss=0.0203, global_step=332.0, val_loss=0.0405]\n",
      "Epoch 36: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0676, v_num=0, reduced_train_loss=0.0203, global_step=332.0, val_loss=0.0405]2023-06-01 18:13:35,634 - root - INFO - val_loss: 0.041513603180646896\n",
      "Epoch 36: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0676, v_num=0, reduced_train_loss=0.0203, global_step=332.0, val_loss=0.0415]\n",
      "Epoch 37:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0676, v_num=0, reduced_train_loss=0.0203, global_step=332.0, val_loss=0.0415]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:13:35.634619 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.041513603180646896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36:  69%|██████▉   | 9/13 [00:16<00:07,  1.85s/it, loss=0.0773, v_num=0, reduced_train_loss=0.038, global_step=332.0, val_loss=0.0819] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 37:   8%|▊         | 1/13 [00:01<00:22,  1.88s/it, loss=0.0699, v_num=0, reduced_train_loss=0.0638, global_step=333.0, val_loss=0.0415]\n",
      "Epoch 36:  77%|███████▋  | 10/13 [00:17<00:05,  1.77s/it, loss=0.0773, v_num=0, reduced_train_loss=0.038, global_step=332.0, val_loss=0.0819]\n",
      "Epoch 37:  15%|█▌        | 2/13 [00:03<00:20,  1.84s/it, loss=0.0711, v_num=0, reduced_train_loss=0.105, global_step=334.0, val_loss=0.0415] \n",
      "Epoch 36:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.0773, v_num=0, reduced_train_loss=0.038, global_step=332.0, val_loss=0.0819]\n",
      "Epoch 36: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0773, v_num=0, reduced_train_loss=0.038, global_step=332.0, val_loss=0.0819]2023-06-01 18:13:39,710 - root - INFO - val_loss: 0.06095682084560394\n",
      "Epoch 36: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0773, v_num=0, reduced_train_loss=0.038, global_step=332.0, val_loss=0.061] \n",
      "Epoch 37:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0773, v_num=0, reduced_train_loss=0.038, global_step=332.0, val_loss=0.061]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:13:39.710510 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.06095682084560394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37:  69%|██████▉   | 9/13 [00:16<00:07,  1.86s/it, loss=0.0694, v_num=0, reduced_train_loss=0.0426, global_step=341.0, val_loss=0.0415]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 37:  54%|█████▍    | 7/13 [00:12<00:10,  1.82s/it, loss=0.0741, v_num=0, reduced_train_loss=0.0579, global_step=339.0, val_loss=0.061]\n",
      "Epoch 37:  62%|██████▏   | 8/13 [00:14<00:09,  1.82s/it, loss=0.0746, v_num=0, reduced_train_loss=0.107, global_step=340.0, val_loss=0.061] 5]\n",
      "Epoch 37:  85%|████████▍ | 11/13 [00:18<00:03,  1.70s/it, loss=0.0694, v_num=0, reduced_train_loss=0.0426, global_step=341.0, val_loss=0.0415]\n",
      "Epoch 37:  92%|█████████▏| 12/13 [00:19<00:01,  1.64s/it, loss=0.0694, v_num=0, reduced_train_loss=0.0426, global_step=341.0, val_loss=0.0415]\n",
      "Epoch 37: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.0694, v_num=0, reduced_train_loss=0.0426, global_step=341.0, val_loss=0.0415]2023-06-01 18:13:55,351 - root - INFO - val_loss: 0.034684065729379654\n",
      "Epoch 37: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.0694, v_num=0, reduced_train_loss=0.0426, global_step=341.0, val_loss=0.0347]\n",
      "Epoch 38:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0694, v_num=0, reduced_train_loss=0.0426, global_step=341.0, val_loss=0.0347]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:13:55.351548 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.034684065729379654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37:  69%|██████▉   | 9/13 [00:16<00:07,  1.83s/it, loss=0.0762, v_num=0, reduced_train_loss=0.0755, global_step=341.0, val_loss=0.061]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 38:   8%|▊         | 1/13 [00:01<00:22,  1.87s/it, loss=0.0665, v_num=0, reduced_train_loss=0.0531, global_step=342.0, val_loss=0.0347]\n",
      "Epoch 37:  77%|███████▋  | 10/13 [00:17<00:05,  1.75s/it, loss=0.0762, v_num=0, reduced_train_loss=0.0755, global_step=341.0, val_loss=0.061]\n",
      "Epoch 38:  15%|█▌        | 2/13 [00:03<00:20,  1.83s/it, loss=0.0666, v_num=0, reduced_train_loss=0.0488, global_step=343.0, val_loss=0.0347]\n",
      "Epoch 37:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.0762, v_num=0, reduced_train_loss=0.0755, global_step=341.0, val_loss=0.061]\n",
      "Epoch 37: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0762, v_num=0, reduced_train_loss=0.0755, global_step=341.0, val_loss=0.061]2023-06-01 18:13:59,321 - root - INFO - val_loss: 0.06927379220724106\n",
      "Epoch 37: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0762, v_num=0, reduced_train_loss=0.0755, global_step=341.0, val_loss=0.0693]\n",
      "Epoch 38:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0762, v_num=0, reduced_train_loss=0.0755, global_step=341.0, val_loss=0.0693]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:13:59.321932 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.06927379220724106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38:  69%|██████▉   | 9/13 [00:16<00:07,  1.82s/it, loss=0.0529, v_num=0, reduced_train_loss=0.0907, global_step=350.0, val_loss=0.0347]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 38:  54%|█████▍    | 7/13 [00:13<00:11,  1.91s/it, loss=0.0727, v_num=0, reduced_train_loss=0.129, global_step=348.0, val_loss=0.0693] \n",
      "Epoch 38:  77%|███████▋  | 10/13 [00:17<00:05,  1.74s/it, loss=0.0529, v_num=0, reduced_train_loss=0.0907, global_step=350.0, val_loss=0.0347]\n",
      "Epoch 38:  62%|██████▏   | 8/13 [00:15<00:09,  1.90s/it, loss=0.0706, v_num=0, reduced_train_loss=0.0833, global_step=349.0, val_loss=0.0693]]\n",
      "Epoch 38:  92%|█████████▏| 12/13 [00:19<00:01,  1.62s/it, loss=0.0529, v_num=0, reduced_train_loss=0.0907, global_step=350.0, val_loss=0.0347]\n",
      "Epoch 38: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.0529, v_num=0, reduced_train_loss=0.0907, global_step=350.0, val_loss=0.0347]2023-06-01 18:14:14,897 - root - INFO - val_loss: 0.03936554864048958\n",
      "Epoch 38: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.0529, v_num=0, reduced_train_loss=0.0907, global_step=350.0, val_loss=0.0394]\n",
      "Epoch 39:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0529, v_num=0, reduced_train_loss=0.0907, global_step=350.0, val_loss=0.0394]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:14:14.897034 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.03936554864048958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38:  69%|██████▉   | 9/13 [00:17<00:07,  1.89s/it, loss=0.073, v_num=0, reduced_train_loss=0.109, global_step=350.0, val_loss=0.0693]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 39:   8%|▊         | 1/13 [00:01<00:23,  1.94s/it, loss=0.052, v_num=0, reduced_train_loss=0.0136, global_step=351.0, val_loss=0.0394] \n",
      "Epoch 38:  77%|███████▋  | 10/13 [00:18<00:05,  1.80s/it, loss=0.073, v_num=0, reduced_train_loss=0.109, global_step=350.0, val_loss=0.0693]\n",
      "Epoch 39:  15%|█▌        | 2/13 [00:03<00:21,  1.91s/it, loss=0.0547, v_num=0, reduced_train_loss=0.0746, global_step=352.0, val_loss=0.0394]\n",
      "Epoch 38:  92%|█████████▏| 12/13 [00:19<00:01,  1.67s/it, loss=0.073, v_num=0, reduced_train_loss=0.109, global_step=350.0, val_loss=0.0693]\n",
      "Epoch 38: 100%|██████████| 13/13 [00:20<00:00,  1.54s/it, loss=0.073, v_num=0, reduced_train_loss=0.109, global_step=350.0, val_loss=0.0693]2023-06-01 18:14:19,396 - root - INFO - val_loss: 0.09369369596242905\n",
      "Epoch 38: 100%|██████████| 13/13 [00:20<00:00,  1.54s/it, loss=0.073, v_num=0, reduced_train_loss=0.109, global_step=350.0, val_loss=0.0937]\n",
      "Epoch 39:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.073, v_num=0, reduced_train_loss=0.109, global_step=350.0, val_loss=0.0937]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:14:19.396110 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.09369369596242905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39:  69%|██████▉   | 9/13 [00:16<00:07,  1.85s/it, loss=0.0535, v_num=0, reduced_train_loss=0.0834, global_step=359.0, val_loss=0.0394]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 39:  54%|█████▍    | 7/13 [00:12<00:11,  1.84s/it, loss=0.0748, v_num=0, reduced_train_loss=0.0682, global_step=357.0, val_loss=0.0937]\n",
      "Epoch 39:  77%|███████▋  | 10/13 [00:17<00:05,  1.76s/it, loss=0.0535, v_num=0, reduced_train_loss=0.0834, global_step=359.0, val_loss=0.0394]\n",
      "Epoch 39:  62%|██████▏   | 8/13 [00:14<00:09,  1.84s/it, loss=0.0715, v_num=0, reduced_train_loss=0.0745, global_step=358.0, val_loss=0.0937]]\n",
      "Epoch 39:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.0535, v_num=0, reduced_train_loss=0.0834, global_step=359.0, val_loss=0.0394]\n",
      "Epoch 39: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0535, v_num=0, reduced_train_loss=0.0834, global_step=359.0, val_loss=0.0394]2023-06-01 18:14:34,532 - root - INFO - val_loss: 0.047257740050554276\n",
      "Epoch 39: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0535, v_num=0, reduced_train_loss=0.0834, global_step=359.0, val_loss=0.0473]\n",
      "Epoch 40:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0535, v_num=0, reduced_train_loss=0.0834, global_step=359.0, val_loss=0.0473]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:14:34.532256 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.047257740050554276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39:  69%|██████▉   | 9/13 [00:16<00:07,  1.84s/it, loss=0.0714, v_num=0, reduced_train_loss=0.0559, global_step=359.0, val_loss=0.0937]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 40:   8%|▊         | 1/13 [00:01<00:22,  1.86s/it, loss=0.054, v_num=0, reduced_train_loss=0.0527, global_step=360.0, val_loss=0.0473] \n",
      "Epoch 39:  77%|███████▋  | 10/13 [00:17<00:05,  1.76s/it, loss=0.0714, v_num=0, reduced_train_loss=0.0559, global_step=359.0, val_loss=0.0937]\n",
      "Epoch 40:  15%|█▌        | 2/13 [00:03<00:20,  1.86s/it, loss=0.0533, v_num=0, reduced_train_loss=0.0273, global_step=361.0, val_loss=0.0473]]\n",
      "Epoch 39:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.0714, v_num=0, reduced_train_loss=0.0559, global_step=359.0, val_loss=0.0937]\n",
      "Epoch 39: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0714, v_num=0, reduced_train_loss=0.0559, global_step=359.0, val_loss=0.0937]2023-06-01 18:14:39,029 - root - INFO - val_loss: 0.08408527076244354\n",
      "Epoch 39: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0714, v_num=0, reduced_train_loss=0.0559, global_step=359.0, val_loss=0.0841]\n",
      "Epoch 40:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0714, v_num=0, reduced_train_loss=0.0559, global_step=359.0, val_loss=0.0841]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:14:39.029793 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.08408527076244354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40:  69%|██████▉   | 9/13 [00:16<00:07,  1.85s/it, loss=0.056, v_num=0, reduced_train_loss=0.0815, global_step=368.0, val_loss=0.0473] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 40:  54%|█████▍    | 7/13 [00:12<00:11,  1.85s/it, loss=0.064, v_num=0, reduced_train_loss=0.0315, global_step=366.0, val_loss=0.0841] \n",
      "Epoch 40:  77%|███████▋  | 10/13 [00:17<00:05,  1.77s/it, loss=0.056, v_num=0, reduced_train_loss=0.0815, global_step=368.0, val_loss=0.0473]\n",
      "Epoch 40:  62%|██████▏   | 8/13 [00:14<00:09,  1.85s/it, loss=0.0642, v_num=0, reduced_train_loss=0.038, global_step=367.0, val_loss=0.0841]]\n",
      "Epoch 40:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.056, v_num=0, reduced_train_loss=0.0815, global_step=368.0, val_loss=0.0473]\n",
      "Epoch 40: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.056, v_num=0, reduced_train_loss=0.0815, global_step=368.0, val_loss=0.0473]2023-06-01 18:14:54,233 - root - INFO - val_loss: 0.04332488775253296\n",
      "Epoch 40: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.056, v_num=0, reduced_train_loss=0.0815, global_step=368.0, val_loss=0.0433]\n",
      "Epoch 41:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.056, v_num=0, reduced_train_loss=0.0815, global_step=368.0, val_loss=0.0433]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:14:54.233572 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.04332488775253296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40:  69%|██████▉   | 9/13 [00:16<00:07,  1.85s/it, loss=0.0632, v_num=0, reduced_train_loss=0.109, global_step=368.0, val_loss=0.0841]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 41:   8%|▊         | 1/13 [00:01<00:22,  1.86s/it, loss=0.0557, v_num=0, reduced_train_loss=0.0275, global_step=369.0, val_loss=0.0433]\n",
      "Epoch 40:  77%|███████▋  | 10/13 [00:17<00:05,  1.77s/it, loss=0.0632, v_num=0, reduced_train_loss=0.109, global_step=368.0, val_loss=0.0841]\n",
      "Epoch 41:  15%|█▌        | 2/13 [00:03<00:20,  1.84s/it, loss=0.0545, v_num=0, reduced_train_loss=0.0661, global_step=370.0, val_loss=0.0433]\n",
      "Epoch 40:  92%|█████████▏| 12/13 [00:19<00:01,  1.64s/it, loss=0.0632, v_num=0, reduced_train_loss=0.109, global_step=368.0, val_loss=0.0841]\n",
      "Epoch 40: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.0632, v_num=0, reduced_train_loss=0.109, global_step=368.0, val_loss=0.0841]2023-06-01 18:14:58,833 - root - INFO - val_loss: 0.06607980281114578\n",
      "Epoch 40: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.0632, v_num=0, reduced_train_loss=0.109, global_step=368.0, val_loss=0.0661]\n",
      "Epoch 41:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0632, v_num=0, reduced_train_loss=0.109, global_step=368.0, val_loss=0.0661]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:14:58.833198 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.06607980281114578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41:  69%|██████▉   | 9/13 [00:16<00:07,  1.82s/it, loss=0.0544, v_num=0, reduced_train_loss=0.0153, global_step=377.0, val_loss=0.0433] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 41:  54%|█████▍    | 7/13 [00:12<00:11,  1.85s/it, loss=0.0596, v_num=0, reduced_train_loss=0.0207, global_step=375.0, val_loss=0.0661]]\n",
      "Epoch 41:  62%|██████▏   | 8/13 [00:14<00:09,  1.85s/it, loss=0.0627, v_num=0, reduced_train_loss=0.110, global_step=376.0, val_loss=0.0661] ]\n",
      "Epoch 41:  92%|█████████▏| 12/13 [00:19<00:01,  1.62s/it, loss=0.0544, v_num=0, reduced_train_loss=0.0153, global_step=377.0, val_loss=0.0433]\n",
      "Epoch 41: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.0544, v_num=0, reduced_train_loss=0.0153, global_step=377.0, val_loss=0.0433]2023-06-01 18:15:13,729 - root - INFO - val_loss: 0.04410412162542343\n",
      "Epoch 41: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.0544, v_num=0, reduced_train_loss=0.0153, global_step=377.0, val_loss=0.0441]\n",
      "Epoch 42:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0544, v_num=0, reduced_train_loss=0.0153, global_step=377.0, val_loss=0.0441]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:15:13.729714 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.04410412162542343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41:  69%|██████▉   | 9/13 [00:16<00:07,  1.85s/it, loss=0.061, v_num=0, reduced_train_loss=0.0339, global_step=377.0, val_loss=0.0661]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 42:   8%|▊         | 1/13 [00:01<00:22,  1.87s/it, loss=0.0509, v_num=0, reduced_train_loss=0.0284, global_step=378.0, val_loss=0.0441]\n",
      "Epoch 42:  15%|█▌        | 2/13 [00:03<00:20,  1.85s/it, loss=0.0478, v_num=0, reduced_train_loss=0.0225, global_step=379.0, val_loss=0.0441]\n",
      "Epoch 41:  85%|████████▍ | 11/13 [00:18<00:03,  1.70s/it, loss=0.061, v_num=0, reduced_train_loss=0.0339, global_step=377.0, val_loss=0.0661]\n",
      "Epoch 41:  92%|█████████▏| 12/13 [00:19<00:01,  1.64s/it, loss=0.061, v_num=0, reduced_train_loss=0.0339, global_step=377.0, val_loss=0.0661]\n",
      "Epoch 41: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.061, v_num=0, reduced_train_loss=0.0339, global_step=377.0, val_loss=0.0661]2023-06-01 18:15:18,561 - root - INFO - val_loss: 0.06102567911148071\n",
      "Epoch 41: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.061, v_num=0, reduced_train_loss=0.0339, global_step=377.0, val_loss=0.061] \n",
      "Epoch 42:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.061, v_num=0, reduced_train_loss=0.0339, global_step=377.0, val_loss=0.061]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:15:18.561875 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.06102567911148071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42:  69%|██████▉   | 9/13 [00:16<00:07,  1.81s/it, loss=0.0494, v_num=0, reduced_train_loss=0.0509, global_step=386.0, val_loss=0.0441]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 42:  54%|█████▍    | 7/13 [00:12<00:11,  1.84s/it, loss=0.0593, v_num=0, reduced_train_loss=0.0613, global_step=384.0, val_loss=0.061]1]\n",
      "Epoch 42:  85%|████████▍ | 11/13 [00:18<00:03,  1.66s/it, loss=0.0494, v_num=0, reduced_train_loss=0.0509, global_step=386.0, val_loss=0.0441]\n",
      "Epoch 42:  92%|█████████▏| 12/13 [00:19<00:01,  1.60s/it, loss=0.0494, v_num=0, reduced_train_loss=0.0509, global_step=386.0, val_loss=0.0441]\n",
      "Epoch 42: 100%|██████████| 13/13 [00:19<00:00,  1.48s/it, loss=0.0494, v_num=0, reduced_train_loss=0.0509, global_step=386.0, val_loss=0.0441]2023-06-01 18:15:33,033 - root - INFO - val_loss: 0.04054192453622818\n",
      "Epoch 42: 100%|██████████| 13/13 [00:19<00:00,  1.48s/it, loss=0.0494, v_num=0, reduced_train_loss=0.0509, global_step=386.0, val_loss=0.0405]\n",
      "Epoch 43:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0494, v_num=0, reduced_train_loss=0.0509, global_step=386.0, val_loss=0.0405]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:15:33.033331 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.04054192453622818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42:  69%|██████▉   | 9/13 [00:16<00:07,  1.84s/it, loss=0.0583, v_num=0, reduced_train_loss=0.0547, global_step=386.0, val_loss=0.061]]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 43:  15%|█▌        | 2/13 [00:03<00:20,  1.83s/it, loss=0.0497, v_num=0, reduced_train_loss=0.0811, global_step=388.0, val_loss=0.0405]\n",
      "Epoch 42:  85%|████████▍ | 11/13 [00:18<00:03,  1.69s/it, loss=0.0583, v_num=0, reduced_train_loss=0.0547, global_step=386.0, val_loss=0.061]\n",
      "Epoch 42:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.0583, v_num=0, reduced_train_loss=0.0547, global_step=386.0, val_loss=0.061]\n",
      "Epoch 42: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0583, v_num=0, reduced_train_loss=0.0547, global_step=386.0, val_loss=0.061]2023-06-01 18:15:38,232 - root - INFO - val_loss: 0.08367002010345459\n",
      "Epoch 42: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0583, v_num=0, reduced_train_loss=0.0547, global_step=386.0, val_loss=0.0837]\n",
      "Epoch 43:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0583, v_num=0, reduced_train_loss=0.0547, global_step=386.0, val_loss=0.0837]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:15:38.232507 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.08367002010345459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43:  69%|██████▉   | 9/13 [00:16<00:07,  1.84s/it, loss=0.0437, v_num=0, reduced_train_loss=0.0472, global_step=395.0, val_loss=0.0405] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 43:  54%|█████▍    | 7/13 [00:12<00:11,  1.84s/it, loss=0.0515, v_num=0, reduced_train_loss=0.011, global_step=393.0, val_loss=0.0837] ]\n",
      "Epoch 43:  85%|████████▍ | 11/13 [00:18<00:03,  1.68s/it, loss=0.0437, v_num=0, reduced_train_loss=0.0472, global_step=395.0, val_loss=0.0405]\n",
      "Epoch 43:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.0437, v_num=0, reduced_train_loss=0.0472, global_step=395.0, val_loss=0.0405]\n",
      "Epoch 43: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0437, v_num=0, reduced_train_loss=0.0472, global_step=395.0, val_loss=0.0405]2023-06-01 18:15:52,651 - root - INFO - val_loss: 0.04500887542963028\n",
      "Epoch 43: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0437, v_num=0, reduced_train_loss=0.0472, global_step=395.0, val_loss=0.045] \n",
      "Epoch 44:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0437, v_num=0, reduced_train_loss=0.0472, global_step=395.0, val_loss=0.045]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:15:52.651866 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.04500887542963028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43:  69%|██████▉   | 9/13 [00:16<00:07,  1.84s/it, loss=0.05, v_num=0, reduced_train_loss=0.0398, global_step=395.0, val_loss=0.0837] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 44:  15%|█▌        | 2/13 [00:03<00:19,  1.79s/it, loss=0.0462, v_num=0, reduced_train_loss=0.0555, global_step=397.0, val_loss=0.045]\n",
      "Epoch 43:  85%|████████▍ | 11/13 [00:18<00:03,  1.68s/it, loss=0.05, v_num=0, reduced_train_loss=0.0398, global_step=395.0, val_loss=0.0837]\n",
      "Epoch 43:  92%|█████████▏| 12/13 [00:19<00:01,  1.62s/it, loss=0.05, v_num=0, reduced_train_loss=0.0398, global_step=395.0, val_loss=0.0837]\n",
      "Epoch 43: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.05, v_num=0, reduced_train_loss=0.0398, global_step=395.0, val_loss=0.0837]2023-06-01 18:15:57,804 - root - INFO - val_loss: 0.08908981084823608\n",
      "Epoch 43: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.05, v_num=0, reduced_train_loss=0.0398, global_step=395.0, val_loss=0.0891]\n",
      "Epoch 44:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.05, v_num=0, reduced_train_loss=0.0398, global_step=395.0, val_loss=0.0891]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:15:57.804195 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.08908981084823608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44:  69%|██████▉   | 9/13 [00:16<00:07,  1.82s/it, loss=0.0469, v_num=0, reduced_train_loss=0.0408, global_step=404.0, val_loss=0.045]]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 44:  54%|█████▍    | 7/13 [00:12<00:11,  1.85s/it, loss=0.0491, v_num=0, reduced_train_loss=0.0444, global_step=402.0, val_loss=0.0891]\n",
      "Epoch 44:  85%|████████▍ | 11/13 [00:18<00:03,  1.67s/it, loss=0.0469, v_num=0, reduced_train_loss=0.0408, global_step=404.0, val_loss=0.045]\n",
      "Epoch 44:  92%|█████████▏| 12/13 [00:19<00:01,  1.61s/it, loss=0.0469, v_num=0, reduced_train_loss=0.0408, global_step=404.0, val_loss=0.045]\n",
      "Epoch 44: 100%|██████████| 13/13 [00:19<00:00,  1.49s/it, loss=0.0469, v_num=0, reduced_train_loss=0.0408, global_step=404.0, val_loss=0.045]2023-06-01 18:16:12,005 - root - INFO - val_loss: 0.04859080910682678\n",
      "Epoch 44: 100%|██████████| 13/13 [00:19<00:00,  1.49s/it, loss=0.0469, v_num=0, reduced_train_loss=0.0408, global_step=404.0, val_loss=0.0486]\n",
      "Epoch 45:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0469, v_num=0, reduced_train_loss=0.0408, global_step=404.0, val_loss=0.0486]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:16:12.005881 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.04859080910682678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44:  69%|██████▉   | 9/13 [00:16<00:07,  1.84s/it, loss=0.0494, v_num=0, reduced_train_loss=0.0134, global_step=404.0, val_loss=0.0891]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 45:  15%|█▌        | 2/13 [00:03<00:20,  1.85s/it, loss=0.0459, v_num=0, reduced_train_loss=0.0184, global_step=406.0, val_loss=0.0486]]\n",
      "Epoch 44:  85%|████████▍ | 11/13 [00:18<00:03,  1.69s/it, loss=0.0494, v_num=0, reduced_train_loss=0.0134, global_step=404.0, val_loss=0.0891]\n",
      "Epoch 44:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.0494, v_num=0, reduced_train_loss=0.0134, global_step=404.0, val_loss=0.0891]\n",
      "Epoch 44: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0494, v_num=0, reduced_train_loss=0.0134, global_step=404.0, val_loss=0.0891]2023-06-01 18:16:17,503 - root - INFO - val_loss: 0.08786755800247192\n",
      "Epoch 44: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.0494, v_num=0, reduced_train_loss=0.0134, global_step=404.0, val_loss=0.0879]\n",
      "Epoch 45:  23%|██▎       | 3/13 [00:05<00:18,  1.86s/it, loss=0.0451, v_num=0, reduced_train_loss=0.0324, global_step=407.0, val_loss=0.0486] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:16:17.503418 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.08786755800247192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45:  69%|██████▉   | 9/13 [00:16<00:07,  1.85s/it, loss=0.0513, v_num=0, reduced_train_loss=0.0511, global_step=413.0, val_loss=0.0486]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 45:  54%|█████▍    | 7/13 [00:12<00:11,  1.83s/it, loss=0.0493, v_num=0, reduced_train_loss=0.0886, global_step=411.0, val_loss=0.0879]]\n",
      "Epoch 45:  85%|████████▍ | 11/13 [00:18<00:03,  1.69s/it, loss=0.0513, v_num=0, reduced_train_loss=0.0511, global_step=413.0, val_loss=0.0486]\n",
      "Epoch 45:  92%|█████████▏| 12/13 [00:19<00:01,  1.64s/it, loss=0.0513, v_num=0, reduced_train_loss=0.0511, global_step=413.0, val_loss=0.0486]\n",
      "Epoch 45: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.0513, v_num=0, reduced_train_loss=0.0511, global_step=413.0, val_loss=0.0486]2023-06-01 18:16:31,734 - root - INFO - val_loss: 0.03960010036826134\n",
      "Epoch 45: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.0513, v_num=0, reduced_train_loss=0.0511, global_step=413.0, val_loss=0.0396]\n",
      "Epoch 46:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0513, v_num=0, reduced_train_loss=0.0511, global_step=413.0, val_loss=0.0396]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:16:31.734048 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.03960010036826134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45:  69%|██████▉   | 9/13 [00:16<00:07,  1.84s/it, loss=0.0486, v_num=0, reduced_train_loss=0.0344, global_step=413.0, val_loss=0.0879]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 46:  15%|█▌        | 2/13 [00:03<00:20,  1.86s/it, loss=0.0494, v_num=0, reduced_train_loss=0.0452, global_step=415.0, val_loss=0.0396]]\n",
      "Epoch 45:  85%|████████▍ | 11/13 [00:18<00:03,  1.69s/it, loss=0.0486, v_num=0, reduced_train_loss=0.0344, global_step=413.0, val_loss=0.0879]\n",
      "Epoch 45:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.0486, v_num=0, reduced_train_loss=0.0344, global_step=413.0, val_loss=0.0879]\n",
      "Epoch 45: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0486, v_num=0, reduced_train_loss=0.0344, global_step=413.0, val_loss=0.0879]2023-06-01 18:16:37,168 - root - INFO - val_loss: 0.06906101107597351\n",
      "Epoch 45: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0486, v_num=0, reduced_train_loss=0.0344, global_step=413.0, val_loss=0.0691]\n",
      "Epoch 46:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0486, v_num=0, reduced_train_loss=0.0344, global_step=413.0, val_loss=0.0691]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:16:37.168536 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.06906101107597351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46:  69%|██████▉   | 9/13 [00:16<00:07,  1.86s/it, loss=0.0601, v_num=0, reduced_train_loss=0.130, global_step=422.0, val_loss=0.0396]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 46:  54%|█████▍    | 7/13 [00:12<00:11,  1.84s/it, loss=0.0473, v_num=0, reduced_train_loss=0.0119, global_step=420.0, val_loss=0.0691]\n",
      "Epoch 46:  85%|████████▍ | 11/13 [00:18<00:03,  1.71s/it, loss=0.0601, v_num=0, reduced_train_loss=0.130, global_step=422.0, val_loss=0.0396]\n",
      "Epoch 46:  92%|█████████▏| 12/13 [00:19<00:01,  1.64s/it, loss=0.0601, v_num=0, reduced_train_loss=0.130, global_step=422.0, val_loss=0.0396]\n",
      "Epoch 46: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.0601, v_num=0, reduced_train_loss=0.130, global_step=422.0, val_loss=0.0396]2023-06-01 18:16:51,538 - root - INFO - val_loss: 0.04582426697015762\n",
      "Epoch 46: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it, loss=0.0601, v_num=0, reduced_train_loss=0.130, global_step=422.0, val_loss=0.0458]\n",
      "Epoch 47:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0601, v_num=0, reduced_train_loss=0.130, global_step=422.0, val_loss=0.0458]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:16:51.538048 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.04582426697015762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46:  69%|██████▉   | 9/13 [00:16<00:07,  1.84s/it, loss=0.0467, v_num=0, reduced_train_loss=0.0376, global_step=422.0, val_loss=0.0691]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 47:  15%|█▌        | 2/13 [00:03<00:20,  1.85s/it, loss=0.0581, v_num=0, reduced_train_loss=0.0464, global_step=424.0, val_loss=0.0458]]\n",
      "Epoch 46:  85%|████████▍ | 11/13 [00:18<00:03,  1.68s/it, loss=0.0467, v_num=0, reduced_train_loss=0.0376, global_step=422.0, val_loss=0.0691]\n",
      "Epoch 46:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.0467, v_num=0, reduced_train_loss=0.0376, global_step=422.0, val_loss=0.0691]\n",
      "Epoch 46: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0467, v_num=0, reduced_train_loss=0.0376, global_step=422.0, val_loss=0.0691]2023-06-01 18:16:56,762 - root - INFO - val_loss: 0.07064922153949738\n",
      "Epoch 46: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0467, v_num=0, reduced_train_loss=0.0376, global_step=422.0, val_loss=0.0706]\n",
      "Epoch 47:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0467, v_num=0, reduced_train_loss=0.0376, global_step=422.0, val_loss=0.0706]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:16:56.762210 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.07064922153949738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47:  69%|██████▉   | 9/13 [00:16<00:07,  1.83s/it, loss=0.057, v_num=0, reduced_train_loss=0.0961, global_step=431.0, val_loss=0.0458] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 47:  54%|█████▍    | 7/13 [00:12<00:11,  1.84s/it, loss=0.0442, v_num=0, reduced_train_loss=0.0344, global_step=429.0, val_loss=0.0706]\n",
      "Epoch 47:  85%|████████▍ | 11/13 [00:18<00:03,  1.68s/it, loss=0.057, v_num=0, reduced_train_loss=0.0961, global_step=431.0, val_loss=0.0458]\n",
      "Epoch 47:  92%|█████████▏| 12/13 [00:19<00:01,  1.62s/it, loss=0.057, v_num=0, reduced_train_loss=0.0961, global_step=431.0, val_loss=0.0458]\n",
      "Epoch 47: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.057, v_num=0, reduced_train_loss=0.0961, global_step=431.0, val_loss=0.0458]2023-06-01 18:17:11,023 - root - INFO - val_loss: 0.03067917563021183\n",
      "Epoch 47: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.057, v_num=0, reduced_train_loss=0.0961, global_step=431.0, val_loss=0.0307]\n",
      "Epoch 48:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.057, v_num=0, reduced_train_loss=0.0961, global_step=431.0, val_loss=0.0307]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:17:11.023819 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.03067917563021183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47:  69%|██████▉   | 9/13 [00:16<00:07,  1.84s/it, loss=0.0437, v_num=0, reduced_train_loss=0.0459, global_step=431.0, val_loss=0.0706]]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 48:  15%|█▌        | 2/13 [00:03<00:20,  1.85s/it, loss=0.0538, v_num=0, reduced_train_loss=0.0301, global_step=433.0, val_loss=0.0307] \n",
      "Epoch 47:  85%|████████▍ | 11/13 [00:18<00:03,  1.68s/it, loss=0.0437, v_num=0, reduced_train_loss=0.0459, global_step=431.0, val_loss=0.0706]\n",
      "Epoch 47:  92%|█████████▏| 12/13 [00:19<00:01,  1.62s/it, loss=0.0437, v_num=0, reduced_train_loss=0.0459, global_step=431.0, val_loss=0.0706]\n",
      "Epoch 47: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.0437, v_num=0, reduced_train_loss=0.0459, global_step=431.0, val_loss=0.0706]2023-06-01 18:17:16,277 - root - INFO - val_loss: 0.09230723232030869\n",
      "Epoch 47: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it, loss=0.0437, v_num=0, reduced_train_loss=0.0459, global_step=431.0, val_loss=0.0923]\n",
      "Epoch 48:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0437, v_num=0, reduced_train_loss=0.0459, global_step=431.0, val_loss=0.0923]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:17:16.277606 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.09230723232030869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48:  69%|██████▉   | 9/13 [00:16<00:07,  1.84s/it, loss=0.0516, v_num=0, reduced_train_loss=0.0407, global_step=440.0, val_loss=0.0307]]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 48:  54%|█████▍    | 7/13 [00:12<00:11,  1.85s/it, loss=0.0397, v_num=0, reduced_train_loss=0.0486, global_step=438.0, val_loss=0.0923] \n",
      "Epoch 48:  85%|████████▍ | 11/13 [00:18<00:03,  1.69s/it, loss=0.0516, v_num=0, reduced_train_loss=0.0407, global_step=440.0, val_loss=0.0307]\n",
      "Epoch 48:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.0516, v_num=0, reduced_train_loss=0.0407, global_step=440.0, val_loss=0.0307]\n",
      "Epoch 48: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0516, v_num=0, reduced_train_loss=0.0407, global_step=440.0, val_loss=0.0307]2023-06-01 18:17:30,628 - root - INFO - val_loss: 0.04659083113074303\n",
      "Epoch 48: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0516, v_num=0, reduced_train_loss=0.0407, global_step=440.0, val_loss=0.0466]\n",
      "Epoch 49:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0516, v_num=0, reduced_train_loss=0.0407, global_step=440.0, val_loss=0.0466]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:17:30.628400 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.04659083113074303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48:  69%|██████▉   | 9/13 [00:16<00:07,  1.84s/it, loss=0.0414, v_num=0, reduced_train_loss=0.0252, global_step=440.0, val_loss=0.0923]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 49:  15%|█▌        | 2/13 [00:03<00:20,  1.88s/it, loss=0.0456, v_num=0, reduced_train_loss=0.0392, global_step=442.0, val_loss=0.0466]]\n",
      "Epoch 48:  85%|████████▍ | 11/13 [00:18<00:03,  1.69s/it, loss=0.0414, v_num=0, reduced_train_loss=0.0252, global_step=440.0, val_loss=0.0923]\n",
      "Epoch 48:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.0414, v_num=0, reduced_train_loss=0.0252, global_step=440.0, val_loss=0.0923]\n",
      "Epoch 48: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0414, v_num=0, reduced_train_loss=0.0252, global_step=440.0, val_loss=0.0923]2023-06-01 18:17:35,933 - root - INFO - val_loss: 0.07195349037647247\n",
      "Epoch 48: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.0414, v_num=0, reduced_train_loss=0.0252, global_step=440.0, val_loss=0.072] \n",
      "Epoch 49:   0%|          | 0/13 [00:00<?, ?it/s, loss=0.0414, v_num=0, reduced_train_loss=0.0252, global_step=440.0, val_loss=0.072]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:17:35.933097 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.07195349037647247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49:  69%|██████▉   | 9/13 [00:17<00:07,  1.91s/it, loss=0.0458, v_num=0, reduced_train_loss=0.0556, global_step=449.0, val_loss=0.0466]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 49:  54%|█████▍    | 7/13 [00:12<00:11,  1.84s/it, loss=0.041, v_num=0, reduced_train_loss=0.049, global_step=447.0, val_loss=0.072]  6]\n",
      "Epoch 49:  85%|████████▍ | 11/13 [00:19<00:03,  1.73s/it, loss=0.0458, v_num=0, reduced_train_loss=0.0556, global_step=449.0, val_loss=0.0466]\n",
      "Epoch 49:  92%|█████████▏| 12/13 [00:20<00:01,  1.67s/it, loss=0.0458, v_num=0, reduced_train_loss=0.0556, global_step=449.0, val_loss=0.0466]\n",
      "Epoch 49: 100%|██████████| 13/13 [00:20<00:00,  1.55s/it, loss=0.0458, v_num=0, reduced_train_loss=0.0556, global_step=449.0, val_loss=0.0466]2023-06-01 18:17:50,733 - root - INFO - val_loss: 0.05934610217809677\n",
      "Epoch 49: 100%|██████████| 13/13 [00:20<00:00,  1.55s/it, loss=0.0458, v_num=0, reduced_train_loss=0.0556, global_step=449.0, val_loss=0.0593]\n",
      "Epoch 49: 100%|██████████| 13/13 [00:20<00:00,  1.55s/it, loss=0.0458, v_num=0, reduced_train_loss=0.0556, global_step=449.0, val_loss=0.0593]2023-06-01 18:17:50,740 - pytorch_lightning.utilities.rank_zero - INFO - `Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Epoch 49:  62%|██████▏   | 8/13 [00:14<00:09,  1.85s/it, loss=0.042, v_num=0, reduced_train_loss=0.0501, global_step=448.0, val_loss=0.072]93]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:17:50.733752 140659256891200 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.05934610217809677\n",
      "I0601 18:17:50.740092 140659256891200 fit_loop.py:175] `Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 18:17:51,743 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-3, peer_run=simulate_job]: got result from client site-3 for task: name=train, id=42980685-a93e-4664-b2e2-9e89ea7f2802\n",
      "2023-06-01 18:17:51,745 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-3, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: ignored result submission since server runner's status is done\n",
      "2023-06-01 18:17:51,747 - SubmitUpdateCommand - INFO - submit_update process. client_name:site-3   task_id:42980685-a93e-4664-b2e2-9e89ea7f2802\n",
      "\n",
      "2023-06-01 18:17:51,627 - PromptLearner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Computed 7 weight differences for global model of length 7\n",
      "2023-06-01 18:17:51,628 - PromptLearner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Local steps per epoch: 9\n",
      "2023-06-01 18:17:51,628 - PromptLearner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Local epochs finished. Returning shareable\n",
      "2023-06-01 18:17:51,629 - ClientRunner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: finished processing task\n",
      "2023-06-01 18:17:51,633 - FederatedClient - INFO - Starting to push execute result.\n",
      "2023-06-01 18:17:51,751 - Communicator - INFO -  SubmitUpdate size: 16873459 Bytes. time: 0.1175844669342041 seconds\n",
      "2023-06-01 18:17:51,753 - ClientRunner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: result sent to server for task: name=train, id=42980685-a93e-4664-b2e2-9e89ea7f2802\n",
      "2023-06-01 18:17:51,754 - ClientTaskWorker - INFO - Finished one task run for client: site-3 interval: 2 task_processed: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:17:51.627754 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Computed 7 weight differences for global model of length 7\n",
      "I0601 18:17:51.628289 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Local steps per epoch: 9\n",
      "I0601 18:17:51.628584 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: Local epochs finished. Returning shareable\n",
      "I0601 18:17:51.629480 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: finished processing task\n",
      "I0601 18:17:51.633421 140656944113408 fed_client_base.py:296] Starting to push execute result.\n",
      "I0601 18:17:51.751286 140656944113408 communicator.py:268]  SubmitUpdate size: 16873459 Bytes. time: 0.1175844669342041 seconds\n",
      "I0601 18:17:51.753593 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=42980685-a93e-4664-b2e2-9e89ea7f2802]: result sent to server for task: name=train, id=42980685-a93e-4664-b2e2-9e89ea7f2802\n",
      "I0601 18:17:51.754020 140659256891200 simulator_worker.py:94] Finished one task run for client: site-3 interval: 2 task_processed: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49:  69%|██████▉   | 9/13 [00:16<00:07,  1.85s/it, loss=0.042, v_num=0, reduced_train_loss=0.033, global_step=449.0, val_loss=0.072] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A2023-06-01 18:17:53,759 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-3, peer_run=simulate_job]: server runner is finalizing - asked client to end the run\n",
      "\n",
      "Epoch 49:  77%|███████▋  | 10/13 [00:17<00:05,  1.76s/it, loss=0.042, v_num=0, reduced_train_loss=0.033, global_step=449.0, val_loss=0.072]2023-06-01 18:17:53,777 - GetTaskCommand - INFO - return task to client.  client_name: site-3  task_name: __end_run__   task_id:   sharable_header_task_id: \n",
      "2023-06-01 18:17:53,782 - FederatedClient - INFO - pull_task completed. Task name:__end_run__ Status:True \n",
      "2023-06-01 18:17:53,782 - ClientRunner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: server asked to end the run\n",
      "2023-06-01 18:17:53,783 - ClientTaskWorker - INFO - End the Simulator run.\n",
      "2023-06-01 18:17:53,783 - ClientTaskWorker - INFO - Clean up ClientRunner for : site-3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:17:53.782506 140659256891200 fed_client.py:91] pull_task completed. Task name:__end_run__ Status:True \n",
      "I0601 18:17:53.782876 140659256891200 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: server asked to end the run\n",
      "I0601 18:17:53.783044 140659256891200 simulator_worker.py:102] End the Simulator run.\n",
      "I0601 18:17:53.783630 140659256891200 simulator_worker.py:125] Clean up ClientRunner for : site-3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 49:  85%|████████▍ | 11/13 [00:18<00:03,  1.69s/it, loss=0.042, v_num=0, reduced_train_loss=0.033, global_step=449.0, val_loss=0.072]\n",
      "Epoch 49:  92%|█████████▏| 12/13 [00:19<00:01,  1.63s/it, loss=0.042, v_num=0, reduced_train_loss=0.033, global_step=449.0, val_loss=0.072]\n",
      "Epoch 49: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.042, v_num=0, reduced_train_loss=0.033, global_step=449.0, val_loss=0.072]2023-06-01 18:17:55,525 - root - INFO - val_loss: 0.08060461282730103\n",
      "Epoch 49: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.042, v_num=0, reduced_train_loss=0.033, global_step=449.0, val_loss=0.0806]\n",
      "Epoch 49: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.042, v_num=0, reduced_train_loss=0.033, global_step=449.0, val_loss=0.0806]2023-06-01 18:17:55,532 - pytorch_lightning.utilities.rank_zero - INFO - `Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Epoch 49: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it, loss=0.042, v_num=0, reduced_train_loss=0.033, global_step=449.0, val_loss=0.0806]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:17:55.525470 140713251325760 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 0.08060461282730103\n",
      "I0601 18:17:55.532335 140713251325760 fit_loop.py:175] `Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 18:17:56,510 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-2, peer_run=simulate_job]: got result from client site-2 for task: name=train, id=e277103e-8b4a-4a10-9202-cf52a937c773\n",
      "2023-06-01 18:17:56,513 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-2, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: ignored result submission since server runner's status is done\n",
      "2023-06-01 18:17:56,515 - SubmitUpdateCommand - INFO - submit_update process. client_name:site-2   task_id:e277103e-8b4a-4a10-9202-cf52a937c773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:17:56.414454 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Computed 7 weight differences for global model of length 7\n",
      "I0601 18:17:56.414947 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Local steps per epoch: 9\n",
      "I0601 18:17:56.415169 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Local epochs finished. Returning shareable\n",
      "I0601 18:17:56.416029 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: finished processing task\n",
      "I0601 18:17:56.419102 140709571065600 fed_client_base.py:296] Starting to push execute result.\n",
      "I0601 18:17:56.519334 140709571065600 communicator.py:268]  SubmitUpdate size: 16873459 Bytes. time: 0.09986448287963867 seconds\n",
      "I0601 18:17:56.521765 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: result sent to server for task: name=train, id=e277103e-8b4a-4a10-9202-cf52a937c773\n",
      "I0601 18:17:56.522298 140713251325760 simulator_worker.py:94] Finished one task run for client: site-2 interval: 2 task_processed: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2023-06-01 18:17:56,414 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Computed 7 weight differences for global model of length 7\n",
      "2023-06-01 18:17:56,414 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Local steps per epoch: 9\n",
      "2023-06-01 18:17:56,415 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: Local epochs finished. Returning shareable\n",
      "2023-06-01 18:17:56,416 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: finished processing task\n",
      "2023-06-01 18:17:56,419 - FederatedClient - INFO - Starting to push execute result.\n",
      "2023-06-01 18:17:56,519 - Communicator - INFO -  SubmitUpdate size: 16873459 Bytes. time: 0.09986448287963867 seconds\n",
      "2023-06-01 18:17:56,521 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=e277103e-8b4a-4a10-9202-cf52a937c773]: result sent to server for task: name=train, id=e277103e-8b4a-4a10-9202-cf52a937c773\n",
      "2023-06-01 18:17:56,522 - ClientTaskWorker - INFO - Finished one task run for client: site-2 interval: 2 task_processed: True\n",
      "2023-06-01 18:17:58,528 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-2, peer_run=simulate_job]: server runner is finalizing - asked client to end the run\n",
      "2023-06-01 18:17:58,543 - GetTaskCommand - INFO - return task to client.  client_name: site-2  task_name: __end_run__   task_id:   sharable_header_task_id: \n",
      "2023-06-01 18:17:58,550 - FederatedClient - INFO - Shutting down client run: site-1\n",
      "2023-06-01 18:17:58,552 - FederatedClient - INFO - Shutting down client run: site-2\n",
      "2023-06-01 18:17:58,553 - FederatedClient - INFO - Shutting down client run: site-3\n",
      "2023-06-01 18:17:58,554 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: asked to abort - triggered abort_signal to stop the RUN\n",
      "2023-06-01 18:17:58,548 - FederatedClient - INFO - pull_task completed. Task name:__end_run__ Status:True \n",
      "2023-06-01 18:17:58,549 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: server asked to end the run\n",
      "2023-06-01 18:17:58,549 - ClientTaskWorker - INFO - End the Simulator run.\n",
      "2023-06-01 18:17:58,549 - ClientTaskWorker - INFO - Clean up ClientRunner for : site-2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:17:58.548664 140713251325760 fed_client.py:91] pull_task completed. Task name:__end_run__ Status:True \n",
      "I0601 18:17:58.549079 140713251325760 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: server asked to end the run\n",
      "I0601 18:17:58.549272 140713251325760 simulator_worker.py:102] End the Simulator run.\n",
      "I0601 18:17:58.549880 140713251325760 simulator_worker.py:125] Clean up ClientRunner for : site-2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 18:18:02,196 - MPM - INFO - MPM: Good Bye!\n",
      "Simulator finished with run_status 0\n"
     ]
    }
   ],
   "source": [
    "from nvflare import SimulatorRunner    \n",
    "\n",
    "simulator = SimulatorRunner(\n",
    "    job_folder=\"jobs/gpt_p-tuning_local_345M\",\n",
    "    workspace=\"/tmp/nvflare/nemo/gpt_p-tuning_local_345M\",\n",
    "    n_clients=3,\n",
    "    threads=3\n",
    ")\n",
    "run_status = simulator.run()\n",
    "print(\"Simulator finished with run_status\", run_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45347828",
   "metadata": {},
   "source": [
    "#### 2. Federated P-Tuning\n",
    "We use the [FedAvg](https://arxiv.org/abs/1602.05629) algorithm to p-tune the model in a federated scenario. First, create and modify the configuration files again. \n",
    "This time, we increase the number of FL rounds and decrease the number of local epochs per round to match the federated scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbd94df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created configs for 3 clients and set ROOT_DIR to /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning\n"
     ]
    }
   ],
   "source": [
    "!python3 create_configs.py --job_folder \"jobs/gpt_p-tuning_fedavg_345M\" --num_clients 3 --aggregation_epochs 1 --num_rounds 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c4ee87",
   "metadata": {},
   "source": [
    "Next, simulate the federated p-tuning using FedAvg. Here, each client p-tunes for one local epoch before sending their local model updates to the server for aggregation. This is repeated for 50 FL rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75a57542",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 18:18:03,497 - SimulatorRunner - INFO - Create the Simulator Server.\n",
      "2023-06-01 18:18:03,504 - Cell - INFO - server: creating listener on tcp://0:55255\n",
      "2023-06-01 18:18:03,506 - Cell - INFO - server: created backbone external listener for tcp://0:55255\n",
      "2023-06-01 18:18:03,507 - ConnectorManager - INFO - 6413: Try start_listener Listener resources: {'secure': False, 'host': 'localhost'}\n",
      "2023-06-01 18:18:03,508 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00002 PASSIVE tcp://0:4457] is starting\n",
      "2023-06-01 18:18:04,011 - Cell - INFO - server: created backbone internal listener for tcp://localhost:4457\n",
      "2023-06-01 18:18:04,017 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 PASSIVE tcp://0:55255] is starting\n",
      "2023-06-01 18:18:04,215 - nvflare.fuel.hci.server.hci - INFO - Starting Admin Server localhost on Port 59359\n",
      "2023-06-01 18:18:04,217 - SimulatorRunner - INFO - Deploy the Apps.\n",
      "2023-06-01 18:18:04,229 - SimulatorRunner - INFO - Create the simulate clients.\n",
      "2023-06-01 18:18:04,235 - ClientManager - INFO - Client: New client site-1@100.96.239.80 joined. Sent token: 2c6b1dd9-7453-420d-8d5d-23a3bd708c39.  Total clients: 1\n",
      "2023-06-01 18:18:04,238 - FederatedClient - INFO - Successfully registered client:site-1 for project simulator_server. Token:2c6b1dd9-7453-420d-8d5d-23a3bd708c39 SSID:\n",
      "2023-06-01 18:18:04,244 - ClientManager - INFO - Client: New client site-2@100.96.239.80 joined. Sent token: 68315dac-c838-4b03-a379-589e6b2fb3de.  Total clients: 2\n",
      "2023-06-01 18:18:04,246 - FederatedClient - INFO - Successfully registered client:site-2 for project simulator_server. Token:68315dac-c838-4b03-a379-589e6b2fb3de SSID:\n",
      "2023-06-01 18:18:04,251 - ClientManager - INFO - Client: New client site-3@100.96.239.80 joined. Sent token: 078aa2bb-202c-4c0f-a5bd-4aee4e805994.  Total clients: 3\n",
      "2023-06-01 18:18:04,253 - FederatedClient - INFO - Successfully registered client:site-3 for project simulator_server. Token:078aa2bb-202c-4c0f-a5bd-4aee4e805994 SSID:\n",
      "2023-06-01 18:18:04,256 - SimulatorRunner - INFO - Set the client status ready.\n",
      "2023-06-01 18:18:04,257 - SimulatorRunner - INFO - Deploy and start the Server App.\n",
      "2023-06-01 18:18:04,259 - ServerCommandAgent - INFO - ServerCommandAgent cell register_request_cb: server.simulate_job\n",
      "NEMO version 1.17.0\n",
      "2023-06-01 18:18:05,484 - IntimeModelSelector - INFO - model selection weights control: None\n",
      "2023-06-01 18:18:05,490 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job]: Server runner starting ...\n",
      "2023-06-01 18:18:05,620 - ServerPromptEncoder - INFO - [identity=simulator_server, run=simulate_job]: Initialized prompt encoder type PromptEncoderType.MLP\n",
      "2023-06-01 18:18:05,627 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job]: starting workflow share_config (<class 'nemo_nvflare.share_config.ShareConfig'>) ...\n",
      "2023-06-01 18:18:05,629 - ShareConfig - INFO - [identity=simulator_server, run=simulate_job]: Initializing BroadcastAndProcess.\n",
      "2023-06-01 18:18:05,632 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job]: Workflow share_config (<class 'nemo_nvflare.share_config.ShareConfig'>) started\n",
      "2023-06-01 18:18:05,682 - ConfigSharer - INFO - [identity=simulator_server, run=simulate_job, wf=share_config]: Load model configuration from /tmp/nvflare/nemo/gpt_p-tuning_fedavg_345M/simulate_job/app_server/config/megatron_gpt_prompt_learning_config.yaml\n",
      "2023-06-01 18:18:05,686 - ConfigSharer - INFO - [identity=simulator_server, run=simulate_job, wf=share_config]: Load task templates from /tmp/nvflare/nemo/gpt_p-tuning_fedavg_345M/simulate_job/app_server/config/task_templates.json\n",
      "2023-06-01 18:18:05,698 - ShareConfig - INFO - [identity=simulator_server, run=simulate_job, wf=share_config]: scheduled task share_config\n",
      "2023-06-01 18:18:06,263 - SimulatorClientRunner - INFO - Start the clients run simulation.\n",
      "2023-06-01 18:18:07,267 - SimulatorClientRunner - INFO - Simulate Run client: site-1\n",
      "2023-06-01 18:18:07,269 - SimulatorClientRunner - INFO - Simulate Run client: site-2\n",
      "2023-06-01 18:18:07,293 - SimulatorClientRunner - INFO - Simulate Run client: site-3\n",
      "2023-06-01 18:18:08,339 - ClientTaskWorker - INFO - ClientTaskWorker started to run\n",
      "2023-06-01 18:18:08,341 - ClientTaskWorker - INFO - ClientTaskWorker started to run\n",
      "2023-06-01 18:18:08,341 - Cell - INFO - site-1.simulate_job: created backbone external connector to tcp://localhost:55255\n",
      "2023-06-01 18:18:08,341 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 ACTIVE tcp://localhost:55255] is starting\n",
      "2023-06-01 18:18:08,343 - Cell - INFO - site-2.simulate_job: created backbone external connector to tcp://localhost:55255\n",
      "2023-06-01 18:18:08,343 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 ACTIVE tcp://localhost:55255] is starting\n",
      "2023-06-01 18:18:08,370 - ClientTaskWorker - INFO - ClientTaskWorker started to run\n",
      "2023-06-01 18:18:08,372 - Cell - INFO - site-3.simulate_job: created backbone external connector to tcp://localhost:55255\n",
      "2023-06-01 18:18:08,372 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 ACTIVE tcp://localhost:55255] is starting\n",
      "2023-06-01 18:18:15,491 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmp64ywuu6o\n",
      "2023-06-01 18:18:15,492 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmp64ywuu6o/_remote_module_non_scriptable.py\n",
      "2023-06-01 18:18:15,540 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmp50n68off\n",
      "2023-06-01 18:18:15,541 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmp50n68off/_remote_module_non_scriptable.py\n",
      "2023-06-01 18:18:15,659 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmp4ttyhsie\n",
      "2023-06-01 18:18:15,660 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmp4ttyhsie/_remote_module_non_scriptable.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-06-01 18:18:23 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-06-01 18:18:23 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-06-01 18:18:23 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-06-01 18:18:23 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-06-01 18:18:23 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-06-01 18:18:23 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-06-01 18:18:24 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-06-01 18:18:24 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 18:18:25,109 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-2, peer_run=simulate_job, task_name=share_config, task_id=6836e3dd-68ed-4928-b9f4-b1b659918590]: assigned task to client site-2: name=share_config, id=6836e3dd-68ed-4928-b9f4-b1b659918590\n",
      "2023-06-01 18:18:25,111 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-2, peer_run=simulate_job, task_name=share_config, task_id=6836e3dd-68ed-4928-b9f4-b1b659918590]: sent task assignment to client. client_name:site-2 task_id:6836e3dd-68ed-4928-b9f4-b1b659918590\n",
      "2023-06-01 18:18:25,115 - GetTaskCommand - INFO - return task to client.  client_name: site-2  task_name: share_config   task_id: 6836e3dd-68ed-4928-b9f4-b1b659918590  sharable_header_task_id: 6836e3dd-68ed-4928-b9f4-b1b659918590\n",
      "2023-06-01 18:18:25,152 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-2, peer_run=simulate_job]: got result from client site-2 for task: name=share_config, id=6836e3dd-68ed-4928-b9f4-b1b659918590\n",
      "2023-06-01 18:18:25,154 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-2, peer_run=simulate_job, peer_rc=OK, task_name=share_config, task_id=6836e3dd-68ed-4928-b9f4-b1b659918590]: finished processing client result by share_config\n",
      "2023-06-01 18:18:25,155 - SubmitUpdateCommand - INFO - submit_update process. client_name:site-2   task_id:6836e3dd-68ed-4928-b9f4-b1b659918590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-06-01 18:18:25 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0601 18:18:25.103726 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job]: Initializing the Learner...\n",
      "I0601 18:18:25.104350 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job]: Running with distributed environment: LOCAL_RANK: 0, RANK: 0, WORLD_SIZE 1, MASTER_ADDR: localhost, and MASTER_PORT: 40037\n",
      "I0601 18:18:25.104617 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job]: client runner started\n",
      "I0601 18:18:25.104791 139825093494592 simulator_worker.py:85] Initialize ClientRunner for client: site-2\n",
      "I0601 18:18:25.117143 139823787386624 communicator.py:200] Received from simulator_server server  (3492 Bytes). getTask: share_config time: 0.009407520294189453 seconds\n",
      "I0601 18:18:25.121602 139825093494592 fed_client.py:91] pull_task completed. Task name:share_config Status:True \n",
      "I0601 18:18:25.121887 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=share_config, id=6836e3dd-68ed-4928-b9f4-b1b659918590\n",
      "I0601 18:18:25.122519 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=6836e3dd-68ed-4928-b9f4-b1b659918590]: invoking task executor <class 'nemo_nvflare.learner_executor.NemoLearnerExecutor'>\n",
      "I0601 18:18:25.122750 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=6836e3dd-68ed-4928-b9f4-b1b659918590]: Initializing the Learner...\n",
      "I0601 18:18:25.123073 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=6836e3dd-68ed-4928-b9f4-b1b659918590]: Running with distributed environment: LOCAL_RANK: 0, RANK: 0, WORLD_SIZE 1, MASTER_ADDR: localhost, and MASTER_PORT: 33589\n",
      "I0601 18:18:25.123268 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=6836e3dd-68ed-4928-b9f4-b1b659918590]: Client trainer got task: share_config\n",
      "I0601 18:18:25.147979 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=6836e3dd-68ed-4928-b9f4-b1b659918590]: Received config with 2 entries from server.\n",
      "I0601 18:18:25.148598 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=6836e3dd-68ed-4928-b9f4-b1b659918590]: finished processing task\n",
      "I0601 18:18:25.150495 139823586051840 fed_client_base.py:296] Starting to push execute result.\n",
      "I0601 18:18:25.157694 139823586051840 communicator.py:268]  SubmitUpdate size: 477 Bytes. time: 0.0069637298583984375 seconds\n",
      "I0601 18:18:25.158693 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=6836e3dd-68ed-4928-b9f4-b1b659918590]: result sent to server for task: name=share_config, id=6836e3dd-68ed-4928-b9f4-b1b659918590\n",
      "I0601 18:18:25.159019 139825093494592 simulator_worker.py:94] Finished one task run for client: site-2 interval: 2 task_processed: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 18:18:25,231 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-1, peer_run=simulate_job, task_name=share_config, task_id=f4db6818-240b-4d93-94ba-19ec7015715a]: assigned task to client site-1: name=share_config, id=f4db6818-240b-4d93-94ba-19ec7015715a\n",
      "2023-06-01 18:18:25,233 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-1, peer_run=simulate_job, task_name=share_config, task_id=f4db6818-240b-4d93-94ba-19ec7015715a]: sent task assignment to client. client_name:site-1 task_id:f4db6818-240b-4d93-94ba-19ec7015715a\n",
      "2023-06-01 18:18:25,234 - GetTaskCommand - INFO - return task to client.  client_name: site-1  task_name: share_config   task_id: f4db6818-240b-4d93-94ba-19ec7015715a  sharable_header_task_id: f4db6818-240b-4d93-94ba-19ec7015715a\n",
      "2023-06-01 18:18:25,271 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-1, peer_run=simulate_job]: got result from client site-1 for task: name=share_config, id=f4db6818-240b-4d93-94ba-19ec7015715a\n",
      "2023-06-01 18:18:25,274 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-1, peer_run=simulate_job, peer_rc=OK, task_name=share_config, task_id=f4db6818-240b-4d93-94ba-19ec7015715a]: finished processing client result by share_config\n",
      "2023-06-01 18:18:25,275 - SubmitUpdateCommand - INFO - submit_update process. client_name:site-1   task_id:f4db6818-240b-4d93-94ba-19ec7015715a\n",
      "NEMO version 1.17.0\n",
      "2023-06-01 18:18:25,103 - PromptLearner - INFO - [identity=site-2, run=simulate_job]: Initializing the Learner...\n",
      "2023-06-01 18:18:25,104 - PromptLearner - INFO - [identity=site-2, run=simulate_job]: Running with distributed environment: LOCAL_RANK: 0, RANK: 0, WORLD_SIZE 1, MASTER_ADDR: localhost, and MASTER_PORT: 40037\n",
      "2023-06-01 18:18:25,104 - ClientRunner - INFO - [identity=site-2, run=simulate_job]: client runner started\n",
      "2023-06-01 18:18:25,104 - ClientTaskWorker - INFO - Initialize ClientRunner for client: site-2\n",
      "2023-06-01 18:18:25,117 - Communicator - INFO - Received from simulator_server server  (3492 Bytes). getTask: share_config time: 0.009407520294189453 seconds\n",
      "2023-06-01 18:18:25,121 - FederatedClient - INFO - pull_task completed. Task name:share_config Status:True \n",
      "2023-06-01 18:18:25,121 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=share_config, id=6836e3dd-68ed-4928-b9f4-b1b659918590\n",
      "2023-06-01 18:18:25,122 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=6836e3dd-68ed-4928-b9f4-b1b659918590]: invoking task executor <class 'nemo_nvflare.learner_executor.NemoLearnerExecutor'>\n",
      "2023-06-01 18:18:25,122 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=6836e3dd-68ed-4928-b9f4-b1b659918590]: Initializing the Learner...\n",
      "2023-06-01 18:18:25,123 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=6836e3dd-68ed-4928-b9f4-b1b659918590]: Running with distributed environment: LOCAL_RANK: 0, RANK: 0, WORLD_SIZE 1, MASTER_ADDR: localhost, and MASTER_PORT: 33589\n",
      "2023-06-01 18:18:25,123 - NemoLearnerExecutor - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=6836e3dd-68ed-4928-b9f4-b1b659918590]: Client trainer got task: share_config\n",
      "2023-06-01 18:18:25,147 - NemoLearnerExecutor - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=6836e3dd-68ed-4928-b9f4-b1b659918590]: Received config with 2 entries from server.\n",
      "2023-06-01 18:18:25,148 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=6836e3dd-68ed-4928-b9f4-b1b659918590]: finished processing task\n",
      "2023-06-01 18:18:25,150 - FederatedClient - INFO - Starting to push execute result.\n",
      "2023-06-01 18:18:25,157 - Communicator - INFO -  SubmitUpdate size: 477 Bytes. time: 0.0069637298583984375 seconds\n",
      "2023-06-01 18:18:25,158 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=6836e3dd-68ed-4928-b9f4-b1b659918590]: result sent to server for task: name=share_config, id=6836e3dd-68ed-4928-b9f4-b1b659918590\n",
      "2023-06-01 18:18:25,159 - ClientTaskWorker - INFO - Finished one task run for client: site-2 interval: 2 task_processed: True\n",
      "NEMO version 1.17.0\n",
      "2023-06-01 18:18:25,226 - PromptLearner - INFO - [identity=site-1, run=simulate_job]: Initializing the Learner...\n",
      "2023-06-01 18:18:25,227 - PromptLearner - INFO - [identity=site-1, run=simulate_job]: Running with distributed environment: LOCAL_RANK: 0, RANK: 0, WORLD_SIZE 1, MASTER_ADDR: localhost, and MASTER_PORT: 44059\n",
      "2023-06-01 18:18:25,227 - ClientRunner - INFO - [identity=site-1, run=simulate_job]: client runner started\n",
      "2023-06-01 18:18:25,227 - ClientTaskWorker - INFO - Initialize ClientRunner for client: site-1\n",
      "2023-06-01 18:18:25,236 - Communicator - INFO - Received from simulator_server server  (3492 Bytes). getTask: share_config time: 0.00652313232421875 seconds\n",
      "2023-06-01 18:18:25,240 - FederatedClient - INFO - pull_task completed. Task name:share_config Status:True \n",
      "2023-06-01 18:18:25,240 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=share_config, id=f4db6818-240b-4d93-94ba-19ec7015715a\n",
      "2023-06-01 18:18:25,241 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=f4db6818-240b-4d93-94ba-19ec7015715a]: invoking task executor <class 'nemo_nvflare.learner_executor.NemoLearnerExecutor'>\n",
      "2023-06-01 18:18:25,241 - PromptLearner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=f4db6818-240b-4d93-94ba-19ec7015715a]: Initializing the Learner...\n",
      "2023-06-01 18:18:25,242 - PromptLearner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=f4db6818-240b-4d93-94ba-19ec7015715a]: Running with distributed environment: LOCAL_RANK: 0, RANK: 0, WORLD_SIZE 1, MASTER_ADDR: localhost, and MASTER_PORT: 39745\n",
      "2023-06-01 18:18:25,242 - NemoLearnerExecutor - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=f4db6818-240b-4d93-94ba-19ec7015715a]: Client trainer got task: share_config\n",
      "2023-06-01 18:18:25,268 - NemoLearnerExecutor - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=f4db6818-240b-4d93-94ba-19ec7015715a]: Received config with 2 entries from server.\n",
      "2023-06-01 18:18:25,268 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=f4db6818-240b-4d93-94ba-19ec7015715a]: finished processing task\n",
      "2023-06-01 18:18:25,270 - FederatedClient - INFO - Starting to push execute result.\n",
      "2023-06-01 18:18:25,277 - Communicator - INFO -  SubmitUpdate size: 477 Bytes. time: 0.006973981857299805 seconds\n",
      "2023-06-01 18:18:25,278 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=f4db6818-240b-4d93-94ba-19ec7015715a]: result sent to server for task: name=share_config, id=f4db6818-240b-4d93-94ba-19ec7015715a\n",
      "2023-06-01 18:18:25,278 - ClientTaskWorker - INFO - Finished one task run for client: site-1 interval: 2 task_processed: True\n",
      "2023-06-01 18:18:25,378 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-3, peer_run=simulate_job, task_name=share_config, task_id=7947adaf-5f47-40a8-b831-44172351602a]: assigned task to client site-3: name=share_config, id=7947adaf-5f47-40a8-b831-44172351602a\n",
      "2023-06-01 18:18:25,380 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-3, peer_run=simulate_job, task_name=share_config, task_id=7947adaf-5f47-40a8-b831-44172351602a]: sent task assignment to client. client_name:site-3 task_id:7947adaf-5f47-40a8-b831-44172351602a\n",
      "2023-06-01 18:18:25,381 - GetTaskCommand - INFO - return task to client.  client_name: site-3  task_name: share_config   task_id: 7947adaf-5f47-40a8-b831-44172351602a  sharable_header_task_id: 7947adaf-5f47-40a8-b831-44172351602a\n",
      "2023-06-01 18:18:25,422 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-3, peer_run=simulate_job]: got result from client site-3 for task: name=share_config, id=7947adaf-5f47-40a8-b831-44172351602a\n",
      "2023-06-01 18:18:25,424 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-3, peer_run=simulate_job, peer_rc=OK, task_name=share_config, task_id=7947adaf-5f47-40a8-b831-44172351602a]: finished processing client result by share_config\n",
      "2023-06-01 18:18:25,425 - SubmitUpdateCommand - INFO - submit_update process. client_name:site-3   task_id:7947adaf-5f47-40a8-b831-44172351602a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0601 18:18:25.226405 140049889785664 fl_component.py:134] [identity=site-1, run=simulate_job]: Initializing the Learner...\n",
      "I0601 18:18:25.227121 140049889785664 fl_component.py:134] [identity=site-1, run=simulate_job]: Running with distributed environment: LOCAL_RANK: 0, RANK: 0, WORLD_SIZE 1, MASTER_ADDR: localhost, and MASTER_PORT: 44059\n",
      "I0601 18:18:25.227404 140049889785664 fl_component.py:134] [identity=site-1, run=simulate_job]: client runner started\n",
      "I0601 18:18:25.227586 140049889785664 simulator_worker.py:85] Initialize ClientRunner for client: site-1\n",
      "I0601 18:18:25.236530 140048717907712 communicator.py:200] Received from simulator_server server  (3492 Bytes). getTask: share_config time: 0.00652313232421875 seconds\n",
      "I0601 18:18:25.240642 140049889785664 fed_client.py:91] pull_task completed. Task name:share_config Status:True \n",
      "I0601 18:18:25.240924 140049889785664 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=share_config, id=f4db6818-240b-4d93-94ba-19ec7015715a\n",
      "I0601 18:18:25.241555 140049889785664 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=f4db6818-240b-4d93-94ba-19ec7015715a]: invoking task executor <class 'nemo_nvflare.learner_executor.NemoLearnerExecutor'>\n",
      "I0601 18:18:25.241788 140049889785664 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=f4db6818-240b-4d93-94ba-19ec7015715a]: Initializing the Learner...\n",
      "I0601 18:18:25.242078 140049889785664 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=f4db6818-240b-4d93-94ba-19ec7015715a]: Running with distributed environment: LOCAL_RANK: 0, RANK: 0, WORLD_SIZE 1, MASTER_ADDR: localhost, and MASTER_PORT: 39745\n",
      "I0601 18:18:25.242302 140049889785664 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=f4db6818-240b-4d93-94ba-19ec7015715a]: Client trainer got task: share_config\n",
      "I0601 18:18:25.268077 140049889785664 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=f4db6818-240b-4d93-94ba-19ec7015715a]: Received config with 2 entries from server.\n",
      "I0601 18:18:25.268762 140049889785664 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=f4db6818-240b-4d93-94ba-19ec7015715a]: finished processing task\n",
      "I0601 18:18:25.270221 140048717907712 fed_client_base.py:296] Starting to push execute result.\n",
      "I0601 18:18:25.277451 140048717907712 communicator.py:268]  SubmitUpdate size: 477 Bytes. time: 0.006973981857299805 seconds\n",
      "I0601 18:18:25.278344 140049889785664 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=f4db6818-240b-4d93-94ba-19ec7015715a]: result sent to server for task: name=share_config, id=f4db6818-240b-4d93-94ba-19ec7015715a\n",
      "I0601 18:18:25.278687 140049889785664 simulator_worker.py:94] Finished one task run for client: site-1 interval: 2 task_processed: True\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0601 18:18:25.371679 140412718274368 fl_component.py:134] [identity=site-3, run=simulate_job]: Initializing the Learner...\n",
      "I0601 18:18:25.372309 140412718274368 fl_component.py:134] [identity=site-3, run=simulate_job]: Running with distributed environment: LOCAL_RANK: 0, RANK: 0, WORLD_SIZE 1, MASTER_ADDR: localhost, and MASTER_PORT: 44417\n",
      "I0601 18:18:25.372578 140412718274368 fl_component.py:134] [identity=site-3, run=simulate_job]: client runner started\n",
      "I0601 18:18:25.372755 140412718274368 simulator_worker.py:85] Initialize ClientRunner for client: site-3\n",
      "I0601 18:18:25.384201 140410904241920 communicator.py:200] Received from simulator_server server  (3492 Bytes). getTask: share_config time: 0.007061958312988281 seconds\n",
      "I0601 18:18:25.389522 140412718274368 fed_client.py:91] pull_task completed. Task name:share_config Status:True \n",
      "I0601 18:18:25.389889 140412718274368 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=share_config, id=7947adaf-5f47-40a8-b831-44172351602a\n",
      "I0601 18:18:25.390579 140412718274368 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=7947adaf-5f47-40a8-b831-44172351602a]: invoking task executor <class 'nemo_nvflare.learner_executor.NemoLearnerExecutor'>\n",
      "I0601 18:18:25.390826 140412718274368 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=7947adaf-5f47-40a8-b831-44172351602a]: Initializing the Learner...\n",
      "I0601 18:18:25.391142 140412718274368 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=7947adaf-5f47-40a8-b831-44172351602a]: Running with distributed environment: LOCAL_RANK: 0, RANK: 0, WORLD_SIZE 1, MASTER_ADDR: localhost, and MASTER_PORT: 36109\n",
      "I0601 18:18:25.391355 140412718274368 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=7947adaf-5f47-40a8-b831-44172351602a]: Client trainer got task: share_config\n",
      "I0601 18:18:25.417542 140412718274368 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=7947adaf-5f47-40a8-b831-44172351602a]: Received config with 2 entries from server.\n",
      "I0601 18:18:25.418318 140412718274368 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=7947adaf-5f47-40a8-b831-44172351602a]: finished processing task\n",
      "I0601 18:18:25.420398 140410198423296 fed_client_base.py:296] Starting to push execute result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 18:18:25,512 - ShareConfig - INFO - [identity=simulator_server, run=simulate_job, wf=share_config]: task share_config exit with status TaskCompletionStatus.OK\n",
      "NEMO version 1.17.0\n",
      "2023-06-01 18:18:25,371 - PromptLearner - INFO - [identity=site-3, run=simulate_job]: Initializing the Learner...\n",
      "2023-06-01 18:18:25,372 - PromptLearner - INFO - [identity=site-3, run=simulate_job]: Running with distributed environment: LOCAL_RANK: 0, RANK: 0, WORLD_SIZE 1, MASTER_ADDR: localhost, and MASTER_PORT: 44417\n",
      "2023-06-01 18:18:25,372 - ClientRunner - INFO - [identity=site-3, run=simulate_job]: client runner started\n",
      "2023-06-01 18:18:25,372 - ClientTaskWorker - INFO - Initialize ClientRunner for client: site-3\n",
      "2023-06-01 18:18:25,384 - Communicator - INFO - Received from simulator_server server  (3492 Bytes). getTask: share_config time: 0.007061958312988281 seconds\n",
      "2023-06-01 18:18:25,389 - FederatedClient - INFO - pull_task completed. Task name:share_config Status:True \n",
      "2023-06-01 18:18:25,389 - ClientRunner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=share_config, id=7947adaf-5f47-40a8-b831-44172351602a\n",
      "2023-06-01 18:18:25,390 - ClientRunner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=7947adaf-5f47-40a8-b831-44172351602a]: invoking task executor <class 'nemo_nvflare.learner_executor.NemoLearnerExecutor'>\n",
      "2023-06-01 18:18:25,390 - PromptLearner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=7947adaf-5f47-40a8-b831-44172351602a]: Initializing the Learner...\n",
      "2023-06-01 18:18:25,391 - PromptLearner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=7947adaf-5f47-40a8-b831-44172351602a]: Running with distributed environment: LOCAL_RANK: 0, RANK: 0, WORLD_SIZE 1, MASTER_ADDR: localhost, and MASTER_PORT: 36109\n",
      "2023-06-01 18:18:25,391 - NemoLearnerExecutor - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=7947adaf-5f47-40a8-b831-44172351602a]: Client trainer got task: share_config\n",
      "2023-06-01 18:18:25,417 - NemoLearnerExecutor - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=7947adaf-5f47-40a8-b831-44172351602a]: Received config with 2 entries from server.\n",
      "2023-06-01 18:18:25,418 - ClientRunner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=7947adaf-5f47-40a8-b831-44172351602a]: finished processing task\n",
      "2023-06-01 18:18:25,420 - FederatedClient - INFO - Starting to push execute result.\n",
      "2023-06-01 18:18:25,427 - Communicator - INFO -  SubmitUpdate size: 477 Bytes. time: 0.007112264633178711 seconds\n",
      "2023-06-01 18:18:25,428 - ClientRunner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=7947adaf-5f47-40a8-b831-44172351602a]: result sent to server for task: name=share_config, id=7947adaf-5f47-40a8-b831-44172351602a\n",
      "2023-06-01 18:18:25,429 - ClientTaskWorker - INFO - Finished one task run for client: site-3 interval: 2 task_processed: True\n",
      "2023-06-01 18:18:25,602 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config]: Workflow: share_config finalizing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:18:25.427738 140410198423296 communicator.py:268]  SubmitUpdate size: 477 Bytes. time: 0.007112264633178711 seconds\n",
      "I0601 18:18:25.428703 140412718274368 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=share_config, task_id=7947adaf-5f47-40a8-b831-44172351602a]: result sent to server for task: name=share_config, id=7947adaf-5f47-40a8-b831-44172351602a\n",
      "I0601 18:18:25.429044 140412718274368 simulator_worker.py:94] Finished one task run for client: site-3 interval: 2 task_processed: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 18:18:25,714 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config]: starting workflow scatter_and_gather (<class 'nvflare.app_common.workflows.scatter_and_gather.ScatterAndGather'>) ...\n",
      "2023-06-01 18:18:25,716 - ScatterAndGather - INFO - [identity=simulator_server, run=simulate_job, wf=share_config]: Initializing ScatterAndGather workflow.\n",
      "2023-06-01 18:18:25,719 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config]: Workflow scatter_and_gather (<class 'nvflare.app_common.workflows.scatter_and_gather.ScatterAndGather'>) started\n",
      "2023-06-01 18:18:25,720 - ScatterAndGather - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: Beginning ScatterAndGather training phase.\n",
      "2023-06-01 18:18:25,722 - ScatterAndGather - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: Round 0 started.\n",
      "2023-06-01 18:18:25,723 - ScatterAndGather - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: scheduled task train\n",
      "2023-06-01 18:18:27,165 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-2, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: assigned task to client site-2: name=train, id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff\n",
      "2023-06-01 18:18:27,167 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-2, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: sent task assignment to client. client_name:site-2 task_id:bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff\n",
      "2023-06-01 18:18:27,221 - GetTaskCommand - INFO - return task to client.  client_name: site-2  task_name: train   task_id: bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff  sharable_header_task_id: bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff\n",
      "2023-06-01 18:18:27,284 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-1, peer_run=simulate_job, task_name=train, task_id=bcf80bb2-5531-4837-8b76-815817acb3ef]: assigned task to client site-1: name=train, id=bcf80bb2-5531-4837-8b76-815817acb3ef\n",
      "2023-06-01 18:18:27,286 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-1, peer_run=simulate_job, task_name=train, task_id=bcf80bb2-5531-4837-8b76-815817acb3ef]: sent task assignment to client. client_name:site-1 task_id:bcf80bb2-5531-4837-8b76-815817acb3ef\n",
      "2023-06-01 18:18:27,331 - GetTaskCommand - INFO - return task to client.  client_name: site-1  task_name: train   task_id: bcf80bb2-5531-4837-8b76-815817acb3ef  sharable_header_task_id: bcf80bb2-5531-4837-8b76-815817acb3ef\n",
      "2023-06-01 18:18:27,421 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-1, peer_run=simulate_job]: got result from client site-1 for task: name=train, id=bcf80bb2-5531-4837-8b76-815817acb3ef\n",
      "2023-06-01 18:18:27,424 - ServerRunner - ERROR - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-1, peer_run=simulate_job, peer_rc=EXECUTION_EXCEPTION, task_name=train, task_id=bcf80bb2-5531-4837-8b76-815817acb3ef]: Aborting current RUN due to FATAL_SYSTEM_ERROR received: Result from site-1 is bad, error code: EXECUTION_EXCEPTION. ScatterAndGather exiting at round 0.\n",
      "2023-06-01 18:18:27,426 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-1, peer_run=simulate_job, peer_rc=EXECUTION_EXCEPTION, task_name=train, task_id=bcf80bb2-5531-4837-8b76-815817acb3ef]: asked to abort - triggered abort_signal to stop the RUN\n",
      "2023-06-01 18:18:27,427 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-1, peer_run=simulate_job, peer_rc=EXECUTION_EXCEPTION, task_name=train, task_id=bcf80bb2-5531-4837-8b76-815817acb3ef]: finished processing client result by scatter_and_gather\n",
      "2023-06-01 18:18:27,429 - SubmitUpdateCommand - INFO - submit_update process. client_name:site-1   task_id:bcf80bb2-5531-4837-8b76-815817acb3ef\n",
      "2023-06-01 18:18:27,434 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-3, peer_run=simulate_job]: server runner is finalizing - asked client to end the run\n",
      "2023-06-01 18:18:27,444 - GetTaskCommand - INFO - return task to client.  client_name: site-3  task_name: __end_run__   task_id:   sharable_header_task_id: \n",
      "2023-06-01 18:18:27,305 - Communicator - INFO - Received from simulator_server server  (16873468 Bytes). getTask: train time: 0.11535334587097168 seconds\n",
      "2023-06-01 18:18:27,307 - FederatedClient - INFO - pull_task completed. Task name:train Status:True \n",
      "2023-06-01 18:18:27,307 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=train, id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff\n",
      "2023-06-01 18:18:27,308 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: invoking task executor <class 'nemo_nvflare.learner_executor.NemoLearnerExecutor'>\n",
      "2023-06-01 18:18:27,308 - NemoLearnerExecutor - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Client trainer got task: train\n",
      "2023-06-01 18:18:27,308 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Configuring the Learner...\n",
      "2023-06-01 18:18:27,311 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Training with global_batch_size 64 and micro_batch_size 4\n",
      "2023-06-01 18:18:27,316 - pytorch_lightning.utilities.rank_zero - INFO - Using 16bit None Automatic Mixed Precision (AMP)\n",
      "2023-06-01 18:18:27,358 - pytorch_lightning.utilities.rank_zero - INFO - GPU available: True (cuda), used: True\n",
      "2023-06-01 18:18:27,358 - pytorch_lightning.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores\n",
      "2023-06-01 18:18:27,359 - pytorch_lightning.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs\n",
      "2023-06-01 18:18:27,359 - pytorch_lightning.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs\n",
      "2023-06-01 18:18:27,360 - pytorch_lightning.utilities.rank_zero - INFO - `Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "2023-06-01 18:18:27,374 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Model config - seed: 1234\n",
      "nemo_path: /tmp/nvflare/nemo/gpt_p-tuning_fedavg_345M/simulate_job/app_site-2/megatron_gpt_345m_sentiment.nemo\n",
      "virtual_prompt_style: P_TUNING\n",
      "tensor_model_parallel_size: 1\n",
      "pipeline_model_parallel_size: 1\n",
      "global_batch_size: 64\n",
      "micro_batch_size: 4\n",
      "validation_global_batch_size: ${model.global_batch_size}\n",
      "validation_micro_batch_size: ${model.micro_batch_size}\n",
      "validation_drop_last: false\n",
      "report_validation_metric: false\n",
      "validation_metric: accuracy\n",
      "restore_path: null\n",
      "language_model_path: /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/megatron_gpt_345m.nemo\n",
      "save_nemo_on_validation_end: true\n",
      "existing_tasks: []\n",
      "new_tasks:\n",
      "- chat\n",
      "sequence_parallel: false\n",
      "activations_checkpoint_granularity: null\n",
      "activations_checkpoint_method: null\n",
      "activations_checkpoint_num_layers: null\n",
      "task_templates:\n",
      "- taskname: sentiment\n",
      "  prompt_template: <|VIRTUAL_PROMPT_0|> {sentence} sentiment:{label}\n",
      "  total_virtual_tokens: 10\n",
      "  virtual_token_splits:\n",
      "  - 10\n",
      "  truncate_field: null\n",
      "  answer_only_loss: true\n",
      "  answer_field: label\n",
      "- taskname: chat\n",
      "  prompt_template: <|VIRTUAL_PROMPT_0|> {input} answer:{output}\n",
      "  total_virtual_tokens: 10\n",
      "  virtual_token_splits:\n",
      "  - 10\n",
      "  truncate_field: null\n",
      "  answer_only_loss: true\n",
      "  answer_field: output\n",
      "prompt_tuning:\n",
      "  new_prompt_init_methods:\n",
      "  - text\n",
      "  new_prompt_init_text:\n",
      "  - some init text goes here\n",
      "p_tuning:\n",
      "  encoder_type: mlp\n",
      "  dropout: 0.0\n",
      "  num_layers: 2\n",
      "  encoder_hidden: 2048\n",
      "  init_std: 0.023\n",
      "data:\n",
      "  train_ds:\n",
      "  - /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/data/FinancialPhraseBank-v1.0_split/site-1.jsonl\n",
      "  validation_ds:\n",
      "  - /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/data/FinancialPhraseBank-v1.0/financial_phrase_bank_val.jsonl\n",
      "  add_eos: true\n",
      "  shuffle: true\n",
      "  num_workers: 8\n",
      "  pin_memory: true\n",
      "  train_cache_data_path: null\n",
      "  validation_cache_data_path: null\n",
      "  test_cache_data_path: null\n",
      "  load_cache: false\n",
      "  max_seq_length: 1024\n",
      "  min_seq_length: 1\n",
      "optim:\n",
      "  name: fused_adam\n",
      "  lr: 0.0001\n",
      "  weight_decay: 0.01\n",
      "  betas:\n",
      "  - 0.9\n",
      "  - 0.98\n",
      "  sched:\n",
      "    name: CosineAnnealing\n",
      "    warmup_steps: 50\n",
      "    min_lr: 0.0\n",
      "    constant_steps: 0\n",
      "    monitor: val_loss\n",
      "    reduce_on_plateau: false\n",
      "    max_steps: 11000\n",
      "inference:\n",
      "  greedy: false\n",
      "  top_k: 0\n",
      "  top_p: 0.9\n",
      "  temperature: 1.0\n",
      "  tokens_to_generate: 30\n",
      "  repetition_penalty: 1.2\n",
      "  min_tokens_to_generate: 0\n",
      "precision: 16\n",
      "\n",
      "2023-06-01 18:18:27,377 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Trainer config - devices: 1\n",
      "accelerator: gpu\n",
      "num_nodes: 1\n",
      "precision: 16\n",
      "logger: true\n",
      "enable_checkpointing: false\n",
      "replace_sampler_ddp: false\n",
      "max_epochs: -1\n",
      "max_steps: -1\n",
      "log_every_n_steps: 10\n",
      "val_check_interval: 1.0\n",
      "gradient_clip_val: 1.0\n",
      "resume_from_checkpoint: null\n",
      "benchmark: false\n",
      "default_root_dir: /tmp/nvflare/nemo/gpt_p-tuning_fedavg_345M/simulate_job/app_site-2\n",
      "\n",
      "2023-06-01 18:18:27,411 - Communicator - INFO - Received from simulator_server server  (16873468 Bytes). getTask: train time: 0.10497117042541504 seconds\n",
      "2023-06-01 18:18:27,413 - FederatedClient - INFO - pull_task completed. Task name:train Status:True \n",
      "2023-06-01 18:18:27,413 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=train, id=bcf80bb2-5531-4837-8b76-815817acb3ef\n",
      "2023-06-01 18:18:27,414 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bcf80bb2-5531-4837-8b76-815817acb3ef]: invoking task executor <class 'nemo_nvflare.learner_executor.NemoLearnerExecutor'>\n",
      "2023-06-01 18:18:27,414 - NemoLearnerExecutor - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bcf80bb2-5531-4837-8b76-815817acb3ef]: Client trainer got task: train\n",
      "2023-06-01 18:18:27,414 - PromptLearner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bcf80bb2-5531-4837-8b76-815817acb3ef]: Configuring the Learner...\n",
      "2023-06-01 18:18:27,416 - NemoLearnerExecutor - ERROR - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bcf80bb2-5531-4837-8b76-815817acb3ef]: learner execute exception: No such file /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/data/FinancialPhraseBank-v1.0_split/site-0.jsonl!\n",
      "2023-06-01 18:18:27,417 - NemoLearnerExecutor - ERROR - Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/nvflare/app_common/executors/learner_executor.py\", line 77, in execute\n",
      "    return self.train(shareable, fl_ctx, abort_signal)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/nvflare/app_common/executors/learner_executor.py\", line 94, in train\n",
      "    validate_result: Shareable = self.learner.validate(shareable, fl_ctx, abort_signal)\n",
      "  File \"/workspace/Code/nvflare/nemo_nvflare/integration/nemo/nemo_nvflare/prompt_learner.py\", line 342, in validate\n",
      "    self._configure(fl_ctx)\n",
      "  File \"/workspace/Code/nvflare/nemo_nvflare/integration/nemo/nemo_nvflare/prompt_learner.py\", line 231, in _configure\n",
      "    self.config.model.data.train_ds = set_datafile_paths(self.train_ds_files, self.app_root)\n",
      "  File \"/workspace/Code/nvflare/nemo_nvflare/integration/nemo/nemo_nvflare/prompt_learner.py\", line 51, in set_datafile_paths\n",
      "    raise ValueError(f\"No such file {f}!\")\n",
      "ValueError: No such file /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/data/FinancialPhraseBank-v1.0_split/site-0.jsonl!\n",
      "\n",
      "2023-06-01 18:18:27,418 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bcf80bb2-5531-4837-8b76-815817acb3ef]: finished processing task\n",
      "2023-06-01 18:18:27,420 - FederatedClient - INFO - Starting to push execute result.\n",
      "2023-06-01 18:18:27,431 - Communicator - INFO -  SubmitUpdate size: 513 Bytes. time: 0.011312007904052734 seconds\n",
      "2023-06-01 18:18:27,432 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bcf80bb2-5531-4837-8b76-815817acb3ef]: result sent to server for task: name=train, id=bcf80bb2-5531-4837-8b76-815817acb3ef\n",
      "2023-06-01 18:18:27,433 - ClientTaskWorker - INFO - Finished one task run for client: site-1 interval: 2 task_processed: True\n",
      "2023-06-01 18:18:27,448 - FederatedClient - INFO - pull_task completed. Task name:__end_run__ Status:True \n",
      "2023-06-01 18:18:27,448 - ClientRunner - INFO - [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: server asked to end the run\n",
      "2023-06-01 18:18:27,449 - ClientTaskWorker - INFO - End the Simulator run.\n",
      "2023-06-01 18:18:27,449 - ClientTaskWorker - INFO - Clean up ClientRunner for : site-3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:18:27.305884 139823398516480 communicator.py:200] Received from simulator_server server  (16873468 Bytes). getTask: train time: 0.11535334587097168 seconds\n",
      "I0601 18:18:27.307244 139825093494592 fed_client.py:91] pull_task completed. Task name:train Status:True \n",
      "I0601 18:18:27.307551 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=train, id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff\n",
      "I0601 18:18:27.308239 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: invoking task executor <class 'nemo_nvflare.learner_executor.NemoLearnerExecutor'>\n",
      "I0601 18:18:27.308483 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Client trainer got task: train\n",
      "I0601 18:18:27.308748 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Configuring the Learner...\n",
      "I0601 18:18:27.311915 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Training with global_batch_size 64 and micro_batch_size 4\n",
      "I0601 18:18:27.316598 139825093494592 accelerator_connector.py:758] Using 16bit None Automatic Mixed Precision (AMP)\n",
      "I0601 18:18:27.358145 139825093494592 setup.py:163] GPU available: True (cuda), used: True\n",
      "I0601 18:18:27.358878 139825093494592 setup.py:166] TPU available: False, using: 0 TPU cores\n",
      "I0601 18:18:27.359079 139825093494592 setup.py:169] IPU available: False, using: 0 IPUs\n",
      "I0601 18:18:27.359252 139825093494592 setup.py:172] HPU available: False, using: 0 HPUs\n",
      "I0601 18:18:27.360242 139825093494592 setup.py:121] `Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "I0601 18:18:27.374725 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Model config - seed: 1234\n",
      "nemo_path: /tmp/nvflare/nemo/gpt_p-tuning_fedavg_345M/simulate_job/app_site-2/megatron_gpt_345m_sentiment.nemo\n",
      "virtual_prompt_style: P_TUNING\n",
      "tensor_model_parallel_size: 1\n",
      "pipeline_model_parallel_size: 1\n",
      "global_batch_size: 64\n",
      "micro_batch_size: 4\n",
      "validation_global_batch_size: ${model.global_batch_size}\n",
      "validation_micro_batch_size: ${model.micro_batch_size}\n",
      "validation_drop_last: false\n",
      "report_validation_metric: false\n",
      "validation_metric: accuracy\n",
      "restore_path: null\n",
      "language_model_path: /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/megatron_gpt_345m.nemo\n",
      "save_nemo_on_validation_end: true\n",
      "existing_tasks: []\n",
      "new_tasks:\n",
      "- chat\n",
      "sequence_parallel: false\n",
      "activations_checkpoint_granularity: null\n",
      "activations_checkpoint_method: null\n",
      "activations_checkpoint_num_layers: null\n",
      "task_templates:\n",
      "- taskname: sentiment\n",
      "  prompt_template: <|VIRTUAL_PROMPT_0|> {sentence} sentiment:{label}\n",
      "  total_virtual_tokens: 10\n",
      "  virtual_token_splits:\n",
      "  - 10\n",
      "  truncate_field: null\n",
      "  answer_only_loss: true\n",
      "  answer_field: label\n",
      "- taskname: chat\n",
      "  prompt_template: <|VIRTUAL_PROMPT_0|> {input} answer:{output}\n",
      "  total_virtual_tokens: 10\n",
      "  virtual_token_splits:\n",
      "  - 10\n",
      "  truncate_field: null\n",
      "  answer_only_loss: true\n",
      "  answer_field: output\n",
      "prompt_tuning:\n",
      "  new_prompt_init_methods:\n",
      "  - text\n",
      "  new_prompt_init_text:\n",
      "  - some init text goes here\n",
      "p_tuning:\n",
      "  encoder_type: mlp\n",
      "  dropout: 0.0\n",
      "  num_layers: 2\n",
      "  encoder_hidden: 2048\n",
      "  init_std: 0.023\n",
      "data:\n",
      "  train_ds:\n",
      "  - /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/data/FinancialPhraseBank-v1.0_split/site-1.jsonl\n",
      "  validation_ds:\n",
      "  - /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/data/FinancialPhraseBank-v1.0/financial_phrase_bank_val.jsonl\n",
      "  add_eos: true\n",
      "  shuffle: true\n",
      "  num_workers: 8\n",
      "  pin_memory: true\n",
      "  train_cache_data_path: null\n",
      "  validation_cache_data_path: null\n",
      "  test_cache_data_path: null\n",
      "  load_cache: false\n",
      "  max_seq_length: 1024\n",
      "  min_seq_length: 1\n",
      "optim:\n",
      "  name: fused_adam\n",
      "  lr: 0.0001\n",
      "  weight_decay: 0.01\n",
      "  betas:\n",
      "  - 0.9\n",
      "  - 0.98\n",
      "  sched:\n",
      "    name: CosineAnnealing\n",
      "    warmup_steps: 50\n",
      "    min_lr: 0.0\n",
      "    constant_steps: 0\n",
      "    monitor: val_loss\n",
      "    reduce_on_plateau: false\n",
      "    max_steps: 11000\n",
      "inference:\n",
      "  greedy: false\n",
      "  top_k: 0\n",
      "  top_p: 0.9\n",
      "  temperature: 1.0\n",
      "  tokens_to_generate: 30\n",
      "  repetition_penalty: 1.2\n",
      "  min_tokens_to_generate: 0\n",
      "precision: 16\n",
      "\n",
      "I0601 18:18:27.377495 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Trainer config - devices: 1\n",
      "accelerator: gpu\n",
      "num_nodes: 1\n",
      "precision: 16\n",
      "logger: true\n",
      "enable_checkpointing: false\n",
      "replace_sampler_ddp: false\n",
      "max_epochs: -1\n",
      "max_steps: -1\n",
      "log_every_n_steps: 10\n",
      "val_check_interval: 1.0\n",
      "gradient_clip_val: 1.0\n",
      "resume_from_checkpoint: null\n",
      "benchmark: false\n",
      "default_root_dir: /tmp/nvflare/nemo/gpt_p-tuning_fedavg_345M/simulate_job/app_site-2\n",
      "\n",
      "I0601 18:18:27.411887 140048415905536 communicator.py:200] Received from simulator_server server  (16873468 Bytes). getTask: train time: 0.10497117042541504 seconds\n",
      "I0601 18:18:27.413269 140049889785664 fed_client.py:91] pull_task completed. Task name:train Status:True \n",
      "I0601 18:18:27.413570 140049889785664 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=train, id=bcf80bb2-5531-4837-8b76-815817acb3ef\n",
      "I0601 18:18:27.414273 140049889785664 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bcf80bb2-5531-4837-8b76-815817acb3ef]: invoking task executor <class 'nemo_nvflare.learner_executor.NemoLearnerExecutor'>\n",
      "I0601 18:18:27.414522 140049889785664 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bcf80bb2-5531-4837-8b76-815817acb3ef]: Client trainer got task: train\n",
      "I0601 18:18:27.414793 140049889785664 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bcf80bb2-5531-4837-8b76-815817acb3ef]: Configuring the Learner...\n",
      "E0601 18:18:27.416299 140049889785664 fl_component.py:216] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bcf80bb2-5531-4837-8b76-815817acb3ef]: learner execute exception: No such file /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/data/FinancialPhraseBank-v1.0_split/site-0.jsonl!\n",
      "E0601 18:18:27.417986 140049889785664 fl_component.py:218] Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/nvflare/app_common/executors/learner_executor.py\", line 77, in execute\n",
      "    return self.train(shareable, fl_ctx, abort_signal)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/nvflare/app_common/executors/learner_executor.py\", line 94, in train\n",
      "    validate_result: Shareable = self.learner.validate(shareable, fl_ctx, abort_signal)\n",
      "  File \"/workspace/Code/nvflare/nemo_nvflare/integration/nemo/nemo_nvflare/prompt_learner.py\", line 342, in validate\n",
      "    self._configure(fl_ctx)\n",
      "  File \"/workspace/Code/nvflare/nemo_nvflare/integration/nemo/nemo_nvflare/prompt_learner.py\", line 231, in _configure\n",
      "    self.config.model.data.train_ds = set_datafile_paths(self.train_ds_files, self.app_root)\n",
      "  File \"/workspace/Code/nvflare/nemo_nvflare/integration/nemo/nemo_nvflare/prompt_learner.py\", line 51, in set_datafile_paths\n",
      "    raise ValueError(f\"No such file {f}!\")\n",
      "ValueError: No such file /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/data/FinancialPhraseBank-v1.0_split/site-0.jsonl!\n",
      "\n",
      "I0601 18:18:27.418618 140049889785664 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bcf80bb2-5531-4837-8b76-815817acb3ef]: finished processing task\n",
      "I0601 18:18:27.420081 140048516572928 fed_client_base.py:296] Starting to push execute result.\n",
      "I0601 18:18:27.431634 140048516572928 communicator.py:268]  SubmitUpdate size: 513 Bytes. time: 0.011312007904052734 seconds\n",
      "I0601 18:18:27.432680 140049889785664 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bcf80bb2-5531-4837-8b76-815817acb3ef]: result sent to server for task: name=train, id=bcf80bb2-5531-4837-8b76-815817acb3ef\n",
      "I0601 18:18:27.433043 140049889785664 simulator_worker.py:94] Finished one task run for client: site-1 interval: 2 task_processed: True\n",
      "I0601 18:18:27.448568 140412718274368 fed_client.py:91] pull_task completed. Task name:__end_run__ Status:True \n",
      "I0601 18:18:27.448935 140412718274368 fl_component.py:134] [identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: server asked to end the run\n",
      "I0601 18:18:27.449098 140412718274368 simulator_worker.py:102] End the Simulator run.\n",
      "I0601 18:18:27.449667 140412718274368 simulator_worker.py:125] Clean up ClientRunner for : site-3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 18:18:27,732 - ScatterAndGather - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: Abort signal received. Exiting at round 0.\n",
      "2023-06-01 18:18:27,734 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: Workflow: scatter_and_gather finalizing ...\n",
      "[NeMo I 2023-06-01 18:18:27 megatron_init:225] Rank 0 has data parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:18:27 megatron_init:228] All data parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:18:27 megatron_init:229] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2023-06-01 18:18:27 megatron_init:237] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:18:27 megatron_init:238] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:18:27 megatron_init:248] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:18:27 megatron_init:252] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:18:27 megatron_init:253] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2023-06-01 18:18:27 megatron_init:267] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:18:27 megatron_init:279] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2023-06-01 18:18:27 megatron_init:285] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:18:27 megatron_init:286] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2023-06-01 18:18:27 megatron_init:287] All embedding group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:18:27 megatron_init:288] Rank 0 has embedding rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23-06-01 18:18:27 - PID:6522 - rank:(0, 0, 0, 0) - microbatches.py:39 - INFO - setting number of micro-batches to constant 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 18:18:28,224 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: ABOUT_TO_END_RUN fired\n",
      "2023-06-01 18:18:28,226 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: END_RUN fired\n",
      "2023-06-01 18:18:28,228 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: Server runner finished.\n",
      "2023-06-01 18:18:29,437 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-1, peer_run=simulate_job]: server runner is finalizing - asked client to end the run\n",
      "2023-06-01 18:18:29,451 - GetTaskCommand - INFO - return task to client.  client_name: site-1  task_name: __end_run__   task_id:   sharable_header_task_id: \n",
      "2023-06-01 18:18:29,509 - SimulatorServer - INFO - Server app stopped.\n",
      "\n",
      "\n",
      "2023-06-01 18:18:29,456 - FederatedClient - INFO - pull_task completed. Task name:__end_run__ Status:True \n",
      "2023-06-01 18:18:29,456 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: server asked to end the run\n",
      "2023-06-01 18:18:29,457 - ClientTaskWorker - INFO - End the Simulator run.\n",
      "2023-06-01 18:18:29,457 - ClientTaskWorker - INFO - Clean up ClientRunner for : site-1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:18:29.456576 140049889785664 fed_client.py:91] pull_task completed. Task name:__end_run__ Status:True \n",
      "I0601 18:18:29.456952 140049889785664 fl_component.py:134] [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: server asked to end the run\n",
      "I0601 18:18:29.457109 140049889785664 simulator_worker.py:102] End the Simulator run.\n",
      "I0601 18:18:29.457633 140049889785664 simulator_worker.py:125] Clean up ClientRunner for : site-1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 18:18:29,717 - nvflare.fuel.hci.server.hci - INFO - Admin Server localhost on Port 59359 shutdown!\n",
      "2023-06-01 18:18:29,720 - SimulatorServer - INFO - shutting down server\n",
      "2023-06-01 18:18:29,722 - SimulatorServer - INFO - canceling sync locks\n",
      "2023-06-01 18:18:29,724 - SimulatorServer - INFO - server off\n",
      "[NeMo I 2023-06-01 18:18:41 megatron_init:225] Rank 0 has data parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:18:41 megatron_init:228] All data parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:18:41 megatron_init:229] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2023-06-01 18:18:41 megatron_init:237] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:18:41 megatron_init:238] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:18:41 megatron_init:248] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:18:41 megatron_init:252] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:18:41 megatron_init:253] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2023-06-01 18:18:41 megatron_init:267] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:18:41 megatron_init:279] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2023-06-01 18:18:41 megatron_init:285] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:18:41 megatron_init:286] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2023-06-01 18:18:41 megatron_init:287] All embedding group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:18:41 megatron_init:288] Rank 0 has embedding rank: 0\n",
      "[NeMo I 2023-06-01 18:18:41 tokenizer_utils:204] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: /tmp/tmpwvfl9s5q/bfcdca5e44814366bdb5dcd651325152_gpt2-vocab.json, and merges file: /tmp/tmpwvfl9s5q/315a11fd68be49d6abdb34363e8c4997_gpt2-merge.txt\n",
      "[NeMo I 2023-06-01 18:18:41 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /tmp/tmpwvfl9s5q/bfcdca5e44814366bdb5dcd651325152_gpt2-vocab.json, merges_files: /tmp/tmpwvfl9s5q/315a11fd68be49d6abdb34363e8c4997_gpt2-merge.txt, special_tokens_dict: {}, and use_fast: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-06-01 18:18:41 modelPT:245] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
      "Using sep_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using pad_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-01 18:18:41 megatron_base_model:205] Padded vocab_size: 50304, original vocab_size: 50257, dummy tokens: 47.\n",
      "[NeMo I 2023-06-01 18:18:43 nlp_overrides:374] Model MegatronGPTModel was successfully restored from /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/megatron_gpt_345m.nemo.\n",
      "[NeMo I 2023-06-01 18:18:43 auto_tokenizer:172] 10 special tokens added, resize your model accordingly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-01 18:18:59 megatron_init:225] Rank 0 has data parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:18:59 megatron_init:228] All data parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:18:59 megatron_init:229] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2023-06-01 18:18:59 megatron_init:237] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:18:59 megatron_init:238] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:18:59 megatron_init:248] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:18:59 megatron_init:252] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:18:59 megatron_init:253] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2023-06-01 18:18:59 megatron_init:267] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2023-06-01 18:18:59 megatron_init:279] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2023-06-01 18:18:59 megatron_init:285] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:18:59 megatron_init:286] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2023-06-01 18:18:59 megatron_init:287] All embedding group ranks: [[0]]\n",
      "[NeMo I 2023-06-01 18:18:59 megatron_init:288] Rank 0 has embedding rank: 0\n",
      "[NeMo I 2023-06-01 18:18:59 tokenizer_utils:204] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: /tmp/tmpvdhm05bf/bfcdca5e44814366bdb5dcd651325152_gpt2-vocab.json, and merges file: /tmp/tmpvdhm05bf/315a11fd68be49d6abdb34363e8c4997_gpt2-merge.txt\n",
      "[NeMo I 2023-06-01 18:18:59 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /tmp/tmpvdhm05bf/bfcdca5e44814366bdb5dcd651325152_gpt2-vocab.json, merges_files: /tmp/tmpvdhm05bf/315a11fd68be49d6abdb34363e8c4997_gpt2-merge.txt, special_tokens_dict: {}, and use_fast: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-06-01 18:18:59 modelPT:245] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
      "Using sep_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using pad_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-01 18:19:00 megatron_base_model:205] Padded vocab_size: 50304, original vocab_size: 50257, dummy tokens: 47.\n",
      "[NeMo I 2023-06-01 18:19:01 nlp_overrides:374] Model MegatronGPTModel was successfully restored from /workspace/Code/nvflare/nemo_nvflare/integration/nemo/examples/prompt_learning/megatron_gpt_345m.nemo.\n",
      "[NeMo I 2023-06-01 18:19:01 auto_tokenizer:172] 10 special tokens added, resize your model accordingly.\n",
      "2023-06-01 18:19:01,541 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Initialized model <class 'nemo_nvflare.fed_megatron_gpt_prompt_learning_model.FedMegatronGPTPromptLearningModel'> and prompt encoder <class 'nemo.collections.nlp.modules.common.prompt_encoder.PromptEncoder'>\n",
      "2023-06-01 18:19:01,550 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Loaded 7 of 7 weights\n",
      "2023-06-01 18:19:01,555 - lightning_fabric.utilities.distributed - INFO - Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "2023-06-01 18:19:01,557 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "2023-06-01 18:19:01,558 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
      "2023-06-01 18:19:01,558 - pytorch_lightning.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "2023-06-01 18:19:01,560 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "2023-06-01 18:19:01,560 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
      "2023-06-01 18:19:01,561 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:3 to store for rank: 0\n",
      "2023-06-01 18:19:01,561 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:3 with 1 nodes.\n",
      "2023-06-01 18:19:01,562 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:4 to store for rank: 0\n",
      "2023-06-01 18:19:01,563 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:4 with 1 nodes.\n",
      "2023-06-01 18:19:01,564 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:5 to store for rank: 0\n",
      "2023-06-01 18:19:01,564 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:5 with 1 nodes.\n",
      "2023-06-01 18:19:01,565 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:6 to store for rank: 0\n",
      "2023-06-01 18:19:01,565 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:6 with 1 nodes.\n",
      "2023-06-01 18:19:01,566 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:7 to store for rank: 0\n",
      "2023-06-01 18:19:01,566 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:7 with 1 nodes.\n",
      "2023-06-01 18:19:01,567 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:8 to store for rank: 0\n",
      "2023-06-01 18:19:01,567 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:8 with 1 nodes.\n",
      "2023-06-01 18:19:01,568 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:9 to store for rank: 0\n",
      "2023-06-01 18:19:01,569 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:9 with 1 nodes.\n",
      "2023-06-01 18:19:01,569 - pytorch_lightning.loggers.tensorboard - WARNING - Missing logger folder: /tmp/nvflare/nemo/gpt_p-tuning_fedavg_345M/simulate_job/app_site-2/lightning_logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n",
      "I0601 18:19:01.541778 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Initialized model <class 'nemo_nvflare.fed_megatron_gpt_prompt_learning_model.FedMegatronGPTPromptLearningModel'> and prompt encoder <class 'nemo.collections.nlp.modules.common.prompt_encoder.PromptEncoder'>\n",
      "I0601 18:19:01.550390 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Loaded 7 of 7 weights\n",
      "I0601 18:19:01.555524 139825093494592 distributed.py:244] Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "I0601 18:19:01.557950 139825093494592 distributed_c10d.py:393] Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "I0601 18:19:01.558239 139825093494592 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
      "I0601 18:19:01.558503 139825093494592 distributed.py:248] ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "I0601 18:19:01.560409 139825093494592 distributed_c10d.py:393] Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "I0601 18:19:01.560669 139825093494592 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
      "I0601 18:19:01.561687 139825093494592 distributed_c10d.py:393] Added key: store_based_barrier_key:3 to store for rank: 0\n",
      "I0601 18:19:01.561928 139825093494592 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:3 with 1 nodes.\n",
      "I0601 18:19:01.562937 139825093494592 distributed_c10d.py:393] Added key: store_based_barrier_key:4 to store for rank: 0\n",
      "I0601 18:19:01.563179 139825093494592 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:4 with 1 nodes.\n",
      "I0601 18:19:01.564162 139825093494592 distributed_c10d.py:393] Added key: store_based_barrier_key:5 to store for rank: 0\n",
      "I0601 18:19:01.564419 139825093494592 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:5 with 1 nodes.\n",
      "I0601 18:19:01.565437 139825093494592 distributed_c10d.py:393] Added key: store_based_barrier_key:6 to store for rank: 0\n",
      "I0601 18:19:01.565675 139825093494592 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:6 with 1 nodes.\n",
      "I0601 18:19:01.566532 139825093494592 distributed_c10d.py:393] Added key: store_based_barrier_key:7 to store for rank: 0\n",
      "I0601 18:19:01.566777 139825093494592 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:7 with 1 nodes.\n",
      "I0601 18:19:01.567726 139825093494592 distributed_c10d.py:393] Added key: store_based_barrier_key:8 to store for rank: 0\n",
      "I0601 18:19:01.567999 139825093494592 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:8 with 1 nodes.\n",
      "I0601 18:19:01.568925 139825093494592 distributed_c10d.py:393] Added key: store_based_barrier_key:9 to store for rank: 0\n",
      "I0601 18:19:01.569167 139825093494592 distributed_c10d.py:427] Rank 0: Completed store-based barrier for key:store_based_barrier_key:9 with 1 nodes.\n",
      "W0601 18:19:01.569768 139825093494592 tensorboard.py:237] Missing logger folder: /tmp/nvflare/nemo/gpt_p-tuning_fedavg_345M/simulate_job/app_site-2/lightning_logs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-01 18:19:02 gpt_prompt_learning_dataset:85] Loading and tokenizing dataset ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "604it [00:00, 795.19it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-01 18:19:03 gpt_prompt_learning_dataset:196] Skipped 0 sentences, sequence length too short or too long even after truncation\n",
      "[NeMo I 2023-06-01 18:19:03 gpt_prompt_learning_dataset:85] Loading and tokenizing dataset ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "226it [00:00, 854.17it/s]\n",
      "I0601 18:19:03.825299 139825093494592 cuda.py:58] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-01 18:19:03 gpt_prompt_learning_dataset:196] Skipped 0 sentences, sequence length too short or too long even after truncation\n",
      "2023-06-01 18:19:03,825 - pytorch_lightning.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Validation: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-06-01 18:19:03 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel/utils.py:81: UserWarning: This function is only for unittest\n",
      "      warnings.warn(\"This function is only for unittest\")\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 4/4 [00:06<00:00,  1.51s/it]2023-06-01 18:19:10,699 - root - INFO - global_model_val_loss: 6.832405090332031\n",
      "Validation DataLoader 0: 100%|██████████| 4/4 [00:06<00:00,  1.51s/it]\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│\u001b[36m \u001b[0m\u001b[36m  global_model_val_loss  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    6.832405090332031    \u001b[0m\u001b[35m \u001b[0m│\n",
      "└───────────────────────────┴───────────────────────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:19:10.699887 139825093494592 fed_megatron_gpt_prompt_learning_model.py:99] global_model_val_loss: 6.832405090332031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 18:19:11,275 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Global_model global_model_val_loss: 6.832405090332031\n",
      "2023-06-01 18:19:11,275 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Current/Total Round: 1/50\n",
      "2023-06-01 18:19:11,276 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Client identity: site-2\n",
      "2023-06-01 18:19:11,283 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Loaded 7 of 7 weights\n",
      "2023-06-01 18:19:11,283 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Start training in round 0\n",
      "2023-06-01 18:19:11,289 - pytorch_lightning.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[NeMo I 2023-06-01 18:19:11 nlp_overrides:105] Configuring DDP for model parallelism.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:19:11.275437 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Global_model global_model_val_loss: 6.832405090332031\n",
      "I0601 18:19:11.275945 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Current/Total Round: 1/50\n",
      "I0601 18:19:11.276138 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Client identity: site-2\n",
      "I0601 18:19:11.283552 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Loaded 7 of 7 weights\n",
      "I0601 18:19:11.283828 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Start training in round 0\n",
      "I0601 18:19:11.289490 139825093494592 cuda.py:58] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-01 18:19:11 modelPT:722] Optimizer config = FusedAdam (\n",
      "    Parameter Group 0\n",
      "        betas: [0.9, 0.98]\n",
      "        bias_correction: True\n",
      "        eps: 1e-08\n",
      "        lr: 0.0001\n",
      "        weight_decay: 0.01\n",
      "    )\n",
      "[NeMo I 2023-06-01 18:19:11 lr_scheduler:910] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7f2b294cb850>\" \n",
      "    will be used during training (effective maximum steps = 11000) - \n",
      "    Parameters : \n",
      "    (warmup_steps: 50\n",
      "    min_lr: 0.0\n",
      "    constant_steps: 0\n",
      "    max_steps: 11000\n",
      "    )\n",
      "2023-06-01 18:19:11,515 - pytorch_lightning.callbacks.model_summary - INFO - \n",
      "  | Name            | Type                   | Params\n",
      "-----------------------------------------------------------\n",
      "0 | frozen_model    | MegatronGPTModel       | 354 M \n",
      "1 | word_embeddings | VocabParallelEmbedding | 51.5 M\n",
      "2 | prompt_encoder  | PromptEncoder          | 4.2 M \n",
      "-----------------------------------------------------------\n",
      "4.2 M     Trainable params\n",
      "354 M     Non-trainable params\n",
      "359 M     Total params\n",
      "718.178   Total estimated model params size (MB)\n",
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:19:11.515919 139825093494592 model_summary.py:83] \n",
      "  | Name            | Type                   | Params\n",
      "-----------------------------------------------------------\n",
      "0 | frozen_model    | MegatronGPTModel       | 354 M \n",
      "1 | word_embeddings | VocabParallelEmbedding | 51.5 M\n",
      "2 | prompt_encoder  | PromptEncoder          | 4.2 M \n",
      "-----------------------------------------------------------\n",
      "4.2 M     Trainable params\n",
      "354 M     Non-trainable params\n",
      "359 M     Total params\n",
      "718.178   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:01<00:00,  1.03it/s]2023-06-01 18:19:13,828 - root - INFO - val_loss: 6.231474876403809\n",
      "Epoch 0:   0%|          | 0/13 [00:00<?, ?it/s]                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:19:13.828571 139825093494592 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 6.231474876403809\n",
      "[NeMo W 2023-06-01 18:19:13 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (9) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "      rank_zero_warn(\n",
      "    \n",
      "[NeMo W 2023-06-01 18:19:19 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:232: UserWarning: You called `self.log('global_step', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "      warning_cache.warn(\n",
      "    \n",
      "[NeMo W 2023-06-01 18:19:19 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "      warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  69%|██████▉   | 9/13 [00:19<00:08,  2.22s/it, loss=6.76, v_num=0, reduced_train_loss=5.550, global_step=8.000]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  77%|███████▋  | 10/13 [00:20<00:06,  2.10s/it, loss=6.76, v_num=0, reduced_train_loss=5.550, global_step=8.000]\n",
      "Epoch 0:  85%|████████▍ | 11/13 [00:21<00:03,  1.99s/it, loss=6.76, v_num=0, reduced_train_loss=5.550, global_step=8.000]\n",
      "Epoch 0:  92%|█████████▏| 12/13 [00:22<00:01,  1.90s/it, loss=6.76, v_num=0, reduced_train_loss=5.550, global_step=8.000]\n",
      "Epoch 0: 100%|██████████| 13/13 [00:22<00:00,  1.76s/it, loss=6.76, v_num=0, reduced_train_loss=5.550, global_step=8.000]2023-06-01 18:19:36,757 - root - INFO - val_loss: 5.130880355834961\n",
      "Epoch 0: 100%|██████████| 13/13 [00:22<00:00,  1.76s/it, loss=6.76, v_num=0, reduced_train_loss=5.550, global_step=8.000, val_loss=5.130]\n",
      "Epoch 0: 100%|██████████| 13/13 [00:22<00:00,  1.76s/it, loss=6.76, v_num=0, reduced_train_loss=5.550, global_step=8.000, val_loss=5.130]2023-06-01 18:19:36,766 - pytorch_lightning.utilities.rank_zero - INFO - `Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Epoch 0: 100%|██████████| 13/13 [00:22<00:00,  1.76s/it, loss=6.76, v_num=0, reduced_train_loss=5.550, global_step=8.000, val_loss=5.130]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:19:36.757718 139825093494592 fed_megatron_gpt_prompt_learning_model.py:99] val_loss: 5.130880355834961\n",
      "I0601 18:19:36.766366 139825093494592 fit_loop.py:175] `Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 18:19:37,731 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-2, peer_run=simulate_job]: got result from client site-2 for task: name=train, id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff\n",
      "2023-06-01 18:19:37,734 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-2, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: ignored result submission since server runner's status is done\n",
      "2023-06-01 18:19:37,736 - SubmitUpdateCommand - INFO - submit_update process. client_name:site-2   task_id:bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff\n",
      "\n",
      "2023-06-01 18:19:37,643 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Computed 7 weight differences for global model of length 7\n",
      "2023-06-01 18:19:37,644 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Local steps per epoch: 9\n",
      "2023-06-01 18:19:37,644 - PromptLearner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Local epochs finished. Returning shareable\n",
      "2023-06-01 18:19:37,645 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: finished processing task\n",
      "2023-06-01 18:19:37,648 - FederatedClient - INFO - Starting to push execute result.\n",
      "2023-06-01 18:19:37,739 - Communicator - INFO -  SubmitUpdate size: 16873459 Bytes. time: 0.09066081047058105 seconds\n",
      "2023-06-01 18:19:37,742 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: result sent to server for task: name=train, id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff\n",
      "2023-06-01 18:19:37,742 - ClientTaskWorker - INFO - Finished one task run for client: site-2 interval: 2 task_processed: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:19:37.643822 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Computed 7 weight differences for global model of length 7\n",
      "I0601 18:19:37.644314 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Local steps per epoch: 9\n",
      "I0601 18:19:37.644602 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: Local epochs finished. Returning shareable\n",
      "I0601 18:19:37.645701 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: finished processing task\n",
      "I0601 18:19:37.648889 139814988396288 fed_client_base.py:296] Starting to push execute result.\n",
      "I0601 18:19:37.739841 139814988396288 communicator.py:268]  SubmitUpdate size: 16873459 Bytes. time: 0.09066081047058105 seconds\n",
      "I0601 18:19:37.742166 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff]: result sent to server for task: name=train, id=bf2d9558-29de-4f0e-ade0-e5f9e2a1d9ff\n",
      "I0601 18:19:37.742659 139825093494592 simulator_worker.py:94] Finished one task run for client: site-2 interval: 2 task_processed: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 18:19:39,748 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-2, peer_run=simulate_job]: server runner is finalizing - asked client to end the run\n",
      "2023-06-01 18:19:39,760 - GetTaskCommand - INFO - return task to client.  client_name: site-2  task_name: __end_run__   task_id:   sharable_header_task_id: \n",
      "2023-06-01 18:19:39,767 - FederatedClient - INFO - Shutting down client run: site-1\n",
      "2023-06-01 18:19:39,769 - FederatedClient - INFO - Shutting down client run: site-2\n",
      "2023-06-01 18:19:39,772 - FederatedClient - INFO - Shutting down client run: site-3\n",
      "2023-06-01 18:19:39,772 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: asked to abort - triggered abort_signal to stop the RUN\n",
      "2023-06-01 18:19:39,766 - FederatedClient - INFO - pull_task completed. Task name:__end_run__ Status:True \n",
      "2023-06-01 18:19:39,766 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: server asked to end the run\n",
      "2023-06-01 18:19:39,766 - ClientTaskWorker - INFO - End the Simulator run.\n",
      "2023-06-01 18:19:39,767 - ClientTaskWorker - INFO - Clean up ClientRunner for : site-2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 18:19:39.766087 139825093494592 fed_client.py:91] pull_task completed. Task name:__end_run__ Status:True \n",
      "I0601 18:19:39.766475 139825093494592 fl_component.py:134] [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: server asked to end the run\n",
      "I0601 18:19:39.766636 139825093494592 simulator_worker.py:102] End the Simulator run.\n",
      "I0601 18:19:39.767145 139825093494592 simulator_worker.py:125] Clean up ClientRunner for : site-2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 18:19:43,291 - MPM - INFO - MPM: Good Bye!\n",
      "Simulator finished with run_status 0\n"
     ]
    }
   ],
   "source": [
    "from nvflare import SimulatorRunner    \n",
    "\n",
    "simulator = SimulatorRunner(\n",
    "    job_folder=\"jobs/gpt_p-tuning_fedavg_345M\",\n",
    "    workspace=\"/tmp/nvflare/nemo/gpt_p-tuning_fedavg_345M\",\n",
    "    n_clients=3,\n",
    "    threads=3\n",
    ")\n",
    "run_status = simulator.run()\n",
    "print(\"Simulator finished with run_status\", run_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb4f89e",
   "metadata": {},
   "source": [
    "You can visualize the training process using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7cfe45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "TensorBoard 2.9.0 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir /tmp/nvflare/nemo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee70ce0",
   "metadata": {},
   "source": [
    "## Results\n",
    "In this scenario, all clients utilize the same validation set, allowing for a direct comparison between the locally p-tuned and federated global models. As anticipated, the FedAvg-trained global model exhibits lower validation loss than the models trained solely on their local datasets. This is because the global model has access to all client datasets and can, consequently, generalize better.\n",
    "\n",
    "![validation loss](./figs/val_loss.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587319df",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "We can use `model.generate()` to run inference after p-tuning the model. \n",
    "Let's define some test examples to feed to the p-tuned model to see its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4b052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = [\n",
    "    {\"taskname\": \"sentiment\", \"sentence\": \"The products have a low salt and fat content .\"},\n",
    "    {\"taskname\": \"sentiment\", \"sentence\": \"The agreement is valid for four years .\"},\n",
    "    {\"taskname\": \"sentiment\", \"sentence\": \"Diluted EPS rose to EUR3 .68 from EUR0 .50 .\"},\n",
    "    {\"taskname\": \"sentiment\", \"sentence\": \"The company is well positioned in Brazil and Uruguay .\"},\n",
    "    {\"taskname\": \"sentiment\", \"sentence\": \"Profit before taxes decreased by 9 % to EUR 187.8 mn in the first nine months of 2008 , compared to EUR 207.1 mn a year earlier .\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6a900a",
   "metadata": {},
   "source": [
    "Next, we will load the global model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec75f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from nemo_nvflare.fed_megatron_gpt_prompt_learning_model import FedMegatronGPTPromptLearningModel\n",
    "from nemo_nvflare.utils import load_weights\n",
    "from omegaconf import OmegaConf\n",
    "from nemo.collections.nlp.parts.nlp_overrides import NLPDDPStrategy\n",
    "from pytorch_lightning.plugins.environments import TorchElasticEnvironment\n",
    "\n",
    "# Load model configuration used by one of the clients\n",
    "config = OmegaConf.load(\"jobs/gpt_p-tuning_fedavg_345M/server/config/megatron_gpt_prompt_learning_config.yaml\")\n",
    "\n",
    "# Set GPT model path\n",
    "config.model.language_model_path = \"megatron_gpt_345m.nemo\"\n",
    "\n",
    "# Load task templates\n",
    "config.model.task_templates = OmegaConf.load(\"jobs/gpt_p-tuning_fedavg_345M/server/config/task_templates.json\")\n",
    "\n",
    "# Set task that were learned\n",
    "config.model.new_tasks = [\"sentiment\"]\n",
    "\n",
    "# Setup cluster environment parameters\n",
    "# use torch elastic cluster environment so `create_process_externally` is True\n",
    "# the launcher is set to None. It will not try to spawn new processes.\n",
    "# It won't create the misconfiguration error because of the `interactive session`\n",
    "os.environ[\"LOCAL_RANK\"] = '0'\n",
    "os.environ[\"RANK\"] = '0'\n",
    "os.environ[\"WORLD_SIZE\"] = '1'\n",
    "strategy = NLPDDPStrategy(find_unused_parameters=False, no_ddp_communication_hook=True)\n",
    "plugins = [TorchElasticEnvironment()]\n",
    "\n",
    "# Set up the trainer and load the model that was used for p-tuning\n",
    "trainer = pl.Trainer(plugins=plugins, strategy=strategy, **config.trainer)\n",
    "model = FedMegatronGPTPromptLearningModel(cfg=config.model, trainer=trainer)\n",
    "model.init_prompt_encoder()\n",
    "\n",
    "print(\"Model initialized\", type(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab3df98",
   "metadata": {},
   "source": [
    "Overwrite the prompt encoder with the best global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b042db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"/tmp/nvflare/nemo/gpt_p-tuning_fedavg_345M/simulate_job/app_server/best_FL_global_model.pt\")\n",
    "global_weights = ckpt[\"model\"]\n",
    "\n",
    "n_loaded = load_weights(model, global_weights, device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))\n",
    "print(f\"Loaded {n_loaded} of {len(global_weights)} weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61e2790",
   "metadata": {},
   "source": [
    "Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453d5719",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate(inputs=test_examples, length_params=None)\n",
    "\n",
    "print('The prediction results of some sample queries with the trained model:')\n",
    "for result in response['sentences']:\n",
    "    print(result)\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cc9c5a",
   "metadata": {},
   "source": [
    "The expected output predictions look something like this\n",
    "\n",
    ">      The products have a low salt and fat content . sentiment: neutral\n",
    ">      ------------------------------\n",
    ">      The agreement is valid for four years . sentiment: neutral\n",
    ">      ------------------------------\n",
    ">      Diluted EPS rose to EUR3 .68 from EUR0 .50 . sentiment: positive\n",
    ">      ------------------------------\n",
    ">      The company is well positioned in Brazil and Uruguay . sentiment: positive\n",
    ">      ------------------------------\n",
    ">      Profit before taxes decreased by 9 % to EUR 187.8 mn in the first nine months of 2008 , compared to EUR 207.1 mn a year earlier . sentiment: negative\n",
    ">      ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bf0c50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
