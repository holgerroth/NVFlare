{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38de0acf",
   "metadata": {},
   "source": [
    "# Prompt Learning with NeMo\n",
    "\n",
    "In this example, we utilize NeMo's [prompt learning](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/nlp/nemo_megatron/prompt_learning.html)\n",
    "feature to showcase how to adapt a large language model (LLM) to \n",
    "a downstream task, such as financial sentiment predictions. \n",
    "\n",
    "The prompt learning technique shown in the example is [p-tuning](https://arxiv.org/abs/2103.10385), which adds a small prompt encoder network to the LLM\n",
    "to produce virtual token embeddings that guide the model toward the desired output of the downstream task.\n",
    "\n",
    "For more details on how to change hyperparameters for prompt learning in NeMo, see this [tutorial](https://github.com/NVIDIA/NeMo/blob/main/tutorials/nlp/Multitask_Prompt_and_PTuning.ipynb) which is also the basis for this NVFlare tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f228a495",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "We assume you followed the instructions [here](../../README.md#requirements) \n",
    "to install the NeMo framework and the NeMo-NVFlare package. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae77c4d2",
   "metadata": {},
   "source": [
    "## Download the pre-trained LLM\n",
    "In this example, we use a `MegatronGPTModel`, a transformer-based language model based on the GPT architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a040ea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what GPT .nemo models we have available on NGC\n",
    "from nemo.collections.nlp.models.language_modeling.megatron_gpt_model import MegatronGPTModel\n",
    "MegatronGPTModel.list_available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d230e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the model from NGC\n",
    "import os\n",
    "model_file = \"megatron_gpt_345m.nemo\"\n",
    "if not os.path.isfile(model_file):\n",
    "    !wget \"https://api.ngc.nvidia.com/v2/models/nvidia/nemo/megatron_gpt_345m/versions/1/files/$model_file\"\n",
    "else:\n",
    "    print(f\"{model_file} already downloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263d66f7",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "As our downstream task, we will use the [Financial PhraseBank dataset](https://huggingface.co/datasets/financial_phrasebank) for sentiment analysis.\n",
    "\n",
    "The Financial PhraseBank dataset contains the sentiments for financial news headlines from a retail investor's perspective. Further details about the dataset can be found in Malo et al.'s [\"Good Debt or Bad Debt: Detecting Semantic Orientations in Economic Texts\"](https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/asi.23062).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb1b2f1",
   "metadata": {},
   "source": [
    "#### 1. Download the preprocessing scripts\n",
    "We use the preprocessing scripts provided by NeMo which can be downloaded from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee024bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_name = \"prompt_learning_financial_phrase_bank_preprocessing.py\"\n",
    "if not os.path.isfile(script_name):\n",
    "    !wget -N \"https://raw.githubusercontent.com/NVIDIA/NeMo/main/scripts/dataset_processing/nlp/financial_phrase_bank/$script_name\"\n",
    "else:\n",
    "    print(f\"{script_name} already downloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbff6b45",
   "metadata": {},
   "source": [
    "#### 2. Download the Financial PhraseBank Dataset\n",
    "\n",
    "Download the `FinancialPhraseBank-v1.0.zip` dataset from [here](https://www.researchgate.net/profile/Pekka_Malo/publication/251231364_FinancialPhraseBank-v1.0/data/0c96051eee4fb1d56e000000/FinancialPhraseBank-v1.0.zip).\n",
    "\n",
    "Then extract it under `./data`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860f8970",
   "metadata": {},
   "source": [
    "#### 3. Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fac0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 prompt_learning_financial_phrase_bank_preprocessing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cd3a07",
   "metadata": {},
   "source": [
    "#### 4. Split the dataset to simulate clients\n",
    "Next, we use three clients to simulate federated learning for p-tuning with NeMo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae8d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 data/split_financial_phrase_data.py --data_path data/FinancialPhraseBank-v1.0/financial_phrase_bank_train.jsonl --num_clients 3 --out_dir data/FinancialPhraseBank-v1.0_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04052a7",
   "metadata": {},
   "source": [
    "## Federated learning simulations\n",
    "Next, we are using NVFlare's [simulator](https://nvflare.readthedocs.io/en/latest/user_guide/fl_simulator.html) to simulate each client training on their own dataset locally and all three clients training together using the [FedAvg](https://arxiv.org/abs/1602.05629) algorithm implemented in NVFlare.\n",
    "\n",
    "With this setting, we require a GPU with at least 16GB memory to run all clients in parallel on the same GPU. \n",
    "If you have multiple GPUs in your system, you can use the `gpu` argument to assign one GPU for each client, e.g., `gpu=\"0,1\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af89f8d",
   "metadata": {},
   "source": [
    "#### 1. Local P-Tuning\n",
    "First, we modify the configuration files to include the current directory path to access the dataset and pre-trained LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f59b4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 modify_configs.py --job_folder \"jobs/gpt_p-tuning_local\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33028b99",
   "metadata": {},
   "source": [
    "Next, simulate each client p-tuning on their local dataset using the FL simulator. To do this, we only run 1 round of FL, with each client running 50 p-tuning epochs on their local dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54567a7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nvflare import SimulatorRunner    \n",
    "\n",
    "simulator = SimulatorRunner(\n",
    "    job_folder=\"jobs/gpt_p-tuning_local\",\n",
    "    workspace=\"/tmp/nvflare/nemo/gpt_p-tuning_local\",\n",
    "    n_clients=3,\n",
    "    threads=3\n",
    ")\n",
    "run_status = simulator.run()\n",
    "print(\"Simulator finished with run_status\", run_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3746b8",
   "metadata": {},
   "source": [
    "#### 2. Federated P-Tuning\n",
    "We use the [FedAvg](https://arxiv.org/abs/1602.05629) algorithm to p-tune the model in a federated scenario. First, modify the configuration files again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d076d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 modify_configs.py --job_folder \"jobs/gpt_p-tuning_fedavg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d73967",
   "metadata": {},
   "source": [
    "Next, simulate the federated p-tuning using FedAvg. Here, each client p-tunes for one local epoch before sending their local model updates to the server for aggregation. This is repeated for 50 FL rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e26e61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nvflare import SimulatorRunner    \n",
    "\n",
    "simulator = SimulatorRunner(\n",
    "    job_folder=\"jobs/gpt_p-tuning_fedavg\",\n",
    "    workspace=\"/tmp/nvflare/nemo/gpt_p-tuning_fedavg\",\n",
    "    n_clients=3,\n",
    "    threads=3\n",
    ")\n",
    "run_status = simulator.run()\n",
    "print(\"Simulator finished with run_status\", run_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d69cbe",
   "metadata": {},
   "source": [
    "You can visualize the training process using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e40c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir /tmp/nvflare/nemo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3659a0b",
   "metadata": {},
   "source": [
    "## Results\n",
    "In this scenario, all clients utilize the same validation set, allowing for a direct comparison between the locally p-tuned and federated global models. As anticipated, the FedAvg-trained global model exhibits lower validation loss than the models trained solely on their local datasets. This is because the global model has access to all client datasets and can, consequently, generalize better.\n",
    "\n",
    "![validation loss](./val_loss.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02d2bc2",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "We can use `model.generate()` to run inference after p-tuning the model. \n",
    "Let's define some test examples to feed to the p-tuned model to see its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa00d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = [\n",
    "    {\"taskname\": \"sentiment\", \"sentence\": \"The products have a low salt and fat content .\"},\n",
    "    {\"taskname\": \"sentiment\", \"sentence\": \"The agreement is valid for four years .\"},\n",
    "    {\"taskname\": \"sentiment\", \"sentence\": \"Diluted EPS rose to EUR3 .68 from EUR0 .50 .\"},\n",
    "    {\"taskname\": \"sentiment\", \"sentence\": \"The company is well positioned in Brazil and Uruguay .\"},\n",
    "    {\"taskname\": \"sentiment\", \"sentence\": \"Profit before taxes decreased by 9 % to EUR 187.8 mn in the first nine months of 2008 , compared to EUR 207.1 mn a year earlier .\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea6c350",
   "metadata": {},
   "source": [
    "Next, we will load the global model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd33626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from nemo_nvflare.fed_megatron_gpt_prompt_learning_model import FedMegatronGPTPromptLearningModel\n",
    "from nemo_nvflare.utils import load_weights\n",
    "from omegaconf import OmegaConf\n",
    "from nemo.collections.nlp.parts.nlp_overrides import NLPDDPStrategy\n",
    "from pytorch_lightning.plugins.environments import TorchElasticEnvironment\n",
    "\n",
    "# Load model configuration used by one of the clients\n",
    "config = OmegaConf.load(\"jobs/gpt_p-tuning_fedavg/app1/config/megatron_gpt_prompt_learning_config.yaml\")\n",
    "\n",
    "# Set GPT model path\n",
    "config.model.language_model_path = \"/workspace/Code/NeMo/upstream/tutorials/nlp/megatron_gpt_345m.nemo\"\n",
    "\n",
    "# Load task templates\n",
    "config.model.task_templates = OmegaConf.load(\"jobs/gpt_p-tuning_fedavg/app1/config/task_templates.json\")\n",
    "\n",
    "# Set task that were learned\n",
    "config.model.new_tasks = [\"sentiment\"]\n",
    "\n",
    "# Setup cluster environment parameters\n",
    "# use torch elastic cluster environment so `create_process_externally` is True\n",
    "# the launcher is set to None. It will not try to spawn new processes.\n",
    "# It won't create the misconfiguration error because of the `interactive session`\n",
    "os.environ[\"LOCAL_RANK\"] = '0'\n",
    "os.environ[\"RANK\"] = '0'\n",
    "os.environ[\"WORLD_SIZE\"] = '1'\n",
    "strategy = NLPDDPStrategy(find_unused_parameters=False, no_ddp_communication_hook=True)\n",
    "plugins = [TorchElasticEnvironment()]\n",
    "\n",
    "# Set up the trainer and load the model that was used for p-tuning\n",
    "trainer = pl.Trainer(plugins=plugins, strategy=strategy, **config.trainer)\n",
    "model = FedMegatronGPTPromptLearningModel(cfg=config.model, trainer=trainer)\n",
    "model.init_prompt_encoder()\n",
    "\n",
    "print(\"Model initialized\", type(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d0d258",
   "metadata": {},
   "source": [
    "Overwrite the prompt encoder with the best global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32332ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"/tmp/nvflare/nemo/gpt_p-tuning_fedavg/simulate_job/app_server/best_FL_global_model.pt\")\n",
    "global_weights = ckpt[\"model\"]\n",
    "\n",
    "n_loaded = load_weights(model, global_weights, device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))\n",
    "print(f\"Loaded {n_loaded} of {len(global_weights)} weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7f9522",
   "metadata": {},
   "source": [
    "Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb776230",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate(inputs=test_examples, length_params=None)\n",
    "\n",
    "print('The prediction results of some sample queries with the trained model:')\n",
    "for result in response['sentences']:\n",
    "    print(result)\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e856bd91",
   "metadata": {},
   "source": [
    "The expected output predictions look something like this\n",
    "\n",
    ">      The products have a low salt and fat content . sentiment: neutral\n",
    ">      ------------------------------\n",
    ">      The agreement is valid for four years . sentiment: neutral\n",
    ">      ------------------------------\n",
    ">      Diluted EPS rose to EUR3 .68 from EUR0 .50 . sentiment: positive\n",
    ">      ------------------------------\n",
    ">      The company is well positioned in Brazil and Uruguay . sentiment: positive\n",
    ">      ------------------------------\n",
    ">      Profit before taxes decreased by 9 % to EUR 187.8 mn in the first nine months of 2008 , compared to EUR 207.1 mn a year earlier . sentiment: negative\n",
    ">      ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089b5c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
