{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Protein Downstream Fine-tuning\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b> This notebook was tested on a single A1000 GPU and is compatible with BioNeMo Framework v2.3. To leverage additional or higher-performance GPUs, you can modify the configuration files and simulation script to accommodate multiple devices and increase thread utilization respectively.</div>\n",
    "\n",
    "The example datasets used here are made available by [Therapeutics Data Commons](https://tdcommons.ai/) through PyTDC.\n",
    "\n",
    "This example shows three different downstream tasks for fine-tuning a BioNeMo ESM-style model on different datasets.\n",
    "We separate the scripts and job configurations into three folders based on the dataset names:\n",
    "\n",
    "\n",
    "1. `tap`: therapeutic antibody profiling\"\n",
    "2. `sabdab`: SAbDab: the structural antibody database\"\n",
    "3. `scl`: \"subcellular location prediction\"\n",
    "\n",
    "## Setup\n",
    "\n",
    "Ensure that you have read through the Getting Started section, can run the BioNeMo Framework docker container, and have configured the NGC Command Line Interface (CLI) within the container. It is assumed that this notebook is being executed from within the container.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b> Some of the cells below generate long text output.  We're using <pre>%%capture --no-display --no-stderr cell_output</pre> to suppress this output.  Comment or delete this line in the cells below to restore full output.</div>\n",
    "\n",
    "### Import and install all required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/opt_einsum-3.4.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/dill-0.3.9-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.12.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.23a0+6627725-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting fuzzywuzzy\n",
      "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting PyTDC\n",
      "  Downloading pytdc-1.1.14.tar.gz (151 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?2done\n",
      "\u001b[?25hDownloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Building wheels for collected packages: PyTDC\n",
      "  Building wheel for PyTDC (setup.py) ... \u001b[done\n",
      "\u001b[?25h  Created wheel for PyTDC: filename=pytdc-1.1.14-py3-none-any.whl size=189444 sha256=17513135f331aa01ab7e3f1919389f44ced97d7ae758f61fb1e232caa2795345\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-q308avwg/wheels/3e/34/ba/e5a6104fb7c17d69daeed0e73d413f296b2971ca6255a77650\n",
      "Successfully built PyTDC\n",
      "Installing collected packages: PyTDC, fuzzywuzzy\n",
      "Successfully installed PyTDC-1.1.14 fuzzywuzzy-0.18.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/opt_einsum-3.4.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/dill-0.3.9-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.12.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.23a0+6627725-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting nvflare~=2.5\n",
      "  Downloading nvflare-2.5.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from nvflare~=2.5) (42.0.8)\n",
      "Collecting Flask==3.0.2 (from nvflare~=2.5)\n",
      "  Downloading flask-3.0.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting Werkzeug==3.0.3 (from nvflare~=2.5)\n",
      "  Downloading werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting Flask-JWT-Extended==4.6.0 (from nvflare~=2.5)\n",
      "  Downloading Flask_JWT_Extended-4.6.0-py2.py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting Flask-SQLAlchemy==3.1.1 (from nvflare~=2.5)\n",
      "  Downloading flask_sqlalchemy-3.1.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting SQLAlchemy==2.0.16 (from nvflare~=2.5)\n",
      "  Downloading SQLAlchemy-2.0.16-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: grpcio>=1.62.1 in /usr/local/lib/python3.12/dist-packages (from nvflare~=2.5) (1.62.1)\n",
      "Collecting gunicorn>=22.0.0 (from nvflare~=2.5)\n",
      "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.12/dist-packages (from nvflare~=2.5) (1.26.4)\n",
      "Collecting protobuf>=4.24.4 (from nvflare~=2.5)\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: psutil>=5.9.1 in /usr/local/lib/python3.12/dist-packages (from nvflare~=2.5) (5.9.8)\n",
      "Requirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.12/dist-packages (from nvflare~=2.5) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.28.0 in /usr/local/lib/python3.12/dist-packages (from nvflare~=2.5) (2.32.3)\n",
      "Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.12/dist-packages (from nvflare~=2.5) (1.17.0)\n",
      "Requirement already satisfied: msgpack>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from nvflare~=2.5) (1.1.0)\n",
      "Requirement already satisfied: docker>=6.0 in /usr/local/lib/python3.12/dist-packages (from nvflare~=2.5) (7.1.0)\n",
      "Collecting websockets>=10.4 (from nvflare~=2.5)\n",
      "  Downloading websockets-14.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting pyhocon (from nvflare~=2.5)\n",
      "  Downloading pyhocon-0.3.61-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask==3.0.2->nvflare~=2.5) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask==3.0.2->nvflare~=2.5) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from Flask==3.0.2->nvflare~=2.5) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.12/dist-packages (from Flask==3.0.2->nvflare~=2.5) (1.9.0)\n",
      "Collecting PyJWT<3.0,>=2.0 (from Flask-JWT-Extended==4.6.0->nvflare~=2.5)\n",
      "  Downloading PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy==2.0.16->nvflare~=2.5) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy==2.0.16->nvflare~=2.5) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Werkzeug==3.0.3->nvflare~=2.5) (3.0.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->nvflare~=2.5) (1.17.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker>=6.0->nvflare~=2.5) (2.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gunicorn>=22.0.0->nvflare~=2.5) (24.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.28.0->nvflare~=2.5) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.28.0->nvflare~=2.5) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.28.0->nvflare~=2.5) (2024.12.14)\n",
      "Requirement already satisfied: pyparsing<4,>=2 in /usr/local/lib/python3.12/dist-packages (from pyhocon->nvflare~=2.5) (3.2.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->nvflare~=2.5) (2.22)\n",
      "Downloading nvflare-2.5.2-py3-none-any.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flask-3.0.2-py3-none-any.whl (101 kB)\n",
      "Downloading Flask_JWT_Extended-4.6.0-py2.py3-none-any.whl (22 kB)\n",
      "Downloading flask_sqlalchemy-3.1.1-py3-none-any.whl (25 kB)\n",
      "Downloading SQLAlchemy-2.0.16-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m139.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading websockets-14.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (170 kB)\n",
      "Downloading pyhocon-0.3.61-py3-none-any.whl (25 kB)\n",
      "Downloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: Werkzeug, websockets, SQLAlchemy, PyJWT, pyhocon, protobuf, gunicorn, Flask, Flask-SQLAlchemy, Flask-JWT-Extended, nvflare\n",
      "  Attempting uninstall: Werkzeug\n",
      "    Found existing installation: Werkzeug 3.1.3\n",
      "    Uninstalling Werkzeug-3.1.3:\n",
      "      Successfully uninstalled Werkzeug-3.1.3\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.38\n",
      "    Uninstalling SQLAlchemy-2.0.38:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.38\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "  Attempting uninstall: Flask\n",
      "    Found existing installation: Flask 3.1.0\n",
      "    Uninstalling Flask-3.1.0:\n",
      "      Successfully uninstalled Flask-3.1.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opentelemetry-proto 1.24.0 requires protobuf<5.0,>=3.19, but you have protobuf 5.29.3 which is incompatible.\n",
      "ngcsdk 3.50.0 requires protobuf<4.0.0,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\n",
      "nemo-toolkit 2.2.0rc1 requires protobuf==3.20.3, but you have protobuf 5.29.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Flask-3.0.2 Flask-JWT-Extended-4.6.0 Flask-SQLAlchemy-3.1.1 PyJWT-2.10.1 SQLAlchemy-2.0.16 Werkzeug-3.0.3 gunicorn-23.0.0 nvflare-2.5.2 protobuf-5.29.3 pyhocon-0.3.61 websockets-14.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# %%capture --no-display --no-stderr cell_output\n",
    "! pip install fuzzywuzzy PyTDC --no-dependencies  # install tdc without dependencies to avoid version conflicts in the BioNeMo container\n",
    "! pip install nvflare~=2.5\n",
    "#! pip install biopython\n",
    "#! pip install scikit-learn\n",
    "#! pip install matplotlib\n",
    "#! pip install protobuf==3.20\n",
    "#! pip install huggingface-hub==0.22.0\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Cross-endpoint multi-task fitting\n",
    "\n",
    "#### Data: Five computational developability guidelines for therapeutic antibody profiling\n",
    "See https://tdcommons.ai/single_pred_tasks/develop/#tap\n",
    "- 241 Antibodies (both chains)\n",
    "\n",
    "#### Task Description: *Regression*. \n",
    "Given the antibody's heavy chain and light chain sequence, predict its developability. The input X is a list of two sequences where the first is the heavy chain and the second light chain.\n",
    "\n",
    "Includes five metrics measuring developability of an antibody: \n",
    " - Complementarity-determining regions (CDR) length - Trivial (excluded)\n",
    " - patches of surface hydrophobicity (PSH)\n",
    " - patches of positive charge (PPC)\n",
    " - patches of negative charge (PNC)\n",
    " - structural Fv charge symmetry parameter (SFvCSP)\n",
    "\n",
    "In the data preparation script, one can choose between uniform sampling of the data among clients and\n",
    "heterogeneous data splits using a Dirichlet sampling strategy. \n",
    "Here, different values of alpha control the level of heterogeneity. Below, we show a Dirichlet sampling of `alpha=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Sampling with alpha=1.0\n",
      "Save 12 training proteins for site-1 (frac=0.064)\n",
      "Save 57 training proteins for site-2 (frac=0.295)\n",
      "Save 34 training proteins for site-3 (frac=0.174)\n",
      "Save 90 training proteins for site-4 (frac=0.466)\n",
      "Saved 193 training and 48 testing proteins.\n",
      "[[       nan 0.07017544 0.08823529 0.04444444]\n",
      " [       nan        nan 0.41176471 0.27777778]\n",
      " [       nan        nan        nan 0.2       ]\n",
      " [       nan        nan        nan        nan]]\n",
      "Avg. overlap: 18.21%\n"
     ]
    }
   ],
   "source": [
    "! cd /bionemo_nvflare_examples/downstream/tap && python prepare_tap_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                                Uniform sampling                                 |                                    Dirichlet sampling                                     |\n",
    "|:-------------------------------------------------------------------------------:|:-----------------------------------------------------------------------------------------:|\n",
    "| <img src=\"./tap/figs/tap_uniform.svg\" alt=\"Uniform data sampling\" width=\"150\"/> | <img src=\"./tap/figs/tap_alpha1.0.svg\" alt=\"Dirichlet sampling (alpha=1.0)\" width=\"150\"/> |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run training (central, local, & FL)**\n",
    "\n",
    "You can change the FL job that's going to be simulated inside the `run_sim_tap.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd /bionemo_nvflare_examples/downstream/tap && python run_sim_tap.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Cross-compound task fitting\n",
    "\n",
    "#### Data: Predicting Antibody Developability from Sequence using Machine Learning\n",
    "See https://tdcommons.ai/single_pred_tasks/develop/#sabdab-chen-et-al\n",
    "- 2,409 Antibodies (both chains)\n",
    "\n",
    "#### Task Description: *Binary classification*. \n",
    "Given the antibody's heavy chain and light chain sequence, predict its developability. The input X is a list of two sequences where the first is the heavy chain and the second light chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "100%|███████████████████████████████████████| 601k/601k [00:00<00:00, 2.35MiB/s]\n",
      "Loading...\n",
      "Done!\n",
      "Sampling with alpha=1.0\n",
      "Save 80 training proteins for site-1 (frac=0.041)\n",
      "Save 365 training proteins for site-2 (frac=0.190)\n",
      "Save 216 training proteins for site-3 (frac=0.112)\n",
      "Save 578 training proteins for site-4 (frac=0.300)\n",
      "Save 568 training proteins for site-5 (frac=0.295)\n",
      "Save 119 training proteins for site-6 (frac=0.062)\n",
      "Saved 1927 training and 482 testing proteins.\n",
      "  TRAIN Pos/Neg ratio: neg=1561, pos=366: 0.234\n",
      "  TRAIN Trivial accuracy: 0.190\n",
      "  TEST Pos/Neg ratio: neg=366, pos=116: 0.317\n",
      "  TEST Trivial accuracy: 0.241\n",
      "[[       nan 0.04657534 0.02314815 0.0449827  0.04929577 0.03361345]\n",
      " [       nan        nan 0.18055556 0.17128028 0.19542254 0.18487395]\n",
      " [       nan        nan        nan 0.11591696 0.10211268 0.08403361]\n",
      " [       nan        nan        nan        nan 0.28521127 0.32773109]\n",
      " [       nan        nan        nan        nan        nan 0.28571429]\n",
      " [       nan        nan        nan        nan        nan        nan]]\n",
      "Avg. overlap: 14.20%\n"
     ]
    }
   ],
   "source": [
    "# you may need to fix these paths to your own scripts\n",
    "! cd /bionemo_nvflare_examples/downstream/sabdab && python prepare_sabdab_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we are using the Dirichlet sampling strategy to generate heterogeneous data distributions among clients.\n",
    "Lower values of `alpha` generate higher levels of heterogeneity.\n",
    "\n",
    "|                                            Alpha 10.0                                             |                                            Alpha 1.0                                            |\n",
    "|:-------------------------------------------------------------------------------------------------:|:-----------------------------------------------------------------------------------------------:|\n",
    "| <img src=\"./sabdab/figs/sabdab_alpha10.0.svg\" alt=\"Dirichlet sampling (alpha=10.0)\" width=\"150\"/> | <img src=\"./sabdab/figs/sabdab_alpha1.0.svg\" alt=\"Dirichlet sampling (alpha=1.0)\" width=\"150\"/> |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Run training (central, local, & FL)**\n",
    "\n",
    "You can change the FL job that's going to be simulated by changing the arguments of `run_sim_sabdab.py` script. You can choose which ESM2 model to download (8M or 650M parameters). The ESM2 finetuning arguments such as learning rate and others can be modified inside the script itself.\n",
    "\n",
    "First, let's check its arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/bionemo_nvflare_examples/downstream/sabdab/run_sim_sabdab.py\", line 15, in <module>\n",
      "    from nvflare.job_config.script_runner import BaseScriptRunner\n",
      "ModuleNotFoundError: No module named 'nvflare'\n"
     ]
    }
   ],
   "source": [
    "!cd /bionemo_nvflare_examples/downstream/sabdab && python run_sim_sabdab.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Central training**\n",
    "\n",
    "To simulate central training, we use one client, running one round of training for several steps. Note that if the `--exp_name` argument contains `\"central\"`, the combined training dataset is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/bionemo_nvflare_examples/downstream/sabdab/run_sim_sabdab.py\", line 15, in <module>\n",
      "    from nvflare.job_config.script_runner import BaseScriptRunner\n",
      "ModuleNotFoundError: No module named 'nvflare'\n"
     ]
    }
   ],
   "source": [
    "!cd /bionemo_nvflare_examples/downstream/sabdab && python run_sim_sabdab.py --num_clients=1 --num_rounds=1 --local_steps=300 --exp_name central"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Local training**\n",
    "\n",
    "To simulate central training, we use six clients, each running one round of training for several steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/bionemo_nvflare_examples/downstream/sabdab/run_sim_sabdab.py\", line 15, in <module>\n",
      "    from nvflare.job_config.script_runner import BaseScriptRunner\n",
      "ModuleNotFoundError: No module named 'nvflare'\n"
     ]
    }
   ],
   "source": [
    "!cd /bionemo_nvflare_examples/downstream/sabdab && python run_sim_sabdab.py --num_clients=6 --num_rounds=1 --local_steps=300 --exp_name local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. FedAvg training**\n",
    "\n",
    "To simulate federated training, we use six clients, running several rounds with FedAvg, each with a smaller number of local steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/bionemo_nvflare_examples/downstream/sabdab/run_sim_sabdab.py\", line 15, in <module>\n",
      "    from nvflare.job_config.script_runner import BaseScriptRunner\n",
      "ModuleNotFoundError: No module named 'nvflare'\n"
     ]
    }
   ],
   "source": [
    "!cd /bionemo_nvflare_examples/downstream/sabdab && python run_sim_sabdab.py --num_clients=6 --num_rounds=30 --local_steps=10 --exp_name fedavg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results with heterogeneous data sampling (alpha=10.0)\n",
    "| Setting | Accuracy  |\n",
    "|:-------:|:---------:|\n",
    "|  Local  |   0.821   |\n",
    "|   FedAvg    | **0.833** |\n",
    "\n",
    "#### Results with heterogeneous data sampling (alpha=1.0)\n",
    "| Setting | Accuracy  |\n",
    "|:-------:|:---------:|\n",
    "|  Local  |   0.813   |\n",
    "|   FedAvg    | **0.835** |\n",
    "\n",
    "### Task 3. Subcellular location prediction with ESM2nv 650M\n",
    "Follow the data download and preparation in [task_fitting.ipynb](../task_fitting/task_fitting.ipynb).\n",
    "\n",
    "Here, we use a heterogeneous sampling with `alpha=1.0`.\n",
    "\n",
    "<img src=\"./scl/figs/scl_alpha1.0.svg\" alt=\"Dirichlet sampling (alpha=10.0)\" width=\"300\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this to work run the task_fitting notebook first in ../nvflare_with_bionemo/task_fitting/task_fitting.ipynb\n",
    "! cd /bionemo_nvflare_examples/downstream/scl && python run_sim_scl.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, you can switch between local and FL jobs by modifying the `run_sim_scl.py` script.\n",
    "\n",
    "#### Results with heterogeneous data sampling (alpha=10.0)\n",
    "| Setting | Accuracy  |\n",
    "|:-------:|:---------:|\n",
    "|  Local  |   0.773   |\n",
    "|   FedAvg    | **0.776** |\n",
    "\n",
    "\n",
    "<img src=\"./scl/figs/scl_results.svg\" alt=\"Dirichlet sampling (alpha=1.0)\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
