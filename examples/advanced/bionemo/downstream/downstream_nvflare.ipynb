{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Protein Downstream Fine-tuning\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b> This notebook was tested on a single A1000 GPU and is compatible with BioNeMo Framework v2.3. To leverage additional or higher-performance GPUs, you can modify the configuration files and simulation script to accommodate multiple devices and increase thread utilization respectively.</div>\n",
    "\n",
    "The example datasets used here are made available by [Therapeutics Data Commons](https://tdcommons.ai/) through PyTDC.\n",
    "\n",
    "This example shows three different downstream tasks for fine-tuning a BioNeMo ESM-style model on different datasets.\n",
    "We separate the scripts and job configurations into three folders based on the dataset names:\n",
    "\n",
    "\n",
    "1. `tap`: therapeutic antibody profiling\"\n",
    "2. `sabdab`: SAbDab: the structural antibody database\"\n",
    "3. `scl`: \"subcellular location prediction\"\n",
    "\n",
    "## Setup\n",
    "\n",
    "Ensure that you have read through the Getting Started section, can run the BioNeMo Framework docker container, and have configured the NGC Command Line Interface (CLI) within the container. It is assumed that this notebook is being executed from within the container.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b> Some of the cells below generate long text output.  We're using <pre>%%capture --no-display --no-stderr cell_output</pre> to suppress this output.  Comment or delete this line in the cells below to restore full output.</div>\n",
    "\n",
    "### Import and install all required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/igraph-0.11.8-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.11.9-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/texttable-1.7.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/opt_einsum-3.4.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/dill-0.3.9-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.13a0+0d33366-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting fuzzywuzzy\n",
      "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting PyTDC\n",
      "  Downloading pytdc-1.1.12.tar.gz (151 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?2done\n",
      "\u001b[?25hDownloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Building wheels for collected packages: PyTDC\n",
      "  Building wheel for PyTDC (setup.py) ... \u001b[done\n",
      "\u001b[?25h  Created wheel for PyTDC: filename=PyTDC-1.1.12-py3-none-any.whl size=189419 sha256=9048cd857b3364c6a849e786b96fc3be325e6570054366190aebadf9283d8376\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-z8ep7o__/wheels/de/2e/da/e46690d98c1256fee1741d03030623bc926cebc13e3e359145\n",
      "Successfully built PyTDC\n",
      "Installing collected packages: PyTDC, fuzzywuzzy\n",
      "Successfully installed PyTDC-1.1.12 fuzzywuzzy-0.18.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# %%capture --no-display --no-stderr cell_output\n",
    "! pip install fuzzywuzzy PyTDC --no-dependencies  # install tdc without dependencies to avoid version conflicts in the BioNeMo container\n",
    "! pip install nvflare~=2.5\n",
    "#! pip install biopython\n",
    "#! pip install scikit-learn\n",
    "#! pip install matplotlib\n",
    "#! pip install protobuf==3.20\n",
    "#! pip install huggingface-hub==0.22.0\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Cross-endpoint multi-task fitting\n",
    "\n",
    "#### Data: Five computational developability guidelines for therapeutic antibody profiling\n",
    "See https://tdcommons.ai/single_pred_tasks/develop/#tap\n",
    "- 241 Antibodies (both chains)\n",
    "\n",
    "#### Task Description: *Regression*. \n",
    "Given the antibody's heavy chain and light chain sequence, predict its developability. The input X is a list of two sequences where the first is the heavy chain and the second light chain.\n",
    "\n",
    "Includes five metrics measuring developability of an antibody: \n",
    " - Complementarity-determining regions (CDR) length - Trivial (excluded)\n",
    " - patches of surface hydrophobicity (PSH)\n",
    " - patches of positive charge (PPC)\n",
    " - patches of negative charge (PNC)\n",
    " - structural Fv charge symmetry parameter (SFvCSP)\n",
    "\n",
    "In the data preparation script, one can choose between uniform sampling of the data among clients and\n",
    "heterogeneous data splits using a Dirichlet sampling strategy. \n",
    "Here, different values of alpha control the level of heterogeneity. Below, we show a Dirichlet sampling of `alpha=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd /bionemo_nvflare_examples/downstream/tap && python prepare_tap_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                                Uniform sampling                                 |                                    Dirichlet sampling                                     |\n",
    "|:-------------------------------------------------------------------------------:|:-----------------------------------------------------------------------------------------:|\n",
    "| <img src=\"./tap/figs/tap_uniform.svg\" alt=\"Uniform data sampling\" width=\"150\"/> | <img src=\"./tap/figs/tap_alpha1.0.svg\" alt=\"Dirichlet sampling (alpha=1.0)\" width=\"150\"/> |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run training (central, local, & FL)**\n",
    "\n",
    "You can change the FL job that's going to be simulated inside the `run_sim_tap.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd /bionemo_nvflare_examples/downstream/tap && python run_sim_tap.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Cross-compound task fitting\n",
    "\n",
    "#### Data: Predicting Antibody Developability from Sequence using Machine Learning\n",
    "See https://tdcommons.ai/single_pred_tasks/develop/#sabdab-chen-et-al\n",
    "- 2,409 Antibodies (both chains)\n",
    "\n",
    "#### Task Description: *Binary classification*. \n",
    "Given the antibody's heavy chain and light chain sequence, predict its developability. The input X is a list of two sequences where the first is the heavy chain and the second light chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Sampling with alpha=1.0\n",
      "Save 80 training proteins for site-1 (frac=0.041)\n",
      "Save 365 training proteins for site-2 (frac=0.190)\n",
      "Save 216 training proteins for site-3 (frac=0.112)\n",
      "Save 578 training proteins for site-4 (frac=0.300)\n",
      "Save 568 training proteins for site-5 (frac=0.295)\n",
      "Save 119 training proteins for site-6 (frac=0.062)\n",
      "Saved 1927 training and 482 testing proteins.\n",
      "  TRAIN Pos/Neg ratio: neg=366, pos=1561: 4.265\n",
      "  TRAIN Trivial accuracy: 0.810\n",
      "  TEST Pos/Neg ratio: neg=116, pos=366: 3.155\n",
      "  TEST Trivial accuracy: 0.759\n",
      "[[       nan 0.04657534 0.02314815 0.0449827  0.04929577 0.03361345]\n",
      " [       nan        nan 0.18055556 0.17128028 0.19542254 0.18487395]\n",
      " [       nan        nan        nan 0.11591696 0.10211268 0.08403361]\n",
      " [       nan        nan        nan        nan 0.28521127 0.32773109]\n",
      " [       nan        nan        nan        nan        nan 0.28571429]\n",
      " [       nan        nan        nan        nan        nan        nan]]\n",
      "Avg. overlap: 14.20%\n"
     ]
    }
   ],
   "source": [
    "# you may need to fix these paths to your own scripts\n",
    "! cd /bionemo_nvflare_examples/downstream/sabdab && python prepare_sabdab_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we are using the Dirichlet sampling strategy to generate heterogeneous data distributions among clients.\n",
    "Lower values of `alpha` generate higher levels of heterogeneity.\n",
    "\n",
    "|                                            Alpha 10.0                                             |                                            Alpha 1.0                                            |\n",
    "|:-------------------------------------------------------------------------------------------------:|:-----------------------------------------------------------------------------------------------:|\n",
    "| <img src=\"./sabdab/figs/sabdab_alpha10.0.svg\" alt=\"Dirichlet sampling (alpha=10.0)\" width=\"150\"/> | <img src=\"./sabdab/figs/sabdab_alpha1.0.svg\" alt=\"Dirichlet sampling (alpha=1.0)\" width=\"150\"/> |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Run training (central, local, & FL)**\n",
    "\n",
    "You can change the FL job that's going to be simulated by changing the arguments of `run_sim_sabdab.py` script. The ESM2 finetuning arguments such as learning rate and others can be modified inside the script itself.\n",
    "\n",
    "First check its arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/bionemo_nvflare_examples/downstream/sabdab/run_sim_sabdab.py\", line 15, in <module>\n",
      "    from nvflare.job_config.script_runner import BaseScriptRunner\n",
      "ModuleNotFoundError: No module named 'nvflare'\n"
     ]
    }
   ],
   "source": [
    "!cd /bionemo_nvflare_examples/downstream/sabdab && python run_sim_sabdab.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Central training**\n",
    "\n",
    "To simulate central training, we use one client, running one round of training for several steps. Note that if the `--exp_name` argument contains `\"central\"`, the combined training dataset is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/bionemo_nvflare_examples/downstream/sabdab/run_sim_sabdab.py\", line 15, in <module>\n",
      "    from nvflare.job_config.script_runner import BaseScriptRunner\n",
      "ModuleNotFoundError: No module named 'nvflare'\n"
     ]
    }
   ],
   "source": [
    "!cd /bionemo_nvflare_examples/downstream/sabdab && python run_sim_sabdab.py --num_clients=1 --num_rounds=1 --local_steps=300 --exp_name central"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Local training**\n",
    "\n",
    "To simulate central training, we use six clients, each running one round of training for several steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/bionemo_nvflare_examples/downstream/sabdab/run_sim_sabdab.py\", line 15, in <module>\n",
      "    from nvflare.job_config.script_runner import BaseScriptRunner\n",
      "ModuleNotFoundError: No module named 'nvflare'\n"
     ]
    }
   ],
   "source": [
    "!cd /bionemo_nvflare_examples/downstream/sabdab && python run_sim_sabdab.py --num_clients=6 --num_rounds=1 --local_steps=300 --exp_name local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. FedAvg training**\n",
    "\n",
    "To simulate federated training, we use six clients, running several rounds with FedAvg, each with a smaller number of local steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/bionemo_nvflare_examples/downstream/sabdab/run_sim_sabdab.py\", line 15, in <module>\n",
      "    from nvflare.job_config.script_runner import BaseScriptRunner\n",
      "ModuleNotFoundError: No module named 'nvflare'\n"
     ]
    }
   ],
   "source": [
    "!cd /bionemo_nvflare_examples/downstream/sabdab && python run_sim_sabdab.py --num_clients=6 --num_rounds=30 --local_steps=10 --exp_name fedavg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results with heterogeneous data sampling (alpha=10.0)\n",
    "| Setting | Accuracy  |\n",
    "|:-------:|:---------:|\n",
    "|  Local  |   0.821   |\n",
    "|   FedAvg    | **0.833** |\n",
    "\n",
    "#### Results with heterogeneous data sampling (alpha=1.0)\n",
    "| Setting | Accuracy  |\n",
    "|:-------:|:---------:|\n",
    "|  Local  |   0.813   |\n",
    "|   FedAvg    | **0.835** |\n",
    "\n",
    "### Task 3. Subcellular location prediction with ESM2nv 650M\n",
    "Follow the data download and preparation in [task_fitting.ipynb](../task_fitting/task_fitting.ipynb).\n",
    "\n",
    "Here, we use a heterogeneous sampling with `alpha=1.0`.\n",
    "\n",
    "<img src=\"./scl/figs/scl_alpha1.0.svg\" alt=\"Dirichlet sampling (alpha=10.0)\" width=\"300\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this to work run the task_fitting notebook first in ../nvflare_with_bionemo/task_fitting/task_fitting.ipynb\n",
    "! cd /bionemo_nvflare_examples/downstream/scl && python run_sim_scl.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, you can switch between local and FL jobs by modifying the `run_sim_scl.py` script.\n",
    "\n",
    "#### Results with heterogeneous data sampling (alpha=10.0)\n",
    "| Setting | Accuracy  |\n",
    "|:-------:|:---------:|\n",
    "|  Local  |   0.773   |\n",
    "|   FedAvg    | **0.776** |\n",
    "\n",
    "\n",
    "<img src=\"./scl/figs/scl_results.svg\" alt=\"Dirichlet sampling (alpha=1.0)\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
