{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e101089",
   "metadata": {},
   "source": [
    "# Federated Protein Embeddings and Task Model Fitting with BioNeMo\n",
    "\n",
    "This example notebook shows how to obtain protein learned representations in the form of embeddings using the ESM-1nv pre-trained model. The model is trained with NVIDIA's BioNeMo framework for Large Language Model training and inference. For more details, please visit NVIDIA BioNeMo Service at https://www.nvidia.com/en-us/gpu-cloud/bionemo.\n",
    "\n",
    "This notebook will walk you through the task fitting workflow in the following sections:\n",
    "\n",
    "* \n",
    "*\n",
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5396e01",
   "metadata": {},
   "source": [
    "### Obtaining the protein embeddings using the BioNeMo ESM-1nv model\n",
    "Using BioNeMo, users can obtain numerical vector representations of protein sequences called embeddings. Protein embeddings can then be used for visualization or making downstream predictions.\n",
    "\n",
    "Here we are interested in training a neural network to predict subcellular location from an embedding.\n",
    "\n",
    "The data we will be using comes from the paper [Light attention predicts protein location from the language of life](https://academic.oup.com/bioinformaticsadvances/article/1/1/vbab035/6432029) by Stärk et al. In this paper, the authors developed a machine learning algorithm to predict the subcellular location of proteins from sequence through protein langage models that are similar to those hosted by BioNeMo. Protein subcellular location refers to where the protein localizes in the cell, for example a protein my be expressed in the Nucleus or in the Cytoplasm. Knowing where proteins localize can provide insights into the underlying mechanisms of cellular processes and help identify potential targets for drug development. The following image includes a few examples of subcellular locations in an animal cell:\n",
    "\n",
    "\n",
    "(Image freely available at https://pixabay.com/images/id-48542)\n",
    "\n",
    "### Dataset sourcing\n",
    "For our target input sequences, we will point to FASTA sequences in a benchmark dataset called Fitness Landscape Inference for Proteins (FLIP). FLIP encompasses experimental data across adeno-associated virus stability for gene therapy, protein domain B1 stability and immunoglobulin binding, and thermostability from multiple protein families."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d047f1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example protein dataset location\n",
    "fasta_url= \"http://data.bioembeddings.com/public/FLIP/fasta/scl/mixed_soft.fasta\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bfef23",
   "metadata": {},
   "source": [
    "First, we define the source of example protein dataset with the FASTA sequences. This data follows the [biotrainer](https://github.com/sacdallago/biotrainer/blob/main/docs/data_standardization.md) standard, so it includes information about the class in the FASTA header, and the protein sequence. Here are two example sequences in this file:\n",
    "\n",
    "```\n",
    ">Sequence1 TARGET=Cell_membrane SET=train VALIDATION=False\n",
    "MMKTLSSGNCTLNVPAKNSYRMVVLGASRVGKSSIVSRFLNGRFEDQYTPTIEDFHRKVYNIHGDMYQLDILDTSGNHPFPAM\n",
    "RRLSILTGDVFILVFSLDSRESFDEVKRLQKQILEVKSCLKNKTKEAAELPMVICGNKNDHSELCRQVPAMEAELLVSGDENC\n",
    "AYFEVSAKKNTNVNEMFYVLFSMAKLPHEMSPALHHKISVQYGDAFHPRPFCMRRTKVAGAYGMVSPFARRPSVNSDLKYIKA\n",
    "KVLREGQARERDKCSIQ\n",
    ">Sequence4833 TARGET=Nucleus SET=train VALIDATION=False\n",
    "MARTKQTARKSTGGKAPRKQLATKAARKSAPATGGVKKPHRFRPGTVALREIRKYQKSTELLIRKLPFQRLVREIAQDFKTDL\n",
    "RFQSSAVAALQEAAEAYLVGLFEDTNLCAIHAKRVTIMPKDIQLARRIRGERA\n",
    "Note the following attributes in the FASTA header:\n",
    "```\n",
    "\n",
    "* `TARGET` attribute holds the subcellular location classification for the sequence, for instance Cell_membrane and Nucleus. This dataset includes a total of ten subcellelular location classes -- more on that below.\n",
    "* `SET` attribute defines whether the sequence should be used for training (train) or testing (test)\n",
    "* `VALIDATION` attribute defines whether the sequence should be used for validation (all sequences where this is True are also in set=train)\n",
    "\n",
    "### Downloading the protein sequences and subcellular location annotations\n",
    "In this step we download the FASTA file defined above and parse the sequences into a list of BioPython SeqRecord objects.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf5c1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Download the FASTA file from FLIP: https://github.com/J-SNACKKB/FLIP/tree/main/splits/scl\n",
    "fasta_content = requests.get(fasta_url, headers={\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x86)'\n",
    "}).content.decode('utf-8')\n",
    "fasta_stream = io.StringIO(fasta_content)\n",
    "\n",
    "# Obtain a list of SeqRecords/proteins which contain sequence and attributes\n",
    "# from the FASTA header\n",
    "proteins = list(SeqIO.parse(fasta_stream, \"fasta\"))\n",
    "print(f\"Downloaded {len(proteins)} sequences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04beb0f",
   "metadata": {},
   "source": [
    "### Data splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befe6646",
   "metadata": {},
   "source": [
    "### Federated embedding extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "776e418f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-26 22:02:13,465 - SimulatorRunner - INFO - Create the Simulator Server.\n",
      "2023-07-26 22:02:13,469 - Cell - INFO - server: creating listener on tcp://0:41509\n",
      "2023-07-26 22:02:13,502 - Cell - INFO - server: created backbone external listener for tcp://0:41509\n",
      "2023-07-26 22:02:13,504 - ConnectorManager - INFO - 9053: Try start_listener Listener resources: {'secure': False, 'host': 'localhost'}\n",
      "2023-07-26 22:02:13,506 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00002 PASSIVE tcp://0:16524] is starting\n",
      "2023-07-26 22:02:14,008 - Cell - INFO - server: created backbone internal listener for tcp://localhost:16524\n",
      "2023-07-26 22:02:14,012 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 PASSIVE tcp://0:41509] is starting\n",
      "2023-07-26 22:02:14,103 - nvflare.fuel.hci.server.hci - INFO - Starting Admin Server localhost on Port 45799\n",
      "2023-07-26 22:02:14,104 - SimulatorRunner - INFO - Deploy the Apps.\n",
      "2023-07-26 22:02:14,623 - SimulatorRunner - INFO - Create the simulate clients.\n",
      "2023-07-26 22:02:14,630 - ClientManager - INFO - Client: New client site-1@192.168.0.25 joined. Sent token: 9a95d871-a03d-4807-adfc-1b4513560533.  Total clients: 1\n",
      "2023-07-26 22:02:14,633 - FederatedClient - INFO - Successfully registered client:site-1 for project simulator_server. Token:9a95d871-a03d-4807-adfc-1b4513560533 SSID:\n",
      "2023-07-26 22:02:14,636 - SimulatorRunner - INFO - Set the client status ready.\n",
      "2023-07-26 22:02:14,638 - SimulatorRunner - INFO - Deploy and start the Server App.\n",
      "2023-07-26 22:02:14,640 - ServerCommandAgent - INFO - ServerCommandAgent cell register_request_cb: server.simulate_job\n",
      "2023-07-26 22:02:16,662 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job]: Server runner starting ...\n",
      "2023-07-26 22:02:16,665 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job]: starting workflow share_config (<class 'bionemo_inference.BioNeMoInference'>) ...\n",
      "2023-07-26 22:02:16,667 - BioNeMoInference - INFO - [identity=simulator_server, run=simulate_job]: Initializing BroadcastAndProcess.\n",
      "2023-07-26 22:02:16,669 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job]: Workflow share_config (<class 'bionemo_inference.BioNeMoInference'>) started\n",
      "2023-07-26 22:02:16,727 - BioNeMoModelSharer - INFO - [identity=simulator_server, run=simulate_job, wf=share_config]: Load model configuration from /tmp/nvflare/bionemo/embeddings/simulate_job/app_server/config/base_config.yaml and /tmp/nvflare/bionemo/embeddings/simulate_job/app_server/config/infer.yaml\n",
      "2023-07-26 22:02:16,730 - BioNeMoInference - INFO - [identity=simulator_server, run=simulate_job, wf=share_config]: scheduled task bionemo_inference\n",
      "2023-07-26 22:02:17,648 - SimulatorClientRunner - INFO - Start the clients run simulation.\n",
      "2023-07-26 22:02:18,652 - SimulatorClientRunner - INFO - Simulate Run client: site-1\n",
      "2023-07-26 22:02:19,706 - ClientTaskWorker - INFO - ClientTaskWorker started to run\n",
      "2023-07-26 22:02:19,784 - Cell - INFO - site-1.simulate_job: created backbone external connector to tcp://localhost:41509\n",
      "2023-07-26 22:02:19,785 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 ACTIVE tcp://localhost:41509] is starting\n",
      "2023-07-26 22:02:23,387 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmp5gufv_gv\n",
      "2023-07-26 22:02:23,388 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmp5gufv_gv/_remote_module_non_scriptable.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-07-26 22:02:29 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-07-26 22:02:30 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-26 22:02:31,139 - Cell - WARNING - site-1.simulate_job: no connection to child site-1.simulate_job.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0726 22:02:31.139726 140064913278784 cell.py:179] site-1.simulate_job: no connection to child site-1.simulate_job.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-26 22:02:32,142 - Cell - WARNING - site-1.simulate_job: no connection to child site-1.simulate_job.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0726 22:02:32.142046 140064913278784 cell.py:179] site-1.simulate_job: no connection to child site-1.simulate_job.0\n",
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-26 22:02:32,844 - Cell - INFO - site-1.simulate_job.0: created backbone internal connector to tcp://localhost:28396 on parent\n",
      "2023-07-26 22:02:32,844 - ConnectorManager - INFO - 9180: Try start_listener Listener resources: {'secure': False, 'host': 'localhost'}\n",
      "2023-07-26 22:02:32,845 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00002 PASSIVE tcp://0:17247] is starting\n",
      "2023-07-26 22:02:32,848 - Cell - INFO - site-1.simulate_job.1: created backbone internal connector to tcp://localhost:28396 on parent\n",
      "2023-07-26 22:02:32,848 - ConnectorManager - INFO - 9181: Try start_listener Listener resources: {'secure': False, 'host': 'localhost'}\n",
      "2023-07-26 22:02:32,849 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00002 PASSIVE tcp://0:21932] is starting\n",
      "2023-07-26 22:02:33,143 - Cell - WARNING - site-1.simulate_job: no connection to child site-1.simulate_job.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0726 22:02:33.143659 140064913278784 cell.py:179] site-1.simulate_job: no connection to child site-1.simulate_job.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-26 22:02:33,345 - Cell - INFO - site-1.simulate_job.0: created backbone internal listener for tcp://localhost:17247\n",
      "2023-07-26 22:02:33,346 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 ACTIVE tcp://localhost:28396] is starting\n",
      "2023-07-26 22:02:33,348 - SubWorkerExecutor - INFO - SubWorkerExecutor process started.\n",
      "2023-07-26 22:02:33,350 - Cell - INFO - site-1.simulate_job.1: created backbone internal listener for tcp://localhost:21932\n",
      "2023-07-26 22:02:33,350 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 ACTIVE tcp://localhost:28396] is starting\n",
      "2023-07-26 22:02:33,353 - SubWorkerExecutor - INFO - SubWorkerExecutor process started.\n",
      "2023-07-26 22:02:37,019 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmpjflm4dzo\n",
      "2023-07-26 22:02:37,019 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmpjflm4dzo/_remote_module_non_scriptable.py\n",
      "2023-07-26 22:02:37,027 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmp7pijbtgr\n",
      "2023-07-26 22:02:37,028 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmp7pijbtgr/_remote_module_non_scriptable.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-07-26 22:02:43 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-07-26 22:02:44 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-26 22:02:44,718 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-1, peer_run=simulate_job, task_name=bionemo_inference, task_id=0e14097a-d4cd-4400-9c36-fff8ca30daf7]: assigned task to client site-1: name=bionemo_inference, id=0e14097a-d4cd-4400-9c36-fff8ca30daf7\n",
      "2023-07-26 22:02:44,724 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-1, peer_run=simulate_job, task_name=bionemo_inference, task_id=0e14097a-d4cd-4400-9c36-fff8ca30daf7]: sent task assignment to client. client_name:site-1 task_id:0e14097a-d4cd-4400-9c36-fff8ca30daf7\n",
      "2023-07-26 22:02:44,726 - GetTaskCommand - INFO - return task to client.  client_name: site-1  task_name: bionemo_inference   task_id: 0e14097a-d4cd-4400-9c36-fff8ca30daf7  sharable_header_task_id: 0e14097a-d4cd-4400-9c36-fff8ca30daf7\n",
      "[NeMo I 2023-07-26 22:02:45 utils:250] Restoring model from /tmp/nvflare/bionemo/embeddings/simulate_job/app_site-1/models/esm1nv.nemo\n",
      "[NeMo I 2023-07-26 22:02:45 utils:254] Loading model class: bionemo.model.protein.esm1nv.esm1nv_model.ESM1nvModel\n",
      "2023-07-26 22:02:45,099 - pytorch_lightning.utilities.rank_zero - INFO - GPU available: True (cuda), used: True\n",
      "2023-07-26 22:02:45,099 - pytorch_lightning.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores\n",
      "2023-07-26 22:02:45,100 - pytorch_lightning.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs\n",
      "2023-07-26 22:02:45,100 - pytorch_lightning.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2023-07-26 22:02:45 utils:234] \n",
      "    \n",
      "    ************** Trainer configuration ***********\n",
      "[NeMo I 2023-07-26 22:02:45 utils:235] \n",
      "    name: ESM1nv_Inference\n",
      "    do_training: true\n",
      "    do_testing: false\n",
      "    restore_from_path: null\n",
      "    trainer:\n",
      "      devices: 2\n",
      "      num_nodes: 1\n",
      "      accelerator: gpu\n",
      "      precision: 16\n",
      "      logger: false\n",
      "      enable_checkpointing: false\n",
      "      replace_sampler_ddp: false\n",
      "      max_epochs: null\n",
      "      max_steps: 1000000\n",
      "      log_every_n_steps: 10\n",
      "      val_check_interval: 1500\n",
      "      limit_val_batches: 50\n",
      "      limit_test_batches: 500\n",
      "      accumulate_grad_batches: 1\n",
      "      gradient_clip_val: 1.0\n",
      "      benchmark: false\n",
      "    model:\n",
      "      micro_batch_size: 8\n",
      "      tensor_model_parallel_size: 1\n",
      "      pipeline_model_parallel_size: 1\n",
      "      seq_length: 512\n",
      "      max_position_embeddings: ${.seq_length}\n",
      "      num_layers: 6\n",
      "      hidden_size: 768\n",
      "      ffn_hidden_size: 3072\n",
      "      num_attention_heads: 12\n",
      "      init_method_std: 0.02\n",
      "      hidden_dropout: 0.1\n",
      "      kv_channels: null\n",
      "      apply_query_key_layer_scaling: true\n",
      "      layernorm_epsilon: 1.0e-05\n",
      "      make_vocab_size_divisible_by: 128\n",
      "      pre_process: true\n",
      "      post_process: false\n",
      "      bert_binary_head: false\n",
      "      resume_from_checkpoint: null\n",
      "      masked_softmax_fusion: true\n",
      "      tokenizer:\n",
      "        library: sentencepiece\n",
      "        type: null\n",
      "        model: models/vocab/protein_sequence_sentencepiece.model\n",
      "        vocab_file: models/vocab/protein_sequence.vocab\n",
      "        merge_file: null\n",
      "        vocab_path: /tmp/nvflare/bionemo/embeddings/simulate_job/app_site-1/models/vocab/protein_sequence.vocab\n",
      "        model_path: /tmp/nvflare/bionemo/embeddings/simulate_job/app_site-1/models/vocab/protein_sequence_sentencepiece.model\n",
      "      native_amp_init_scale: 4294967296\n",
      "      native_amp_growth_interval: 1000\n",
      "      fp32_residual_connection: false\n",
      "      fp16_lm_cross_entropy: false\n",
      "      seed: 1234\n",
      "      use_cpu_initialization: false\n",
      "      onnx_safe: false\n",
      "      activations_checkpoint_method: null\n",
      "      activations_checkpoint_num_layers: 1\n",
      "      data:\n",
      "        dataset_path: /tmp/data/FLIP/secondary_structure/test/x000\n",
      "        dataset:\n",
      "          train: x[000..049]\n",
      "          test: x[000..049]\n",
      "          val: x[000..049]\n",
      "        newline_int: 10\n",
      "        header_lines: 1\n",
      "        data_col: 3\n",
      "        data_sep: ','\n",
      "        sort_dataset_paths: true\n",
      "        skip_lines: 0\n",
      "        micro_batch_size: 370\n",
      "        encoder_augment: false\n",
      "        encoder_mask: false\n",
      "        decoder_augment: false\n",
      "        decoder_mask: false\n",
      "        canonicalize_input: true\n",
      "        dataloader_type: single\n",
      "        drop_last: false\n",
      "        pin_memory: false\n",
      "        num_workers: 8\n",
      "        data_prefix: ''\n",
      "        index_mapping_dir: null\n",
      "        data_impl: ''\n",
      "        splits_string: 900,50,50\n",
      "        skip_warmup: true\n",
      "        reset_position_ids: false\n",
      "        reset_attention_mask: false\n",
      "        eod_mask_loss: false\n",
      "        masked_lm_prob: 0.15\n",
      "        short_seq_prob: 0.1\n",
      "        dataset_format: csv\n",
      "        seed: ${model.seed}\n",
      "        max_seq_length: ${model.seq_length}\n",
      "        batch_size: 128\n",
      "        ngc_registry_target: uniref50_2022_05\n",
      "        ngc_registry_version: v23.06\n",
      "        data_impl_kwargs:\n",
      "          csv_fields_mmap:\n",
      "            newline_int: 10\n",
      "            header_lines: 1\n",
      "            workers: null\n",
      "            sort_dataset_paths: false\n",
      "            data_sep: ','\n",
      "            data_fields:\n",
      "              id: 0\n",
      "              sequence: 1\n",
      "          fasta_fields_mmap:\n",
      "            data_fields:\n",
      "              id: 0\n",
      "              sequence: 1\n",
      "        use_upsampling: true\n",
      "        output_fname: ''\n",
      "      optim:\n",
      "        name: fused_adam\n",
      "        lr: 0.0002\n",
      "        weight_decay: 0.01\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.98\n",
      "        sched:\n",
      "          name: CosineAnnealing\n",
      "          warmup_steps: 500\n",
      "          constant_steps: 50000\n",
      "          min_lr: 2.0e-05\n",
      "      precision: 16\n",
      "      encoder_seq_length: ${.seq_length}\n",
      "      downstream_task:\n",
      "        restore_from_path: /tmp/nvflare/bionemo/embeddings/simulate_job/app_site-1/models/esm1nv.nemo\n",
      "        outputs:\n",
      "        - embeddings\n",
      "        - hiddens\n",
      "      global_batch_size: 16\n",
      "    defaults:\n",
      "    - base_infer_config\n",
      "    - _self_\n",
      "    desc: Minimum configuration for initializing a ESM1nv model for inference.\n",
      "    target: bionemo.model.protein.esm1nv.esm1nv_model.ESM1nvModel\n",
      "    infer_target: bionemo.model.protein.esm1nv.infer.ESM1nvInference\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-07-26 22:02:45 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/plugins/precision/native_amp.py:131: LightningDeprecationWarning: The `NativeMixedPrecisionPlugin` class has been renamed in v1.9.0 and will be removed in v2.0.0. Please use `pytorch_lightning.plugins.MixedPrecisionPlugin` instead.\n",
      "      rank_zero_deprecation(\n",
      "    \n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0726 22:02:45.099255 140246922557184 setup.py:163] GPU available: True (cuda), used: True\n",
      "I0726 22:02:45.099840 140246922557184 setup.py:166] TPU available: False, using: 0 TPU cores\n",
      "I0726 22:02:45.100004 140246922557184 setup.py:169] IPU available: False, using: 0 IPUs\n",
      "I0726 22:02:45.100112 140246922557184 setup.py:172] HPU available: False, using: 0 HPUs\n",
      "[NeMo E 2023-07-26 22:02:45 exp_manager:306] exp_manager did not receive a cfg argument. It will be disabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-07-26 22:02:45 megatron_init:231] Rank 0 has data parallel group: [0, 1]\n",
      "[NeMo I 2023-07-26 22:02:45 megatron_init:234] All data parallel group ranks: [[0, 1]]\n",
      "[NeMo I 2023-07-26 22:02:45 megatron_init:235] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2023-07-26 22:02:45 megatron_init:243] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2023-07-26 22:02:45 megatron_init:244] All model parallel group ranks: [[0], [1]]\n",
      "[NeMo I 2023-07-26 22:02:45 megatron_init:254] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2023-07-26 22:02:45 megatron_init:258] All tensor model parallel group ranks: [[0], [1]]\n",
      "[NeMo I 2023-07-26 22:02:45 megatron_init:259] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2023-07-26 22:02:45 megatron_init:273] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2023-07-26 22:02:45 megatron_init:285] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2023-07-26 22:02:45 megatron_init:291] All pipeline model parallel group ranks: [[0], [1]]\n",
      "[NeMo I 2023-07-26 22:02:45 megatron_init:292] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2023-07-26 22:02:45 megatron_init:293] All embedding group ranks: [[0], [1]]\n",
      "[NeMo I 2023-07-26 22:02:45 megatron_init:294] Rank 0 has embedding rank: 0\n",
      "[NeMo I 2023-07-26 22:02:45 tokenizer_utils:191] Getting SentencePiece with model: /tmp/nvflare/bionemo/embeddings/simulate_job/app_site-1/models/vocab/protein_sequence_sentencepiece.model\n",
      "[NeMo I 2023-07-26 22:02:45 megatron_base_model:229] Padded vocab_size: 128, original vocab_size: 30, dummy tokens: 98.\n",
      "[NeMo I 2023-07-26 22:02:45 nlp_overrides:396] Model ESM1nvModel was successfully restored from /tmp/nvflare/bionemo/embeddings/simulate_job/app_site-1/models/esm1nv.nemo.\n",
      "[NeMo I 2023-07-26 22:02:45 utils:338] DDP is not initialized. Initializing...\n",
      "2023-07-26 22:02:45,631 - lightning_fabric.utilities.distributed - INFO - Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\n",
      "2023-07-26 22:02:45,638 - lightning_fabric.utilities.distributed - INFO - Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\n",
      "2023-07-26 22:02:45,643 - pytorch_lightning.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 2 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-07-26 22:02:45 modelPT:245] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
      "I0726 22:02:45.631522 140246922557184 distributed.py:244] Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0726 22:02:45.638794 140174512092928 distributed.py:244] Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\n",
      "I0726 22:02:45.643024 140246922557184 distributed.py:248] ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 2 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo W 2023-07-26 22:02:45 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel/utils.py:81: UserWarning: This function is only for unittest\n",
      "      warnings.warn(\"This function is only for unittest\")\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-07-26 22:02:45 text_memmap_dataset:104] Building data files\n",
      "[NeMo I 2023-07-26 22:02:45 text_memmap_dataset:343] Processing 1 data files using 6 workers\n",
      "[NeMo I 2023-07-26 22:02:45 text_memmap_dataset:349] Time building 0 / 1 mem-mapped files: 0:00:00.165732\n",
      "[NeMo I 2023-07-26 22:02:46 text_memmap_dataset:114] Loading data files\n",
      "[NeMo I 2023-07-26 22:02:46 text_memmap_dataset:205] Loading /tmp/data/FLIP/secondary_structure/test/x000.csv\n",
      "[NeMo I 2023-07-26 22:02:46 text_memmap_dataset:117] Time loading 1 mem-mapped files: 0:00:00.002323\n",
      "[NeMo I 2023-07-26 22:02:46 text_memmap_dataset:121] Computing global indices\n",
      "[NeMo I 2023-07-26 22:02:46 mapped_dataset:206] Filtered out (ignored) 24 samples ( 340 / 364 )\n",
      "2023-07-26 22:02:46,773 - pytorch_lightning.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "2023-07-26 22:02:46,773 - pytorch_lightning.accelerators.cuda - INFO - LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Predicting: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0726 22:02:46.773807 140246922557184 cuda.py:58] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "I0726 22:02:46.773926 140174512092928 cuda.py:58] LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 3/3 [00:04<00:00,  1.40s/it]\n",
      "%%%%%% Saving 680 samples to output_fname = /tmp/data/FLIP/secondary_structure/test/x000.pkl\n",
      "2023-07-26 22:02:54,157 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-1, peer_run=simulate_job]: got result from client site-1 for task: name=bionemo_inference, id=0e14097a-d4cd-4400-9c36-fff8ca30daf7\n",
      "2023-07-26 22:02:54,160 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-1, peer_run=simulate_job, peer_rc=OK, task_name=bionemo_inference, task_id=0e14097a-d4cd-4400-9c36-fff8ca30daf7]: finished processing client result by share_config\n",
      "2023-07-26 22:02:54,163 - SubmitUpdateCommand - INFO - submit_update process. client_name:site-1   task_id:0e14097a-d4cd-4400-9c36-fff8ca30daf7\n",
      "2023-07-26 22:02:54,344 - BioNeMoInference - INFO - [identity=simulator_server, run=simulate_job, wf=share_config]: task bionemo_inference exit with status TaskCompletionStatus.OK\n",
      "2023-07-26 22:02:54,383 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config]: Workflow: share_config finalizing ...\n",
      "2023-07-26 22:02:54,549 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config]: ABOUT_TO_END_RUN fired\n",
      "2023-07-26 22:02:54,552 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config]: END_RUN fired\n",
      "2023-07-26 22:02:54,554 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config]: Server runner finished.\n",
      "2023-07-26 22:02:55,699 - SimulatorServer - INFO - Server app stopped.\n",
      "\n",
      "\n",
      "2023-07-26 22:02:56,157 - nvflare.fuel.hci.server.hci - INFO - Admin Server localhost on Port 45799 shutdown!\n",
      "2023-07-26 22:02:56,160 - SimulatorServer - INFO - shutting down server\n",
      "2023-07-26 22:02:56,162 - SimulatorServer - INFO - canceling sync locks\n",
      "2023-07-26 22:02:56,165 - SimulatorServer - INFO - server off\n",
      "2023-07-26 22:02:56,178 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config, peer=site-1, peer_run=simulate_job]: server runner is finalizing - asked client to end the run\n",
      "2023-07-26 22:02:56,181 - GetTaskCommand - INFO - return task to client.  client_name: site-1  task_name: __end_run__   task_id:   sharable_header_task_id: \n",
      "2023-07-26 22:02:56,187 - FederatedClient - INFO - Shutting down client run: site-1\n",
      "2023-07-26 22:02:56,189 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=share_config]: asked to abort - triggered abort_signal to stop the RUN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torch.distributed.elastic.agent.server.api:Received 15 death signal, shutting down workers\n",
      "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 9180 closing signal SIGTERM\n",
      "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 9181 closing signal SIGTERM\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py\", line 783, in <module>\n",
      "    main()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 346, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py\", line 779, in main\n",
      "    run(args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py\", line 770, in run\n",
      "    elastic_launch(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py\", line 134, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py\", line 241, in launch_agent\n",
      "    result = agent.run()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/elastic/metrics/api.py\", line 129, in wrapper\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 723, in run\n",
      "    result = self._invoke_run(role)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 864, in _invoke_run\n",
      "    time.sleep(monitor_interval)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 62, in _terminate_process_handler\n",
      "    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\n",
      "torch.distributed.elastic.multiprocessing.api.SignalException: Process 9165 got signal: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-26 22:02:59,627 - MPM - INFO - MPM: Good Bye!\n",
      "Simulator finished with run_status 0\n"
     ]
    }
   ],
   "source": [
    "from nvflare import SimulatorRunner    \n",
    "\n",
    "simulator = SimulatorRunner(\n",
    "    job_folder=\"jobs/embeddings\",\n",
    "    workspace=\"/tmp/nvflare/bionemo/embeddings\",\n",
    "    n_clients=1,\n",
    "    threads=1\n",
    ")\n",
    "run_status = simulator.run()\n",
    "print(\"Simulator finished with run_status\", run_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d21580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2529982",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
