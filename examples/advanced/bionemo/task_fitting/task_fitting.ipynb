{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2bd8aed",
   "metadata": {},
   "source": [
    "# Federated Protein Embeddings and Task Model Fitting with BioNeMo\n",
    "\n",
    "This example notebook shows how to obtain protein learned representations in the form of embeddings using the ESM-1nv pre-trained model. The model is trained with NVIDIA's BioNeMo framework for Large Language Model training and inference. For more details, please visit NVIDIA BioNeMo Service at https://www.nvidia.com/en-us/gpu-cloud/bionemo.\n",
    "\n",
    "This notebook will walk you through the task fitting workflow in the following sections:\n",
    "\n",
    "* \n",
    "*\n",
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e39085",
   "metadata": {},
   "source": [
    "### Install requirements\n",
    "Let's start by installing and importing library dependencies. We'll use requests to interact with the BioNeMo service, BioPython to parse FASTA sequences into SeqRecord objects, scikit-learn for classification tasks, and matplotlib for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5dd56a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting nvflare\n",
      "  Downloading nvflare-2.3.2-py3-none-any.whl (862 kB)\n",
      "\u001b[K     |████████████████████████████████| 862 kB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting biopython\n",
      "  Downloading biopython-1.81-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 7.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (3.4.3)\n",
      "Collecting grpcio==1.51.1\n",
      "  Downloading grpcio-1.51.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.8 MB 6.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Flask-SQLAlchemy==2.5.1\n",
      "  Downloading Flask_SQLAlchemy-2.5.1-py2.py3-none-any.whl (17 kB)\n",
      "Collecting Flask-JWT-Extended==4.4.3\n",
      "  Downloading Flask_JWT_Extended-4.4.3-py2.py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: psutil>=5.9.1 in /usr/local/lib/python3.8/dist-packages (from nvflare->-r requirements.txt (line 1)) (5.9.4)\n",
      "Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.8/dist-packages (from nvflare->-r requirements.txt (line 1)) (3.20.3)\n",
      "Requirement already satisfied: requests>=2.28.0 in /usr/local/lib/python3.8/dist-packages (from nvflare->-r requirements.txt (line 1)) (2.28.2)\n",
      "Collecting gunicorn>=20.1.0\n",
      "  Downloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
      "\u001b[K     |████████████████████████████████| 80 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cryptography>=36.0.0\n",
      "  Downloading cryptography-41.0.2-cp37-abi3-manylinux_2_28_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Flask==2.2.5 in /usr/local/lib/python3.8/dist-packages (from nvflare->-r requirements.txt (line 1)) (2.2.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from nvflare->-r requirements.txt (line 1)) (1.22.2)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.8/dist-packages (from nvflare->-r requirements.txt (line 1)) (11.0.3)\n",
      "Collecting PyYAML>=6.0\n",
      "  Downloading PyYAML-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (736 kB)\n",
      "\u001b[K     |████████████████████████████████| 736 kB 5.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: msgpack>=1.0.3 in /usr/local/lib/python3.8/dist-packages (from nvflare->-r requirements.txt (line 1)) (1.0.4)\n",
      "Collecting docker>=6.0\n",
      "  Downloading docker-6.1.3-py3-none-any.whl (148 kB)\n",
      "\u001b[K     |████████████████████████████████| 148 kB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting SQLAlchemy==1.4.31\n",
      "  Downloading SQLAlchemy-1.4.31-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from nvflare->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.8/dist-packages (from Flask==2.2.5->nvflare->-r requirements.txt (line 1)) (2.3.4)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.8/dist-packages (from Flask==2.2.5->nvflare->-r requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.8/dist-packages (from Flask==2.2.5->nvflare->-r requirements.txt (line 1)) (8.0.2)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from Flask==2.2.5->nvflare->-r requirements.txt (line 1)) (6.0.0)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.8/dist-packages (from Flask==2.2.5->nvflare->-r requirements.txt (line 1)) (2.1.2)\n",
      "Collecting PyJWT<3.0,>=2.0\n",
      "  Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from SQLAlchemy==1.4.31->nvflare->-r requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (1.6.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (3.1.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 4)) (9.3.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 4)) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 4)) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=36.0.0->nvflare->-r requirements.txt (line 1)) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=36.0.0->nvflare->-r requirements.txt (line 1)) (2.21)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-1.6.1-py3-none-any.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=14.0 in /usr/local/lib/python3.8/dist-packages (from docker>=6.0->nvflare->-r requirements.txt (line 1)) (23.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.8/dist-packages (from docker>=6.0->nvflare->-r requirements.txt (line 1)) (1.26.14)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=3.6.0->Flask==2.2.5->nvflare->-r requirements.txt (line 1)) (3.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from Jinja2>=3.0->Flask==2.2.5->nvflare->-r requirements.txt (line 1)) (2.1.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.28.0->nvflare->-r requirements.txt (line 1)) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.28.0->nvflare->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.28.0->nvflare->-r requirements.txt (line 1)) (3.1.0)\n",
      "Installing collected packages: websocket-client, SQLAlchemy, PyJWT, PyYAML, gunicorn, grpcio, Flask-SQLAlchemy, Flask-JWT-Extended, docker, cryptography, nvflare, biopython\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 1.4.23\n",
      "    Uninstalling SQLAlchemy-1.4.23:\n",
      "      Successfully uninstalled SQLAlchemy-1.4.23\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 5.4.1\n",
      "    Uninstalling PyYAML-5.4.1:\n",
      "      Successfully uninstalled PyYAML-5.4.1\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.51.3\n",
      "    Uninstalling grpcio-1.51.3:\n",
      "      Successfully uninstalled grpcio-1.51.3\n",
      "Successfully installed Flask-JWT-Extended-4.4.3 Flask-SQLAlchemy-2.5.1 PyJWT-2.8.0 PyYAML-6.0.1 SQLAlchemy-1.4.31 biopython-1.81 cryptography-41.0.2 docker-6.1.3 grpcio-1.51.1 gunicorn-21.2.0 nvflare-2.3.2 websocket-client-1.6.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa330b20",
   "metadata": {},
   "source": [
    "### Obtaining the protein embeddings using the BioNeMo ESM-1nv model\n",
    "Using BioNeMo, users can obtain numerical vector representations of protein sequences called embeddings. Protein embeddings can then be used for visualization or making downstream predictions.\n",
    "\n",
    "Here we are interested in training a neural network to predict subcellular location from an embedding.\n",
    "\n",
    "The data we will be using comes from the paper [Light attention predicts protein location from the language of life](https://academic.oup.com/bioinformaticsadvances/article/1/1/vbab035/6432029) by Stärk et al. In this paper, the authors developed a machine learning algorithm to predict the subcellular location of proteins from sequence through protein langage models that are similar to those hosted by BioNeMo. Protein subcellular location refers to where the protein localizes in the cell, for example a protein my be expressed in the Nucleus or in the Cytoplasm. Knowing where proteins localize can provide insights into the underlying mechanisms of cellular processes and help identify potential targets for drug development. The following image includes a few examples of subcellular locations in an animal cell:\n",
    "\n",
    "\n",
    "(Image freely available at https://pixabay.com/images/id-48542)\n",
    "\n",
    "### Dataset sourcing\n",
    "For our target input sequences, we will point to FASTA sequences in a benchmark dataset called Fitness Landscape Inference for Proteins (FLIP). FLIP encompasses experimental data across adeno-associated virus stability for gene therapy, protein domain B1 stability and immunoglobulin binding, and thermostability from multiple protein families."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb6dd1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example protein dataset location\n",
    "fasta_url= \"http://data.bioembeddings.com/public/FLIP/fasta/scl/mixed_soft.fasta\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd76dfc3",
   "metadata": {},
   "source": [
    "First, we define the source of example protein dataset with the FASTA sequences. This data follows the [biotrainer](https://github.com/sacdallago/biotrainer/blob/main/docs/data_standardization.md) standard, so it includes information about the class in the FASTA header, and the protein sequence. Here are two example sequences in this file:\n",
    "\n",
    "```\n",
    ">Sequence1 TARGET=Cell_membrane SET=train VALIDATION=False\n",
    "MMKTLSSGNCTLNVPAKNSYRMVVLGASRVGKSSIVSRFLNGRFEDQYTPTIEDFHRKVYNIHGDMYQLDILDTSGNHPFPAM\n",
    "RRLSILTGDVFILVFSLDSRESFDEVKRLQKQILEVKSCLKNKTKEAAELPMVICGNKNDHSELCRQVPAMEAELLVSGDENC\n",
    "AYFEVSAKKNTNVNEMFYVLFSMAKLPHEMSPALHHKISVQYGDAFHPRPFCMRRTKVAGAYGMVSPFARRPSVNSDLKYIKA\n",
    "KVLREGQARERDKCSIQ\n",
    ">Sequence4833 TARGET=Nucleus SET=train VALIDATION=False\n",
    "MARTKQTARKSTGGKAPRKQLATKAARKSAPATGGVKKPHRFRPGTVALREIRKYQKSTELLIRKLPFQRLVREIAQDFKTDL\n",
    "RFQSSAVAALQEAAEAYLVGLFEDTNLCAIHAKRVTIMPKDIQLARRIRGERA\n",
    "Note the following attributes in the FASTA header:\n",
    "```\n",
    "\n",
    "* `TARGET` attribute holds the subcellular location classification for the sequence, for instance Cell_membrane and Nucleus. This dataset includes a total of ten subcellelular location classes -- more on that below.\n",
    "* `SET` attribute defines whether the sequence should be used for training (train) or testing (test)\n",
    "* `VALIDATION` attribute defines whether the sequence should be used for validation (all sequences where this is True are also in set=train)\n",
    "\n",
    "### Downloading the protein sequences and subcellular location annotations\n",
    "In this step we download the FASTA file defined above and parse the sequences into a list of BioPython SeqRecord objects.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cd63a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 13949 sequences\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import requests\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Download the FASTA file from FLIP: https://github.com/J-SNACKKB/FLIP/tree/main/splits/scl\n",
    "fasta_content = requests.get(fasta_url, headers={\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x86)'\n",
    "}).content.decode('utf-8')\n",
    "fasta_stream = io.StringIO(fasta_content)\n",
    "\n",
    "# Obtain a list of SeqRecords/proteins which contain sequence and attributes\n",
    "# from the FASTA header\n",
    "proteins = list(SeqIO.parse(fasta_stream, \"fasta\"))\n",
    "print(f\"Downloaded {len(proteins)} sequences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8954e6d2",
   "metadata": {},
   "source": [
    "### Data splitting\n",
    "Next, we prepare the data for simulating federated learning using `n_clients`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2861e188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 8619 valid sequences.\n",
      "Saving 2873 training sequences for client site-1.\n",
      "Saving 2873 training sequences for client site-2.\n",
      "Saving 2873 training sequences for client site-3.\n"
     ]
    }
   ],
   "source": [
    "n_clients = 3\n",
    "# limiting to the proteins with sequence length<512 for embedding queries\n",
    "MAX_SEQUENCE_LEN = 512\n",
    "seed=0\n",
    "out_dir = \"/tmp/fasta/mixed_soft\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import random\n",
    "random.seed(seed)\n",
    "        \n",
    "# extract meta data and split\n",
    "data = []\n",
    "for i, x in enumerate(proteins):\n",
    "        if len(str(x.seq)) > MAX_SEQUENCE_LEN:\n",
    "            continue\n",
    "            \n",
    "        entry = {key: value for key, value in re.findall(r\"([A-Z_]+)=(-?[A-z0-9]+[.0-9]*)\", x.description)}\n",
    "        entry[\"sequence\"] = str(x.seq)\n",
    "        entry[\"id\"] = str(i)\n",
    "    \n",
    "        data.append(entry)\n",
    "        \n",
    "print(f\"Read {len(data)} valid sequences.\")\n",
    "        \n",
    "# shuffle & split training data\n",
    "random.shuffle(data)\n",
    "data_splits = np.array_split(data, n_clients)\n",
    "\n",
    "# save split data\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "# save split training data\n",
    "for idx, split in enumerate(data_splits):\n",
    "    client_name = f\"site-{idx+1}\"\n",
    "    \n",
    "    split_dict = {}\n",
    "    for entry in split:\n",
    "        for k, v in entry.items():\n",
    "            if k not in split_dict:\n",
    "                split_dict[k] = []\n",
    "            else:\n",
    "                split_dict[k].append(v)\n",
    "\n",
    "    df = pd.DataFrame(split_dict)\n",
    "    df.to_csv(os.path.join(out_dir, f\"data_{client_name}.csv\"), index=False, columns=[\"id\", \"sequence\", \"TARGET\", \"SET\"])    \n",
    "    print(f\"Saving {len(split)} training sequences for client {client_name}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0328d552",
   "metadata": {},
   "source": [
    "### Federated embedding extraction\n",
    "Running inference of the ESM-1nv model to extract embeddings requires a GPU with at least 12 GB memory. Here we run inference on each client sequentially using one thread to preserve GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "856b653d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-31 18:47:49,048 - SimulatorRunner - INFO - Create the Simulator Server.\n",
      "2023-07-31 18:47:49,053 - Cell - INFO - server: creating listener on tcp://0:49501\n",
      "2023-07-31 18:47:49,075 - Cell - INFO - server: created backbone external listener for tcp://0:49501\n",
      "2023-07-31 18:47:49,077 - ConnectorManager - INFO - 550: Try start_listener Listener resources: {'secure': False, 'host': 'localhost'}\n",
      "2023-07-31 18:47:49,079 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00002 PASSIVE tcp://0:23551] is starting\n",
      "2023-07-31 18:47:49,581 - Cell - INFO - server: created backbone internal listener for tcp://localhost:23551\n",
      "2023-07-31 18:47:49,584 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 PASSIVE tcp://0:49501] is starting\n",
      "2023-07-31 18:47:49,675 - nvflare.fuel.hci.server.hci - INFO - Starting Admin Server localhost on Port 53069\n",
      "2023-07-31 18:47:49,677 - SimulatorRunner - INFO - Deploy the Apps.\n",
      "2023-07-31 18:47:50,442 - SimulatorRunner - INFO - Create the simulate clients.\n",
      "2023-07-31 18:47:50,450 - ClientManager - INFO - Client: New client site-1@192.168.0.25 joined. Sent token: 33998989-f6b6-4ea8-b533-228a46f63c3f.  Total clients: 1\n",
      "2023-07-31 18:47:50,452 - FederatedClient - INFO - Successfully registered client:site-1 for project simulator_server. Token:33998989-f6b6-4ea8-b533-228a46f63c3f SSID:\n",
      "2023-07-31 18:47:50,467 - ClientManager - INFO - Client: New client site-2@192.168.0.25 joined. Sent token: 26716c36-75c3-405f-a61d-ddeeac748221.  Total clients: 2\n",
      "2023-07-31 18:47:50,470 - FederatedClient - INFO - Successfully registered client:site-2 for project simulator_server. Token:26716c36-75c3-405f-a61d-ddeeac748221 SSID:\n",
      "2023-07-31 18:47:50,482 - ClientManager - INFO - Client: New client site-3@192.168.0.25 joined. Sent token: 07064b6a-bec0-4641-bac6-e546fbc63c4b.  Total clients: 3\n",
      "2023-07-31 18:47:50,484 - FederatedClient - INFO - Successfully registered client:site-3 for project simulator_server. Token:07064b6a-bec0-4641-bac6-e546fbc63c4b SSID:\n",
      "2023-07-31 18:47:50,487 - SimulatorRunner - INFO - Set the client status ready.\n",
      "2023-07-31 18:47:50,488 - SimulatorRunner - INFO - Deploy and start the Server App.\n",
      "2023-07-31 18:47:50,501 - ServerCommandAgent - INFO - ServerCommandAgent cell register_request_cb: server.simulate_job\n",
      "2023-07-31 18:47:52,808 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmpielg9hp4\n",
      "2023-07-31 18:47:52,809 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmpielg9hp4/_remote_module_non_scriptable.py\n",
      "2023-07-31 18:47:53,570 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job]: Server runner starting ...\n",
      "2023-07-31 18:47:53,573 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job]: starting workflow bionemo_inference (<class 'bionemo_inference.BioNeMoInference'>) ...\n",
      "2023-07-31 18:47:53,575 - BioNeMoInference - INFO - [identity=simulator_server, run=simulate_job]: Initializing BroadcastAndProcess.\n",
      "2023-07-31 18:47:53,577 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job]: Workflow bionemo_inference (<class 'bionemo_inference.BioNeMoInference'>) started\n",
      "2023-07-31 18:47:53,611 - BioNeMoInferenceProcessor - INFO - [identity=simulator_server, run=simulate_job, wf=bionemo_inference]: Load model configuration from /tmp/nvflare/bionemo/embeddings/simulate_job/app_server/config/base_infer_config.yaml and /tmp/nvflare/bionemo/embeddings/simulate_job/app_server/config/infer.yaml\n",
      "2023-07-31 18:47:53,613 - BioNeMoInference - INFO - [identity=simulator_server, run=simulate_job, wf=bionemo_inference]: scheduled task bionemo_inference\n",
      "2023-07-31 18:47:54,499 - SimulatorClientRunner - INFO - Start the clients run simulation.\n",
      "2023-07-31 18:47:55,504 - SimulatorClientRunner - INFO - Simulate Run client: site-1 on GPU group: None\n",
      "2023-07-31 18:47:56,570 - ClientTaskWorker - INFO - ClientTaskWorker started to run\n",
      "2023-07-31 18:47:56,645 - Cell - INFO - site-1.simulate_job: created backbone external connector to tcp://localhost:49501\n",
      "2023-07-31 18:47:56,645 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 ACTIVE tcp://localhost:49501] is starting\n",
      "2023-07-31 18:47:59,400 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmppk3w7mtm\n",
      "2023-07-31 18:47:59,400 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmppk3w7mtm/_remote_module_non_scriptable.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-07-31 18:48:06 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-07-31 18:48:07 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-31 18:48:07,608 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=bionemo_inference, peer=site-1, peer_run=simulate_job, task_name=bionemo_inference, task_id=f2ecc5f2-e0c4-45fa-b014-3d9d699b5324]: assigned task to client site-1: name=bionemo_inference, id=f2ecc5f2-e0c4-45fa-b014-3d9d699b5324\n",
      "2023-07-31 18:48:07,611 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=bionemo_inference, peer=site-1, peer_run=simulate_job, task_name=bionemo_inference, task_id=f2ecc5f2-e0c4-45fa-b014-3d9d699b5324]: sent task assignment to client. client_name:site-1 task_id:f2ecc5f2-e0c4-45fa-b014-3d9d699b5324\n",
      "2023-07-31 18:48:07,614 - GetTaskCommand - INFO - return task to client.  client_name: site-1  task_name: bionemo_inference   task_id: f2ecc5f2-e0c4-45fa-b014-3d9d699b5324  sharable_header_task_id: f2ecc5f2-e0c4-45fa-b014-3d9d699b5324\n",
      "[NeMo I 2023-07-31 18:48:07 utils:250] Restoring model from /tmp/nvflare/bionemo/embeddings/simulate_job/app_site-1/models/esm1nv.nemo\n",
      "[NeMo I 2023-07-31 18:48:07 utils:254] Loading model class: bionemo.model.protein.esm1nv.esm1nv_model.ESM1nvModel\n",
      "2023-07-31 18:48:07,727 - pytorch_lightning.utilities.rank_zero - INFO - GPU available: True (cuda), used: True\n",
      "2023-07-31 18:48:07,728 - pytorch_lightning.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores\n",
      "2023-07-31 18:48:07,728 - pytorch_lightning.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs\n",
      "2023-07-31 18:48:07,728 - pytorch_lightning.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2023-07-31 18:48:07 exp_manager:374] Experiments will be logged at /tmp/nvflare/bionemo/embeddings/simulate_job/app_site-1/nemo_experiments/ESM1nv_Inference/2023-07-31_18-48-07\n",
      "[NeMo I 2023-07-31 18:48:07 exp_manager:797] TensorboardLogger has been set up\n",
      "[NeMo I 2023-07-31 18:48:07 utils:234] \n",
      "    \n",
      "    ************** Trainer configuration ***********\n",
      "[NeMo I 2023-07-31 18:48:07 utils:235] \n",
      "    name: ESM1nv_Inference\n",
      "    desc: Minimum configuration for initializing a ESM1nv model for inference.\n",
      "    trainer:\n",
      "      precision: 16\n",
      "      devices: 1\n",
      "      num_nodes: 1\n",
      "      accelerator: gpu\n",
      "      logger: null\n",
      "      accumulate_grad_batches: 1\n",
      "    exp_manager:\n",
      "      explicit_log_dir: null\n",
      "      exp_dir: null\n",
      "      name: ${name}\n",
      "      create_checkpoint_callback: false\n",
      "    model:\n",
      "      micro_batch_size: 370\n",
      "      tensor_model_parallel_size: 1\n",
      "      pipeline_model_parallel_size: 1\n",
      "      seq_length: 512\n",
      "      max_position_embeddings: 512\n",
      "      num_layers: 6\n",
      "      hidden_size: 768\n",
      "      ffn_hidden_size: 3072\n",
      "      num_attention_heads: 12\n",
      "      init_method_std: 0.02\n",
      "      hidden_dropout: 0.1\n",
      "      kv_channels: null\n",
      "      apply_query_key_layer_scaling: true\n",
      "      layernorm_epsilon: 1.0e-05\n",
      "      make_vocab_size_divisible_by: 128\n",
      "      pre_process: true\n",
      "      post_process: false\n",
      "      bert_binary_head: false\n",
      "      resume_from_checkpoint: null\n",
      "      masked_softmax_fusion: true\n",
      "      tokenizer:\n",
      "        library: sentencepiece\n",
      "        type: null\n",
      "        model: nemo:08a2085a60b3411fad6b6ff6bd6ae525_tokenizer_protein.sp.30.model\n",
      "        vocab_file: nemo:70960ca328a54437ba8e161f6404bc8b_tokenizer_protein.sp.30.vocab\n",
      "        merge_file: null\n",
      "        vocab_path: /tmp/nvflare/bionemo/embeddings/simulate_job/app_site-1/models/vocab/protein_sequence.vocab\n",
      "        model_path: /tmp/nvflare/bionemo/embeddings/simulate_job/app_site-1/models/vocab/protein_sequence_sentencepiece.model\n",
      "      native_amp_init_scale: 4294967296\n",
      "      native_amp_growth_interval: 1000\n",
      "      fp32_residual_connection: false\n",
      "      fp16_lm_cross_entropy: false\n",
      "      seed: 1234\n",
      "      use_cpu_initialization: false\n",
      "      onnx_safe: false\n",
      "      activations_checkpoint_method: null\n",
      "      activations_checkpoint_num_layers: 1\n",
      "      data:\n",
      "        dataset_path: /tmp/fasta/mixed_soft\n",
      "        dataset:\n",
      "          train: x[000..049]\n",
      "          test: x[000..049]\n",
      "          val: x[000..049]\n",
      "        newline_int: 10\n",
      "        header_lines: 1\n",
      "        data_col: 3\n",
      "        data_sep: ','\n",
      "        sort_dataset_paths: true\n",
      "        skip_lines: 0\n",
      "        micro_batch_size: 370\n",
      "        encoder_augment: false\n",
      "        encoder_mask: false\n",
      "        decoder_augment: false\n",
      "        decoder_mask: false\n",
      "        canonicalize_input: true\n",
      "        dataloader_type: single\n",
      "        drop_last: false\n",
      "        pin_memory: false\n",
      "        num_workers: 4\n",
      "        data_prefix: ''\n",
      "        index_mapping_dir: null\n",
      "        data_impl: ''\n",
      "        splits_string: 900,50,50\n",
      "        skip_warmup: true\n",
      "        reset_position_ids: false\n",
      "        reset_attention_mask: false\n",
      "        eod_mask_loss: false\n",
      "        masked_lm_prob: 0.15\n",
      "        short_seq_prob: 0.1\n",
      "        dataset_format: csv\n",
      "        seed: 1234\n",
      "        max_seq_length: 512\n",
      "        batch_size: 128\n",
      "        output_fname: ''\n",
      "        data_fields_map:\n",
      "          sequence: sequence\n",
      "          id: id\n",
      "        data_impl_kwargs:\n",
      "          csv_fields_mmap:\n",
      "            newline_int: 10\n",
      "            header_lines: 1\n",
      "            workers: null\n",
      "            sort_dataset_paths: false\n",
      "            data_sep: ','\n",
      "            data_fields:\n",
      "              id: 0\n",
      "              sequence: 1\n",
      "          fasta_fields_mmap:\n",
      "            data_fields:\n",
      "              id: 0\n",
      "              sequence: 1\n",
      "      optim:\n",
      "        name: fused_adam\n",
      "        lr: 0.0002\n",
      "        weight_decay: 0.01\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.98\n",
      "        sched:\n",
      "          name: CosineAnnealing\n",
      "          warmup_steps: 500\n",
      "          constant_steps: 50000\n",
      "          min_lr: 2.0e-05\n",
      "      precision: 16\n",
      "      downstream_task:\n",
      "        restore_from_path: /tmp/nvflare/bionemo/embeddings/simulate_job/app_site-1/models/esm1nv.nemo\n",
      "        outputs:\n",
      "        - embeddings\n",
      "        - hiddens\n",
      "      global_batch_size: 370\n",
      "    target: bionemo.model.protein.esm1nv.esm1nv_model.ESM1nvModel\n",
      "    infer_target: bionemo.model.protein.esm1nv.infer.ESM1nvInference\n",
      "    formatters:\n",
      "      simple:\n",
      "        format: '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'\n",
      "    handlers:\n",
      "      console:\n",
      "        class: logging.StreamHandler\n",
      "        formatter: simple\n",
      "        stream: ext://sys.stdout\n",
      "      file:\n",
      "        class: logging.FileHandler\n",
      "        formatter: simple\n",
      "        filename: /logs/inference.log\n",
      "    root:\n",
      "      level: INFO\n",
      "      handlers:\n",
      "      - console\n",
      "    disable_existing_loggers: false\n",
      "    defaults:\n",
      "    - base_infer_config\n",
      "    - _self_\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-07-31 18:48:07 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/plugins/precision/native_amp.py:131: LightningDeprecationWarning: The `NativeMixedPrecisionPlugin` class has been renamed in v1.9.0 and will be removed in v2.0.0. Please use `pytorch_lightning.plugins.MixedPrecisionPlugin` instead.\n",
      "      rank_zero_deprecation(\n",
      "    \n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0731 18:48:07.727596 139945031272256 setup.py:163] GPU available: True (cuda), used: True\n",
      "I0731 18:48:07.728082 139945031272256 setup.py:166] TPU available: False, using: 0 TPU cores\n",
      "I0731 18:48:07.728196 139945031272256 setup.py:169] IPU available: False, using: 0 IPUs\n",
      "I0731 18:48:07.728281 139945031272256 setup.py:172] HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-07-31 18:48:08 megatron_init:231] Rank 0 has data parallel group: [0]\n",
      "[NeMo I 2023-07-31 18:48:08 megatron_init:234] All data parallel group ranks: [[0]]\n",
      "[NeMo I 2023-07-31 18:48:08 megatron_init:235] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2023-07-31 18:48:08 megatron_init:243] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2023-07-31 18:48:08 megatron_init:244] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-07-31 18:48:08 megatron_init:254] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2023-07-31 18:48:08 megatron_init:258] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-07-31 18:48:08 megatron_init:259] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2023-07-31 18:48:08 megatron_init:273] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2023-07-31 18:48:08 megatron_init:285] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2023-07-31 18:48:08 megatron_init:291] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-07-31 18:48:08 megatron_init:292] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2023-07-31 18:48:08 megatron_init:293] All embedding group ranks: [[0]]\n",
      "[NeMo I 2023-07-31 18:48:08 megatron_init:294] Rank 0 has embedding rank: 0\n",
      "[NeMo I 2023-07-31 18:48:08 tokenizer_utils:191] Getting SentencePiece with model: /tmp/tmpnmik61n3/08a2085a60b3411fad6b6ff6bd6ae525_tokenizer_protein.sp.30.model\n",
      "[NeMo I 2023-07-31 18:48:08 megatron_base_model:229] Padded vocab_size: 128, original vocab_size: 30, dummy tokens: 98.\n",
      "[NeMo I 2023-07-31 18:48:08 nlp_overrides:396] Model ESM1nvModel was successfully restored from /tmp/nvflare/bionemo/embeddings/simulate_job/app_site-1/models/esm1nv.nemo.\n",
      "[NeMo I 2023-07-31 18:48:08 utils:338] DDP is not initialized. Initializing...\n",
      "2023-07-31 18:48:08,294 - lightning_fabric.utilities.distributed - INFO - Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "2023-07-31 18:48:08,296 - pytorch_lightning.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2023-07-31 18:48:08 text_memmap_dataset:104] Building data files\n",
      "[NeMo I 2023-07-31 18:48:08 text_memmap_dataset:343] Processing 1 data files using 6 workers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-07-31 18:48:08 modelPT:245] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
      "I0731 18:48:08.294756 139945031272256 distributed.py:244] Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "I0731 18:48:08.296262 139945031272256 distributed.py:248] ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo W 2023-07-31 18:48:08 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel/utils.py:81: UserWarning: This function is only for unittest\n",
      "      warnings.warn(\"This function is only for unittest\")\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-07-31 18:48:08 text_memmap_dataset:315] Building indexing for fn = /tmp/fasta/mixed_soft/data_site-1.csv\n",
      "[NeMo I 2023-07-31 18:48:08 text_memmap_dataset:327] Saving idx file = /tmp/fasta/mixed_soft/data_site-1.csv.idx.npy\n",
      "[NeMo I 2023-07-31 18:48:08 text_memmap_dataset:329] Saving metadata file = /tmp/fasta/mixed_soft/data_site-1.csv.idx.info\n",
      "[NeMo I 2023-07-31 18:48:08 text_memmap_dataset:349] Time building 1 / 1 mem-mapped files: 0:00:00.158976\n",
      "[NeMo I 2023-07-31 18:48:09 text_memmap_dataset:114] Loading data files\n",
      "[NeMo I 2023-07-31 18:48:09 text_memmap_dataset:205] Loading /tmp/fasta/mixed_soft/data_site-1.csv\n",
      "[NeMo I 2023-07-31 18:48:09 text_memmap_dataset:117] Time loading 1 mem-mapped files: 0:00:00.002510\n",
      "[NeMo I 2023-07-31 18:48:09 text_memmap_dataset:121] Computing global indices\n",
      "[NeMo I 2023-07-31 18:48:09 mapped_dataset:206] Filtered out (ignored) 10 samples ( 2862 / 2872 )\n",
      "2023-07-31 18:48:09,958 - pytorch_lightning.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Predicting: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0731 18:48:09.958788 139945031272256 cuda.py:58] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 23/23 [00:28<00:00,  1.24s/it]2023-07-31 18:48:43,543 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=bionemo_inference, peer=site-1, peer_run=simulate_job]: got result from client site-1 for task: name=bionemo_inference, id=f2ecc5f2-e0c4-45fa-b014-3d9d699b5324\n",
      "2023-07-31 18:48:43,546 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=bionemo_inference, peer=site-1, peer_run=simulate_job, peer_rc=OK, task_name=bionemo_inference, task_id=f2ecc5f2-e0c4-45fa-b014-3d9d699b5324]: finished processing client result by bionemo_inference\n",
      "2023-07-31 18:48:43,549 - SubmitUpdateCommand - INFO - submit_update process. client_name:site-1   task_id:f2ecc5f2-e0c4-45fa-b014-3d9d699b5324\n",
      "2023-07-31 18:48:43,554 - SimulatorClientRunner - INFO - Simulate Run client: site-2 on GPU group: None\n",
      "2023-07-31 18:48:45,613 - ClientTaskWorker - INFO - ClientTaskWorker started to run\n",
      "2023-07-31 18:48:45,689 - Cell - INFO - site-2.simulate_job: created backbone external connector to tcp://localhost:49501\n",
      "2023-07-31 18:48:45,690 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 ACTIVE tcp://localhost:49501] is starting\n",
      "2023-07-31 18:48:48,509 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmp2z86gz0n\n",
      "2023-07-31 18:48:48,509 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmp2z86gz0n/_remote_module_non_scriptable.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-07-31 18:48:56 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-31 18:48:57,238 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=bionemo_inference, peer=site-2, peer_run=simulate_job, task_name=bionemo_inference, task_id=f4f92557-e241-439a-be29-cfca2ea16fbd]: assigned task to client site-2: name=bionemo_inference, id=f4f92557-e241-439a-be29-cfca2ea16fbd\n",
      "2023-07-31 18:48:57,242 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=bionemo_inference, peer=site-2, peer_run=simulate_job, task_name=bionemo_inference, task_id=f4f92557-e241-439a-be29-cfca2ea16fbd]: sent task assignment to client. client_name:site-2 task_id:f4f92557-e241-439a-be29-cfca2ea16fbd\n",
      "2023-07-31 18:48:57,244 - GetTaskCommand - INFO - return task to client.  client_name: site-2  task_name: bionemo_inference   task_id: f4f92557-e241-439a-be29-cfca2ea16fbd  sharable_header_task_id: f4f92557-e241-439a-be29-cfca2ea16fbd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-07-31 18:48:57 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-07-31 18:48:57 utils:250] Restoring model from /tmp/nvflare/bionemo/embeddings/simulate_job/app_site-2/models/esm1nv.nemo\n",
      "[NeMo I 2023-07-31 18:48:57 utils:254] Loading model class: bionemo.model.protein.esm1nv.esm1nv_model.ESM1nvModel\n",
      "2023-07-31 18:48:57,358 - pytorch_lightning.utilities.rank_zero - INFO - GPU available: True (cuda), used: True\n",
      "2023-07-31 18:48:57,359 - pytorch_lightning.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores\n",
      "2023-07-31 18:48:57,359 - pytorch_lightning.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs\n",
      "2023-07-31 18:48:57,359 - pytorch_lightning.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2023-07-31 18:48:57 exp_manager:374] Experiments will be logged at /tmp/nvflare/bionemo/embeddings/simulate_job/app_site-2/nemo_experiments/ESM1nv_Inference/2023-07-31_18-48-57\n",
      "[NeMo I 2023-07-31 18:48:57 exp_manager:797] TensorboardLogger has been set up\n",
      "[NeMo I 2023-07-31 18:48:57 utils:234] \n",
      "    \n",
      "    ************** Trainer configuration ***********\n",
      "[NeMo I 2023-07-31 18:48:57 utils:235] \n",
      "    name: ESM1nv_Inference\n",
      "    desc: Minimum configuration for initializing a ESM1nv model for inference.\n",
      "    trainer:\n",
      "      precision: 16\n",
      "      devices: 1\n",
      "      num_nodes: 1\n",
      "      accelerator: gpu\n",
      "      logger: null\n",
      "      accumulate_grad_batches: 1\n",
      "    exp_manager:\n",
      "      explicit_log_dir: null\n",
      "      exp_dir: null\n",
      "      name: ${name}\n",
      "      create_checkpoint_callback: false\n",
      "    model:\n",
      "      micro_batch_size: 370\n",
      "      tensor_model_parallel_size: 1\n",
      "      pipeline_model_parallel_size: 1\n",
      "      seq_length: 512\n",
      "      max_position_embeddings: 512\n",
      "      num_layers: 6\n",
      "      hidden_size: 768\n",
      "      ffn_hidden_size: 3072\n",
      "      num_attention_heads: 12\n",
      "      init_method_std: 0.02\n",
      "      hidden_dropout: 0.1\n",
      "      kv_channels: null\n",
      "      apply_query_key_layer_scaling: true\n",
      "      layernorm_epsilon: 1.0e-05\n",
      "      make_vocab_size_divisible_by: 128\n",
      "      pre_process: true\n",
      "      post_process: false\n",
      "      bert_binary_head: false\n",
      "      resume_from_checkpoint: null\n",
      "      masked_softmax_fusion: true\n",
      "      tokenizer:\n",
      "        library: sentencepiece\n",
      "        type: null\n",
      "        model: nemo:08a2085a60b3411fad6b6ff6bd6ae525_tokenizer_protein.sp.30.model\n",
      "        vocab_file: nemo:70960ca328a54437ba8e161f6404bc8b_tokenizer_protein.sp.30.vocab\n",
      "        merge_file: null\n",
      "        vocab_path: /tmp/nvflare/bionemo/embeddings/simulate_job/app_site-2/models/vocab/protein_sequence.vocab\n",
      "        model_path: /tmp/nvflare/bionemo/embeddings/simulate_job/app_site-2/models/vocab/protein_sequence_sentencepiece.model\n",
      "      native_amp_init_scale: 4294967296\n",
      "      native_amp_growth_interval: 1000\n",
      "      fp32_residual_connection: false\n",
      "      fp16_lm_cross_entropy: false\n",
      "      seed: 1234\n",
      "      use_cpu_initialization: false\n",
      "      onnx_safe: false\n",
      "      activations_checkpoint_method: null\n",
      "      activations_checkpoint_num_layers: 1\n",
      "      data:\n",
      "        dataset_path: /tmp/fasta/mixed_soft\n",
      "        dataset:\n",
      "          train: x[000..049]\n",
      "          test: x[000..049]\n",
      "          val: x[000..049]\n",
      "        newline_int: 10\n",
      "        header_lines: 1\n",
      "        data_col: 3\n",
      "        data_sep: ','\n",
      "        sort_dataset_paths: true\n",
      "        skip_lines: 0\n",
      "        micro_batch_size: 370\n",
      "        encoder_augment: false\n",
      "        encoder_mask: false\n",
      "        decoder_augment: false\n",
      "        decoder_mask: false\n",
      "        canonicalize_input: true\n",
      "        dataloader_type: single\n",
      "        drop_last: false\n",
      "        pin_memory: false\n",
      "        num_workers: 4\n",
      "        data_prefix: ''\n",
      "        index_mapping_dir: null\n",
      "        data_impl: ''\n",
      "        splits_string: 900,50,50\n",
      "        skip_warmup: true\n",
      "        reset_position_ids: false\n",
      "        reset_attention_mask: false\n",
      "        eod_mask_loss: false\n",
      "        masked_lm_prob: 0.15\n",
      "        short_seq_prob: 0.1\n",
      "        dataset_format: csv\n",
      "        seed: 1234\n",
      "        max_seq_length: 512\n",
      "        batch_size: 128\n",
      "        output_fname: ''\n",
      "        data_fields_map:\n",
      "          sequence: sequence\n",
      "          id: id\n",
      "        data_impl_kwargs:\n",
      "          csv_fields_mmap:\n",
      "            newline_int: 10\n",
      "            header_lines: 1\n",
      "            workers: null\n",
      "            sort_dataset_paths: false\n",
      "            data_sep: ','\n",
      "            data_fields:\n",
      "              id: 0\n",
      "              sequence: 1\n",
      "          fasta_fields_mmap:\n",
      "            data_fields:\n",
      "              id: 0\n",
      "              sequence: 1\n",
      "      optim:\n",
      "        name: fused_adam\n",
      "        lr: 0.0002\n",
      "        weight_decay: 0.01\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.98\n",
      "        sched:\n",
      "          name: CosineAnnealing\n",
      "          warmup_steps: 500\n",
      "          constant_steps: 50000\n",
      "          min_lr: 2.0e-05\n",
      "      precision: 16\n",
      "      downstream_task:\n",
      "        restore_from_path: /tmp/nvflare/bionemo/embeddings/simulate_job/app_site-2/models/esm1nv.nemo\n",
      "        outputs:\n",
      "        - embeddings\n",
      "        - hiddens\n",
      "      global_batch_size: 370\n",
      "    target: bionemo.model.protein.esm1nv.esm1nv_model.ESM1nvModel\n",
      "    infer_target: bionemo.model.protein.esm1nv.infer.ESM1nvInference\n",
      "    formatters:\n",
      "      simple:\n",
      "        format: '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'\n",
      "    handlers:\n",
      "      console:\n",
      "        class: logging.StreamHandler\n",
      "        formatter: simple\n",
      "        stream: ext://sys.stdout\n",
      "      file:\n",
      "        class: logging.FileHandler\n",
      "        formatter: simple\n",
      "        filename: /logs/inference.log\n",
      "    root:\n",
      "      level: INFO\n",
      "      handlers:\n",
      "      - console\n",
      "    disable_existing_loggers: false\n",
      "    defaults:\n",
      "    - base_infer_config\n",
      "    - _self_\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-07-31 18:48:57 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/plugins/precision/native_amp.py:131: LightningDeprecationWarning: The `NativeMixedPrecisionPlugin` class has been renamed in v1.9.0 and will be removed in v2.0.0. Please use `pytorch_lightning.plugins.MixedPrecisionPlugin` instead.\n",
      "      rank_zero_deprecation(\n",
      "    \n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0731 18:48:57.358414 140128720627520 setup.py:163] GPU available: True (cuda), used: True\n",
      "I0731 18:48:57.359100 140128720627520 setup.py:166] TPU available: False, using: 0 TPU cores\n",
      "I0731 18:48:57.359314 140128720627520 setup.py:169] IPU available: False, using: 0 IPUs\n",
      "I0731 18:48:57.359436 140128720627520 setup.py:172] HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-07-31 18:48:57 megatron_init:231] Rank 0 has data parallel group: [0]\n",
      "[NeMo I 2023-07-31 18:48:57 megatron_init:234] All data parallel group ranks: [[0]]\n",
      "[NeMo I 2023-07-31 18:48:57 megatron_init:235] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2023-07-31 18:48:57 megatron_init:243] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2023-07-31 18:48:57 megatron_init:244] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-07-31 18:48:57 megatron_init:254] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2023-07-31 18:48:57 megatron_init:258] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-07-31 18:48:57 megatron_init:259] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2023-07-31 18:48:57 megatron_init:273] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2023-07-31 18:48:57 megatron_init:285] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2023-07-31 18:48:57 megatron_init:291] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-07-31 18:48:57 megatron_init:292] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2023-07-31 18:48:57 megatron_init:293] All embedding group ranks: [[0]]\n",
      "[NeMo I 2023-07-31 18:48:57 megatron_init:294] Rank 0 has embedding rank: 0\n",
      "[NeMo I 2023-07-31 18:48:57 tokenizer_utils:191] Getting SentencePiece with model: /tmp/tmpxxvj4hw1/08a2085a60b3411fad6b6ff6bd6ae525_tokenizer_protein.sp.30.model\n",
      "[NeMo I 2023-07-31 18:48:57 megatron_base_model:229] Padded vocab_size: 128, original vocab_size: 30, dummy tokens: 98.\n",
      "[NeMo I 2023-07-31 18:48:57 nlp_overrides:396] Model ESM1nvModel was successfully restored from /tmp/nvflare/bionemo/embeddings/simulate_job/app_site-2/models/esm1nv.nemo.\n",
      "[NeMo I 2023-07-31 18:48:57 utils:338] DDP is not initialized. Initializing...\n",
      "2023-07-31 18:48:57,957 - lightning_fabric.utilities.distributed - INFO - Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "2023-07-31 18:48:57,959 - pytorch_lightning.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2023-07-31 18:48:57 text_memmap_dataset:104] Building data files\n",
      "[NeMo I 2023-07-31 18:48:57 text_memmap_dataset:343] Processing 1 data files using 6 workers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-07-31 18:48:57 modelPT:245] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
      "I0731 18:48:57.957601 140128720627520 distributed.py:244] Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "I0731 18:48:57.959187 140128720627520 distributed.py:248] ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo W 2023-07-31 18:48:57 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel/utils.py:81: UserWarning: This function is only for unittest\n",
      "      warnings.warn(\"This function is only for unittest\")\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-07-31 18:48:58 text_memmap_dataset:315] Building indexing for fn = /tmp/fasta/mixed_soft/data_site-2.csv\n",
      "[NeMo I 2023-07-31 18:48:58 text_memmap_dataset:327] Saving idx file = /tmp/fasta/mixed_soft/data_site-2.csv.idx.npy\n",
      "[NeMo I 2023-07-31 18:48:58 text_memmap_dataset:329] Saving metadata file = /tmp/fasta/mixed_soft/data_site-2.csv.idx.info\n",
      "[NeMo I 2023-07-31 18:48:58 text_memmap_dataset:349] Time building 1 / 1 mem-mapped files: 0:00:00.156449\n",
      "[NeMo I 2023-07-31 18:48:58 text_memmap_dataset:114] Loading data files\n",
      "[NeMo I 2023-07-31 18:48:58 text_memmap_dataset:205] Loading /tmp/fasta/mixed_soft/data_site-2.csv\n",
      "[NeMo I 2023-07-31 18:48:58 text_memmap_dataset:117] Time loading 1 mem-mapped files: 0:00:00.002437\n",
      "[NeMo I 2023-07-31 18:48:58 text_memmap_dataset:121] Computing global indices\n",
      "[NeMo I 2023-07-31 18:48:59 mapped_dataset:206] Filtered out (ignored) 15 samples ( 2857 / 2872 )\n",
      "2023-07-31 18:48:59,775 - pytorch_lightning.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Predicting: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0731 18:48:59.775378 140128720627520 cuda.py:58] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 23/23 [00:28<00:00,  1.25s/it]2023-07-31 18:49:33,507 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=bionemo_inference, peer=site-2, peer_run=simulate_job]: got result from client site-2 for task: name=bionemo_inference, id=f4f92557-e241-439a-be29-cfca2ea16fbd\n",
      "2023-07-31 18:49:33,510 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=bionemo_inference, peer=site-2, peer_run=simulate_job, peer_rc=OK, task_name=bionemo_inference, task_id=f4f92557-e241-439a-be29-cfca2ea16fbd]: finished processing client result by bionemo_inference\n",
      "2023-07-31 18:49:33,513 - SubmitUpdateCommand - INFO - submit_update process. client_name:site-2   task_id:f4f92557-e241-439a-be29-cfca2ea16fbd\n",
      "2023-07-31 18:49:33,519 - SimulatorClientRunner - INFO - Simulate Run client: site-3 on GPU group: None\n",
      "2023-07-31 18:49:35,578 - ClientTaskWorker - INFO - ClientTaskWorker started to run\n",
      "2023-07-31 18:49:35,654 - Cell - INFO - site-3.simulate_job: created backbone external connector to tcp://localhost:49501\n",
      "2023-07-31 18:49:35,654 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 ACTIVE tcp://localhost:49501] is starting\n",
      "2023-07-31 18:49:38,419 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmpjib9nvsx\n",
      "2023-07-31 18:49:38,419 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmpjib9nvsx/_remote_module_non_scriptable.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-07-31 18:49:45 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-31 18:49:46,539 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=bionemo_inference, peer=site-3, peer_run=simulate_job, task_name=bionemo_inference, task_id=451b3ce7-bb6d-4b28-9ff7-e540ee9eb67a]: assigned task to client site-3: name=bionemo_inference, id=451b3ce7-bb6d-4b28-9ff7-e540ee9eb67a\n",
      "2023-07-31 18:49:46,543 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=bionemo_inference, peer=site-3, peer_run=simulate_job, task_name=bionemo_inference, task_id=451b3ce7-bb6d-4b28-9ff7-e540ee9eb67a]: sent task assignment to client. client_name:site-3 task_id:451b3ce7-bb6d-4b28-9ff7-e540ee9eb67a\n",
      "2023-07-31 18:49:46,545 - GetTaskCommand - INFO - return task to client.  client_name: site-3  task_name: bionemo_inference   task_id: 451b3ce7-bb6d-4b28-9ff7-e540ee9eb67a  sharable_header_task_id: 451b3ce7-bb6d-4b28-9ff7-e540ee9eb67a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-07-31 18:49:46 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-07-31 18:49:46 utils:250] Restoring model from /tmp/nvflare/bionemo/embeddings/simulate_job/app_site-3/models/esm1nv.nemo\n",
      "[NeMo I 2023-07-31 18:49:46 utils:254] Loading model class: bionemo.model.protein.esm1nv.esm1nv_model.ESM1nvModel\n",
      "2023-07-31 18:49:46,665 - pytorch_lightning.utilities.rank_zero - INFO - GPU available: True (cuda), used: True\n",
      "2023-07-31 18:49:46,665 - pytorch_lightning.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores\n",
      "2023-07-31 18:49:46,665 - pytorch_lightning.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs\n",
      "2023-07-31 18:49:46,665 - pytorch_lightning.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2023-07-31 18:49:46 exp_manager:374] Experiments will be logged at /tmp/nvflare/bionemo/embeddings/simulate_job/app_site-3/nemo_experiments/ESM1nv_Inference/2023-07-31_18-49-46\n",
      "[NeMo I 2023-07-31 18:49:46 exp_manager:797] TensorboardLogger has been set up\n",
      "[NeMo I 2023-07-31 18:49:46 utils:234] \n",
      "    \n",
      "    ************** Trainer configuration ***********\n",
      "[NeMo I 2023-07-31 18:49:46 utils:235] \n",
      "    name: ESM1nv_Inference\n",
      "    desc: Minimum configuration for initializing a ESM1nv model for inference.\n",
      "    trainer:\n",
      "      precision: 16\n",
      "      devices: 1\n",
      "      num_nodes: 1\n",
      "      accelerator: gpu\n",
      "      logger: null\n",
      "      accumulate_grad_batches: 1\n",
      "    exp_manager:\n",
      "      explicit_log_dir: null\n",
      "      exp_dir: null\n",
      "      name: ${name}\n",
      "      create_checkpoint_callback: false\n",
      "    model:\n",
      "      micro_batch_size: 370\n",
      "      tensor_model_parallel_size: 1\n",
      "      pipeline_model_parallel_size: 1\n",
      "      seq_length: 512\n",
      "      max_position_embeddings: 512\n",
      "      num_layers: 6\n",
      "      hidden_size: 768\n",
      "      ffn_hidden_size: 3072\n",
      "      num_attention_heads: 12\n",
      "      init_method_std: 0.02\n",
      "      hidden_dropout: 0.1\n",
      "      kv_channels: null\n",
      "      apply_query_key_layer_scaling: true\n",
      "      layernorm_epsilon: 1.0e-05\n",
      "      make_vocab_size_divisible_by: 128\n",
      "      pre_process: true\n",
      "      post_process: false\n",
      "      bert_binary_head: false\n",
      "      resume_from_checkpoint: null\n",
      "      masked_softmax_fusion: true\n",
      "      tokenizer:\n",
      "        library: sentencepiece\n",
      "        type: null\n",
      "        model: nemo:08a2085a60b3411fad6b6ff6bd6ae525_tokenizer_protein.sp.30.model\n",
      "        vocab_file: nemo:70960ca328a54437ba8e161f6404bc8b_tokenizer_protein.sp.30.vocab\n",
      "        merge_file: null\n",
      "        vocab_path: /tmp/nvflare/bionemo/embeddings/simulate_job/app_site-3/models/vocab/protein_sequence.vocab\n",
      "        model_path: /tmp/nvflare/bionemo/embeddings/simulate_job/app_site-3/models/vocab/protein_sequence_sentencepiece.model\n",
      "      native_amp_init_scale: 4294967296\n",
      "      native_amp_growth_interval: 1000\n",
      "      fp32_residual_connection: false\n",
      "      fp16_lm_cross_entropy: false\n",
      "      seed: 1234\n",
      "      use_cpu_initialization: false\n",
      "      onnx_safe: false\n",
      "      activations_checkpoint_method: null\n",
      "      activations_checkpoint_num_layers: 1\n",
      "      data:\n",
      "        dataset_path: /tmp/fasta/mixed_soft\n",
      "        dataset:\n",
      "          train: x[000..049]\n",
      "          test: x[000..049]\n",
      "          val: x[000..049]\n",
      "        newline_int: 10\n",
      "        header_lines: 1\n",
      "        data_col: 3\n",
      "        data_sep: ','\n",
      "        sort_dataset_paths: true\n",
      "        skip_lines: 0\n",
      "        micro_batch_size: 370\n",
      "        encoder_augment: false\n",
      "        encoder_mask: false\n",
      "        decoder_augment: false\n",
      "        decoder_mask: false\n",
      "        canonicalize_input: true\n",
      "        dataloader_type: single\n",
      "        drop_last: false\n",
      "        pin_memory: false\n",
      "        num_workers: 4\n",
      "        data_prefix: ''\n",
      "        index_mapping_dir: null\n",
      "        data_impl: ''\n",
      "        splits_string: 900,50,50\n",
      "        skip_warmup: true\n",
      "        reset_position_ids: false\n",
      "        reset_attention_mask: false\n",
      "        eod_mask_loss: false\n",
      "        masked_lm_prob: 0.15\n",
      "        short_seq_prob: 0.1\n",
      "        dataset_format: csv\n",
      "        seed: 1234\n",
      "        max_seq_length: 512\n",
      "        batch_size: 128\n",
      "        output_fname: ''\n",
      "        data_fields_map:\n",
      "          sequence: sequence\n",
      "          id: id\n",
      "        data_impl_kwargs:\n",
      "          csv_fields_mmap:\n",
      "            newline_int: 10\n",
      "            header_lines: 1\n",
      "            workers: null\n",
      "            sort_dataset_paths: false\n",
      "            data_sep: ','\n",
      "            data_fields:\n",
      "              id: 0\n",
      "              sequence: 1\n",
      "          fasta_fields_mmap:\n",
      "            data_fields:\n",
      "              id: 0\n",
      "              sequence: 1\n",
      "      optim:\n",
      "        name: fused_adam\n",
      "        lr: 0.0002\n",
      "        weight_decay: 0.01\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.98\n",
      "        sched:\n",
      "          name: CosineAnnealing\n",
      "          warmup_steps: 500\n",
      "          constant_steps: 50000\n",
      "          min_lr: 2.0e-05\n",
      "      precision: 16\n",
      "      downstream_task:\n",
      "        restore_from_path: /tmp/nvflare/bionemo/embeddings/simulate_job/app_site-3/models/esm1nv.nemo\n",
      "        outputs:\n",
      "        - embeddings\n",
      "        - hiddens\n",
      "      global_batch_size: 370\n",
      "    target: bionemo.model.protein.esm1nv.esm1nv_model.ESM1nvModel\n",
      "    infer_target: bionemo.model.protein.esm1nv.infer.ESM1nvInference\n",
      "    formatters:\n",
      "      simple:\n",
      "        format: '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'\n",
      "    handlers:\n",
      "      console:\n",
      "        class: logging.StreamHandler\n",
      "        formatter: simple\n",
      "        stream: ext://sys.stdout\n",
      "      file:\n",
      "        class: logging.FileHandler\n",
      "        formatter: simple\n",
      "        filename: /logs/inference.log\n",
      "    root:\n",
      "      level: INFO\n",
      "      handlers:\n",
      "      - console\n",
      "    disable_existing_loggers: false\n",
      "    defaults:\n",
      "    - base_infer_config\n",
      "    - _self_\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-07-31 18:49:46 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/plugins/precision/native_amp.py:131: LightningDeprecationWarning: The `NativeMixedPrecisionPlugin` class has been renamed in v1.9.0 and will be removed in v2.0.0. Please use `pytorch_lightning.plugins.MixedPrecisionPlugin` instead.\n",
      "      rank_zero_deprecation(\n",
      "    \n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0731 18:49:46.665012 140077106870080 setup.py:163] GPU available: True (cuda), used: True\n",
      "I0731 18:49:46.665490 140077106870080 setup.py:166] TPU available: False, using: 0 TPU cores\n",
      "I0731 18:49:46.665618 140077106870080 setup.py:169] IPU available: False, using: 0 IPUs\n",
      "I0731 18:49:46.665689 140077106870080 setup.py:172] HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-07-31 18:49:47 megatron_init:231] Rank 0 has data parallel group: [0]\n",
      "[NeMo I 2023-07-31 18:49:47 megatron_init:234] All data parallel group ranks: [[0]]\n",
      "[NeMo I 2023-07-31 18:49:47 megatron_init:235] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2023-07-31 18:49:47 megatron_init:243] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2023-07-31 18:49:47 megatron_init:244] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-07-31 18:49:47 megatron_init:254] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2023-07-31 18:49:47 megatron_init:258] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-07-31 18:49:47 megatron_init:259] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2023-07-31 18:49:47 megatron_init:273] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2023-07-31 18:49:47 megatron_init:285] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2023-07-31 18:49:47 megatron_init:291] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2023-07-31 18:49:47 megatron_init:292] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2023-07-31 18:49:47 megatron_init:293] All embedding group ranks: [[0]]\n",
      "[NeMo I 2023-07-31 18:49:47 megatron_init:294] Rank 0 has embedding rank: 0\n",
      "[NeMo I 2023-07-31 18:49:47 tokenizer_utils:191] Getting SentencePiece with model: /tmp/tmpallz1z7x/08a2085a60b3411fad6b6ff6bd6ae525_tokenizer_protein.sp.30.model\n",
      "[NeMo I 2023-07-31 18:49:47 megatron_base_model:229] Padded vocab_size: 128, original vocab_size: 30, dummy tokens: 98.\n",
      "[NeMo I 2023-07-31 18:49:47 nlp_overrides:396] Model ESM1nvModel was successfully restored from /tmp/nvflare/bionemo/embeddings/simulate_job/app_site-3/models/esm1nv.nemo.\n",
      "[NeMo I 2023-07-31 18:49:47 utils:338] DDP is not initialized. Initializing...\n",
      "2023-07-31 18:49:47,272 - lightning_fabric.utilities.distributed - INFO - Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "2023-07-31 18:49:47,274 - pytorch_lightning.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2023-07-31 18:49:47 text_memmap_dataset:104] Building data files\n",
      "[NeMo I 2023-07-31 18:49:47 text_memmap_dataset:343] Processing 1 data files using 6 workers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-07-31 18:49:47 modelPT:245] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
      "I0731 18:49:47.272995 140077106870080 distributed.py:244] Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "I0731 18:49:47.274384 140077106870080 distributed.py:248] ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo W 2023-07-31 18:49:47 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel/utils.py:81: UserWarning: This function is only for unittest\n",
      "      warnings.warn(\"This function is only for unittest\")\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-07-31 18:49:47 text_memmap_dataset:315] Building indexing for fn = /tmp/fasta/mixed_soft/data_site-3.csv\n",
      "[NeMo I 2023-07-31 18:49:47 text_memmap_dataset:327] Saving idx file = /tmp/fasta/mixed_soft/data_site-3.csv.idx.npy\n",
      "[NeMo I 2023-07-31 18:49:47 text_memmap_dataset:329] Saving metadata file = /tmp/fasta/mixed_soft/data_site-3.csv.idx.info\n",
      "[NeMo I 2023-07-31 18:49:47 text_memmap_dataset:349] Time building 1 / 1 mem-mapped files: 0:00:00.171638\n",
      "[NeMo I 2023-07-31 18:49:48 text_memmap_dataset:114] Loading data files\n",
      "[NeMo I 2023-07-31 18:49:48 text_memmap_dataset:205] Loading /tmp/fasta/mixed_soft/data_site-3.csv\n",
      "[NeMo I 2023-07-31 18:49:48 text_memmap_dataset:117] Time loading 1 mem-mapped files: 0:00:00.003106\n",
      "[NeMo I 2023-07-31 18:49:48 text_memmap_dataset:121] Computing global indices\n",
      "[NeMo I 2023-07-31 18:49:49 mapped_dataset:206] Filtered out (ignored) 12 samples ( 2860 / 2872 )\n",
      "2023-07-31 18:49:49,279 - pytorch_lightning.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Predicting: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0731 18:49:49.279194 140077106870080 cuda.py:58] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 23/23 [00:28<00:00,  1.24s/it]2023-07-31 18:50:22,621 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=bionemo_inference, peer=site-3, peer_run=simulate_job]: got result from client site-3 for task: name=bionemo_inference, id=451b3ce7-bb6d-4b28-9ff7-e540ee9eb67a\n",
      "2023-07-31 18:50:22,624 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=bionemo_inference, peer=site-3, peer_run=simulate_job, peer_rc=OK, task_name=bionemo_inference, task_id=451b3ce7-bb6d-4b28-9ff7-e540ee9eb67a]: finished processing client result by bionemo_inference\n",
      "2023-07-31 18:50:22,626 - SubmitUpdateCommand - INFO - submit_update process. client_name:site-3   task_id:451b3ce7-bb6d-4b28-9ff7-e540ee9eb67a\n",
      "2023-07-31 18:50:22,630 - SimulatorClientRunner - INFO - Simulate Run client: site-1 on GPU group: None\n",
      "2023-07-31 18:50:22,660 - BioNeMoInference - INFO - [identity=simulator_server, run=simulate_job, wf=bionemo_inference]: task bionemo_inference exit with status TaskCompletionStatus.OK\n",
      "2023-07-31 18:50:22,809 - BioNeMoInferenceProcessor - INFO - [identity=simulator_server, run=simulate_job, wf=bionemo_inference]: Clients inference responses: {'site-1': {'bionemo_number_sequences': 2862}, 'site-2': {'bionemo_number_sequences': 2857}, 'site-3': {'bionemo_number_sequences': 2860}}\n",
      "2023-07-31 18:50:22,812 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=bionemo_inference]: Workflow: bionemo_inference finalizing ...\n",
      "2023-07-31 18:50:22,864 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=bionemo_inference]: ABOUT_TO_END_RUN fired\n",
      "2023-07-31 18:50:22,867 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=bionemo_inference]: END_RUN fired\n",
      "2023-07-31 18:50:22,869 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=bionemo_inference]: Server runner finished.\n",
      "2023-07-31 18:50:23,692 - SimulatorServer - INFO - Server app stopped.\n",
      "\n",
      "\n",
      "2023-07-31 18:50:24,157 - nvflare.fuel.hci.server.hci - INFO - Admin Server localhost on Port 53069 shutdown!\n",
      "2023-07-31 18:50:24,159 - SimulatorServer - INFO - shutting down server\n",
      "2023-07-31 18:50:24,162 - SimulatorServer - INFO - canceling sync locks\n",
      "2023-07-31 18:50:24,164 - SimulatorServer - INFO - server off\n",
      "2023-07-31 18:50:24,688 - ClientTaskWorker - INFO - ClientTaskWorker started to run\n",
      "2023-07-31 18:50:24,763 - Cell - INFO - site-1.simulate_job: created backbone external connector to tcp://localhost:49501\n",
      "2023-07-31 18:50:24,764 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 ACTIVE tcp://localhost:49501] is starting\n",
      "2023-07-31 18:50:27,550 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmpdma_l1c7\n",
      "2023-07-31 18:50:27,550 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmpdma_l1c7/_remote_module_non_scriptable.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-07-31 18:50:34 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-31 18:50:35,568 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=bionemo_inference, peer=site-1, peer_run=simulate_job]: server runner is finalizing - asked client to end the run\n",
      "2023-07-31 18:50:35,571 - GetTaskCommand - INFO - return task to client.  client_name: site-1  task_name: __end_run__   task_id:   sharable_header_task_id: \n",
      "2023-07-31 18:50:35,579 - SimulatorClientRunner - INFO - Simulate Run client: site-2 on GPU group: None\n",
      "2023-07-31 18:50:35,583 - FederatedClient - INFO - Shutting down client run: site-1\n",
      "2023-07-31 18:50:35,585 - FederatedClient - INFO - Shutting down client run: site-2\n",
      "2023-07-31 18:50:35,586 - FederatedClient - INFO - Shutting down client run: site-3\n",
      "2023-07-31 18:50:35,588 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=bionemo_inference]: asked to abort - triggered abort_signal to stop the RUN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-07-31 18:50:35 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-31 18:50:38,828 - MPM - INFO - MPM: Good Bye!\n",
      "Simulator finished with run_status 0\n"
     ]
    }
   ],
   "source": [
    "from nvflare import SimulatorRunner    \n",
    "\n",
    "simulator = SimulatorRunner(\n",
    "    job_folder=\"jobs/embeddings\",\n",
    "    workspace=\"/tmp/nvflare/bionemo/embeddings\",\n",
    "    n_clients=n_clients,\n",
    "    threads=1  # due to memory constraints, we run the client execution sequentially in one thread\n",
    ")\n",
    "run_status = simulator.run()\n",
    "print(\"Simulator finished with run_status\", run_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c27820",
   "metadata": {},
   "source": [
    "### Inspecting the embeddings and labels\n",
    "Embeddings returned from the BioNeMo server are vectors of fixed size for each input sequence. In other words, if we input 10 sequences, we will obtain a matrix `10xD`, where `D` is the size of the embedding (in the case of ESM-1nv, `D=768`). At a glance, these real-valued vector embeddings don't show any obvious features (see the printout in the next cell). But these vectors do contain information that can be used in downstream models to reveal properties of the protein, for example the subcellular location as we'll explore below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ce56a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2862 embeddings from site-1.\n",
      "Inference result contains ['embeddings', 'hiddens', 'sequence', 'id']\n",
      "10649: range -0.90283203125-1.7978515625, mean=-0.0032165292650461197, shape=(768,)\n",
      "Inference result contains ['embeddings', 'hiddens', 'sequence', 'id']\n",
      "7598: range -0.8017578125-1.2138671875, mean=-0.0010715207317844033, shape=(768,)\n",
      "Inference result contains ['embeddings', 'hiddens', 'sequence', 'id']\n",
      "11506: range -0.86865234375-1.708984375, mean=-0.0034913886338472366, shape=(768,)\n",
      "Inference result contains ['embeddings', 'hiddens', 'sequence', 'id']\n",
      "7116: range -0.7880859375-1.5556640625, mean=-0.0015334287891164422, shape=(768,)\n"
     ]
    }
   ],
   "source": [
    "# load embeddings from site-1\n",
    "import pickle\n",
    "protein_embeddings = pickle.load(open(os.path.join(out_dir, \"data_site-1.pkl\"), \"rb\"))\n",
    "print(f\"Loaded {len(protein_embeddings)} embeddings from site-1.\")\n",
    "\n",
    "for i in range(4):\n",
    "    protein_embedding = protein_embeddings[i]\n",
    "    print(f\"Inference result contains {list(protein_embedding.keys())}\")\n",
    "    x = protein_embedding[\"embeddings\"]\n",
    "    print(f\"{protein_embedding['id']}: range {np.min(x)}-{np.max(x)}, mean={np.mean(x)}, shape={x.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab29214",
   "metadata": {},
   "source": [
    "Let's enumerate the labels corresponding to potential subcellular locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fbde6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Mitochondrion\n",
      "2. Golgi apparatus\n",
      "3. Extracellular\n",
      "4. Cytoplasm\n",
      "5. Peroxisome\n",
      "6. Cell membrane\n",
      "7. Nucleus\n",
      "8. Plastid\n",
      "9. Lysosome\n",
      "10. Endoplasmic reticulum\n"
     ]
    }
   ],
   "source": [
    "# Let's also print all the labels\n",
    "\n",
    "labels = set([entry['TARGET'] for entry in data])\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    print(f\"{i+1}. {label.replace('_', ' ')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a077ba",
   "metadata": {},
   "source": [
    "### Training a MLP to predict subcellular location\n",
    "To be able to classify proteins for their subcellular location, we train a simple scikit-learn Multi-layer Perceptron (MPL) classifier. The MLP model uses a network of hidden layers to fit the input embedding vectors to the model classes (the cellular locations above). In the call below, we define the MLP to use the Adam optimizer with a network of 32 hidden layers, defining a random state (or seed) for reproducibility, and trained for a maximum of 500 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2573f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-01 14:25:15,524 - SimulatorRunner - INFO - Create the Simulator Server.\n",
      "2023-08-01 14:25:15,529 - Cell - INFO - server: creating listener on tcp://0:43109\n",
      "2023-08-01 14:25:15,557 - Cell - INFO - server: created backbone external listener for tcp://0:43109\n",
      "2023-08-01 14:25:15,558 - ConnectorManager - INFO - 121322: Try start_listener Listener resources: {'secure': False, 'host': 'localhost'}\n",
      "2023-08-01 14:25:15,561 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00002 PASSIVE tcp://0:4601] is starting\n",
      "2023-08-01 14:25:16,064 - Cell - INFO - server: created backbone internal listener for tcp://localhost:4601\n",
      "2023-08-01 14:25:16,067 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 PASSIVE tcp://0:43109] is starting\n",
      "2023-08-01 14:25:16,162 - nvflare.fuel.hci.server.hci - INFO - Starting Admin Server localhost on Port 51185\n",
      "2023-08-01 14:25:16,164 - SimulatorRunner - INFO - Deploy the Apps.\n",
      "2023-08-01 14:25:16,171 - SimulatorRunner - INFO - Create the simulate clients.\n",
      "2023-08-01 14:25:16,185 - ClientManager - INFO - Client: New client site-1@192.168.0.25 joined. Sent token: e5c0297e-1c5a-4222-b225-471a5a2dcb0d.  Total clients: 1\n",
      "2023-08-01 14:25:16,188 - FederatedClient - INFO - Successfully registered client:site-1 for project simulator_server. Token:e5c0297e-1c5a-4222-b225-471a5a2dcb0d SSID:\n",
      "2023-08-01 14:25:16,199 - ClientManager - INFO - Client: New client site-2@192.168.0.25 joined. Sent token: d3931253-e03d-4684-b477-03303262e213.  Total clients: 2\n",
      "2023-08-01 14:25:16,201 - FederatedClient - INFO - Successfully registered client:site-2 for project simulator_server. Token:d3931253-e03d-4684-b477-03303262e213 SSID:\n",
      "2023-08-01 14:25:16,214 - ClientManager - INFO - Client: New client site-3@192.168.0.25 joined. Sent token: f16ec1c8-7221-4f43-b610-dc6752f6a7ea.  Total clients: 3\n",
      "2023-08-01 14:25:16,217 - FederatedClient - INFO - Successfully registered client:site-3 for project simulator_server. Token:f16ec1c8-7221-4f43-b610-dc6752f6a7ea SSID:\n",
      "2023-08-01 14:25:16,220 - SimulatorRunner - INFO - Set the client status ready.\n",
      "2023-08-01 14:25:16,222 - SimulatorRunner - INFO - Deploy and start the Server App.\n",
      "2023-08-01 14:25:16,231 - ServerCommandAgent - INFO - ServerCommandAgent cell register_request_cb: server.simulate_job\n",
      "2023-08-01 14:25:18,823 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmp_eoj55js\n",
      "2023-08-01 14:25:18,826 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmp_eoj55js/_remote_module_non_scriptable.py\n",
      "2023-08-01 14:25:19,594 - IntimeModelSelector - INFO - model selection weights control: None\n",
      "2023-08-01 14:25:19,597 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job]: Server runner starting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-01 14:25:19,629 - BioNeMoMLPModelPersistor - INFO - [identity=simulator_server, run=simulate_job]: MLPClassifier coefficients [(768, 32), (32, 10)], intercepts [(32,), (10,)]\n",
      "2023-08-01 14:25:19,634 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job]: starting workflow scatter_gather_ctl (<class 'nvflare.app_common.workflows.scatter_and_gather.ScatterAndGather'>) ...\n",
      "2023-08-01 14:25:19,638 - ScatterAndGather - INFO - [identity=simulator_server, run=simulate_job]: Initializing ScatterAndGather workflow.\n",
      "2023-08-01 14:25:19,642 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job]: Workflow scatter_gather_ctl (<class 'nvflare.app_common.workflows.scatter_and_gather.ScatterAndGather'>) started\n",
      "2023-08-01 14:25:19,650 - ScatterAndGather - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_gather_ctl]: Beginning ScatterAndGather training phase.\n",
      "2023-08-01 14:25:19,653 - ScatterAndGather - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_gather_ctl]: Round 0 started.\n",
      "2023-08-01 14:25:19,656 - ScatterAndGather - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_gather_ctl]: scheduled task train\n",
      "2023-08-01 14:25:20,412 - SimulatorClientRunner - INFO - Start the clients run simulation.\n",
      "2023-08-01 14:25:21,416 - SimulatorClientRunner - INFO - Simulate Run client: site-1 on GPU group: None\n",
      "2023-08-01 14:25:21,419 - SimulatorClientRunner - INFO - Simulate Run client: site-2 on GPU group: None\n",
      "2023-08-01 14:25:21,508 - SimulatorClientRunner - INFO - Simulate Run client: site-3 on GPU group: None\n",
      "2023-08-01 14:25:22,642 - ClientTaskWorker - INFO - ClientTaskWorker started to run\n",
      "2023-08-01 14:25:22,663 - ClientTaskWorker - INFO - ClientTaskWorker started to run\n",
      "2023-08-01 14:25:22,717 - Cell - INFO - site-1.simulate_job: created backbone external connector to tcp://localhost:43109\n",
      "2023-08-01 14:25:22,717 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 ACTIVE tcp://localhost:43109] is starting\n",
      "2023-08-01 14:25:22,729 - ClientTaskWorker - INFO - ClientTaskWorker started to run\n",
      "2023-08-01 14:25:22,736 - Cell - INFO - site-2.simulate_job: created backbone external connector to tcp://localhost:43109\n",
      "2023-08-01 14:25:22,736 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 ACTIVE tcp://localhost:43109] is starting\n",
      "2023-08-01 14:25:22,805 - Cell - INFO - site-3.simulate_job: created backbone external connector to tcp://localhost:43109\n",
      "2023-08-01 14:25:22,805 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 ACTIVE tcp://localhost:43109] is starting\n",
      "2023-08-01 14:25:25,644 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmpzqkyvs8z\n",
      "2023-08-01 14:25:25,644 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmpzqkyvs8z/_remote_module_non_scriptable.py\n",
      "2023-08-01 14:25:25,680 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmp1kautf_e\n",
      "2023-08-01 14:25:25,680 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmp1kautf_e/_remote_module_non_scriptable.py\n",
      "2023-08-01 14:25:25,689 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmpn1crxcop\n",
      "2023-08-01 14:25:25,689 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmpn1crxcop/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "from nvflare import SimulatorRunner    \n",
    "\n",
    "simulator = SimulatorRunner(\n",
    "    job_folder=\"jobs/fedavg\",\n",
    "    workspace=\"/tmp/nvflare/bionemo/fedavg\",\n",
    "    n_clients=n_clients,\n",
    "    threads=n_clients\n",
    ")\n",
    "run_status = simulator.run()\n",
    "print(\"Simulator finished with run_status\", run_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439b84ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
