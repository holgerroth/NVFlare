{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cada310b-e776-4b9a-aabe-f111c31efcc2",
   "metadata": {},
   "source": [
    "# Split Learning with CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9d461eb-d30f-46f5-8f74-9516fc9deaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export PYTHONPATH=/home/hroth/Code2/nvflare/splitnn:/home/hroth/Code2/nvflare/splitnn/examples/cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0653cbf2-92f2-4a22-8317-69cfb0266e92",
   "metadata": {},
   "source": [
    "## 1. Download and split the CIFAR-10 dataset\n",
    "To simulate a vertical split dataset, we first download the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset and distribute it between the two clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4130b15-09e6-456f-a3c7-87c8ee9e07f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SPLIT_DIR=/tmp/cifar10_vert_splits\n",
      "env: OVERLAP=10000\n",
      "INFO:Cifar10VerticalDataSplitter:[identity=local, run=_]: Partition CIFAR-10 dataset into vertically with 10000 overlapping samples.\n",
      "Files already downloaded and verified\n",
      "INFO:Cifar10VerticalDataSplitter:[identity=local, run=_]: save /tmp/cifar10_vert_splits/overlap.npy\n",
      "INFO:Cifar10VerticalDataSplitter:[identity=local, run=_]: save /tmp/cifar10_vert_splits/site-1.npy\n",
      "INFO:Cifar10VerticalDataSplitter:[identity=local, run=_]: save /tmp/cifar10_vert_splits/site-2.npy\n"
     ]
    }
   ],
   "source": [
    "%env SPLIT_DIR=/tmp/cifar10_vert_splits\n",
    "%env OVERLAP=10000\n",
    "!python3 ../pt/utils/cifar10_split_data_vertical.py --split_dir ${SPLIT_DIR} --overlap ${OVERLAP}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af257e69-2bb7-49b6-ac6c-f007b0e6618e",
   "metadata": {},
   "source": [
    "## 2. Run private set intersection\n",
    "We are using NVFlare's FL simulator to run the following experiments.\n",
    "\n",
    "In order to find the overlapping data indices between the different clients participating in split learning, \n",
    "we randomly select an subset of the training indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdb7290a-48ff-4e80-be58-5e6b0e0f9379",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SimulatorRunner' from 'nvflare' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnvflare\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimulatorRunner    \n\u001b[1;32m      4\u001b[0m simulator \u001b[38;5;241m=\u001b[39m SimulatorRunner(\n\u001b[1;32m      5\u001b[0m     job_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob_configs/cifar10_psi\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     workspace\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tmp/nvflare/cifar10_psi\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     n_clients\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      8\u001b[0m     threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m run_status \u001b[38;5;241m=\u001b[39m simulator\u001b[38;5;241m.\u001b[39mrun()\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'SimulatorRunner' from 'nvflare' (unknown location)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#from nvflare import SimulatorRunner\n",
    "from nvflare.private.fed.app.simulator.simulator_runner import SimulatorRunner\n",
    "\n",
    "simulator = SimulatorRunner(\n",
    "    job_folder=f\"job_configs/cifar10_psi\",\n",
    "    workspace=\"/tmp/nvflare/cifar10_psi\",\n",
    "    n_clients=2,\n",
    "    threads=2\n",
    ")\n",
    "run_status = simulator.run()\n",
    "print(\"Simulator finished with run_status\", run_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1388dc-6a4f-4965-a09f-4d058fc3833c",
   "metadata": {},
   "source": [
    "The result will be saved on each client's working directory in `intersection.txt`.\n",
    "\n",
    "We can check the correctness of the result by comparing to the generate ground truth overlap, saved in `overlap.npy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedb6bcc-9443-4331-bde3-4576fbfffaec",
   "metadata": {},
   "source": [
    "### Check the PSI result\n",
    "We can check the correctness of the result by comparing to the generate ground truth overlap, saved in overlap.npy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a6b36f-649f-4e19-ba0a-5dd71dfda5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "split_dir = os.environ[\"SPLIT_DIR\"]\n",
    "gt_overlap = np.load(os.path.join(split_dir, \"overlap.npy\"))\n",
    "\n",
    "psi_overlap_1 = np.loadtxt(\"/tmp/nvflare/cifar10_psi/simulate_job/site-1/psi/intersection.txt\")\n",
    "psi_overlap_2 = np.loadtxt(\"/tmp/nvflare/cifar10_psi/simulate_job/site-2/psi/intersection.txt\")\n",
    "                     \n",
    "print(\"gt_overlap\", gt_overlap, f\"n={len(gt_overlap)}\")\n",
    "print(\"psi_overlap_1\", psi_overlap_1, f\"n={len(psi_overlap_1)}\")\n",
    "print(\"psi_overlap_2\", psi_overlap_2, f\"n={len(psi_overlap_2)}\")\n",
    "\n",
    "intersect_1 = np.intersect1d(psi_overlap_1, gt_overlap, assume_unique=True)\n",
    "intersect_2 = np.intersect1d(psi_overlap_2, gt_overlap, assume_unique=True)\n",
    "\n",
    "print(f\"Found {100*len(intersect_1)/len(gt_overlap):.1f}% of the overlapping sample ids for site-1.\")\n",
    "print(f\"Found {100*len(intersect_2)/len(gt_overlap):.1f}% of the overlapping sample ids for site-2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0713e2-e393-41c0-9da0-392535cf8a54",
   "metadata": {},
   "source": [
    "## 3. Run simulated split-learning experiments\n",
    "Next we use the `intersection.txt` files to align the datasets on each participating site in order to do split learning.\n",
    "The [config_fed_client.json](./job_configs/cifar10_splitnn/site-1/config/config_fed_client.json) takes as input the previously generated intersection file for each site.\n",
    "```\n",
    "    {\n",
    "        \"id\": \"cifar10-learner\",\n",
    "        \"path\": \"pt.learners.cifar10_learner_splitnn.CIFAR10LearnerSplitNN\",\n",
    "        \"args\": {\n",
    "            \"dataset_root\": \"{DATASET_ROOT}\",\n",
    "            \"intersection_file\": \"{INTERSECTION_FILE}\",\n",
    "            \"lr\": 1e-2,\n",
    "            \"model\": {\"path\": \"pt.networks.split_nn.SplitNN\", \"args\":  {\"split_id\":  0}},\n",
    "            \"timeit\": true\n",
    "        }\n",
    "    }\n",
    "```\n",
    "On the server side, the [config_fed_server.json](./job_configs/cifar10_splitnn/server/config/config_fed_server.json) needs to specify the size of the training dataset in order to generate random sample ids to build each batch during training. Here, the training set size (`train_size`) is equal to the number of overlapping samples defined above.\n",
    "```\n",
    "    {\n",
    "        \"id\": \"splitnn_ctl\",\n",
    "        \"path\": \"pt.workflows.splitnn_workflow.SplitNNController\",\n",
    "        \"args\": {\n",
    "            \"num_rounds\" : \"{num_rounds}\",\n",
    "            \"batch_size\": \"{batch_size}\",\n",
    "            \"train_size\": \"{train_size}\",\n",
    "            \"start_round\": 0,\n",
    "            \"persistor_id\": \"persistor\",\n",
    "            \"task_timeout\": 0,\n",
    "            \"shareable_generator_id\": \"shareable_generator\",\n",
    "            \"timeit\": true\n",
    "        }\n",
    "    }\n",
    "```\n",
    "To run the experiment, execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c75dcb-014d-40c4-8a4a-7a53847c486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nvflare import SimulatorRunner    \n",
    "\n",
    "simulator = SimulatorRunner(\n",
    "    job_folder=f\"job_configs/cifar10_splitnn\",\n",
    "    workspace=\"/tmp/nvflare/cifar10_splitnn\",\n",
    "    n_clients=2,\n",
    "    threads=2\n",
    ")\n",
    "run_status = simulator.run()\n",
    "print(\"Simulator finished with run_status\", run_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3e7ac4-7685-4610-bc2b-9627771c3799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nvflare simulator job_configs/cifar10_splitnn --workspace /tmp/nvflare/splitnn_cifar10 --threads 2 --n_clients 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6814434-4e6d-4460-b480-709cb3e77cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
